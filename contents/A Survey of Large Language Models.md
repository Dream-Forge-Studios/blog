---
date: '2024-01-30'
title: 'A Survey of Large Language Models'
categories: ['Large Language']
summary: 'A Survey of Large Language Models에서 내가 몰랐거나 도움이 될 만한 내용을 요약해보자!'
thumbnail: './test.png'
---

<div id="대규모 언어 모델의 효율적인 훈련"></div>

## 대규모 언어 모델의 효율적인 훈련

### 분산 훈련 알고리즘

1. 병렬 전략 사용: 

대규모 모델을 효과적으로 훈련하기 위해, 네트워크 파라미터를 학습하는 과정에서 여러 병렬 전략이 사용됩니다. 이러한 전략은 모델을 여러 컴퓨팅 장치에 분산시켜 각 장치가 모델의 일부를 학습하도록 합니다.

2. 효율적인 리소스 관리

이 접근법은 계산 자원을 최적화하고, 학습 시간을 단축하며, 대규모 모델을 실제로 훈련 가능하게 만듭니다.

### 최적화 프레임워크

1. DeepSpeed와 Megatron-LM

이러한 프레임워크는 분산 훈련을 지원하고, 병렬 알고리즘의 구현과 배포를 용이하게 합니다. DeepSpeed는 학습 속도를 높이고 메모리 사용을 최적화하는 반면, Megatron-LM은 모델 병렬화에 초점을 맞춥니다.

2. 프레임워크의 중요성

이러한 프레임워크는 대규모 모델을 효율적으로 학습시키는 데 필수적입니다. 그들은 개발자가 복잡한 하드웨어 설정을 직접 관리하지 않고도 대규모 모델을 학습할 수 있도록 도와줍니다.

### 최적화 기법

1. 재시작 전략

훈련 중 손실이 갑자기 증가하는 경우, 모델 훈련을 재시작하여 이 문제를 해결할 수 있습니다.

2. 혼합 정밀도 훈련

이 기법은 다른 데이터 유형(예: float32 대신 float16)을 사용하여 메모리 사용량을 줄이고, 계산 속도를 높입니다. 이는 모델 성능에 영향을 미치지 않으면서 훈련 속도를 개선합니다.

<div id="코드 데이터 학습"></div>

## 코드 데이터 학습

원래 GPT-3 모델은 일반 텍스트에 대한 사전 훈련을 받았지만, 복잡한 작업, 예를 들어 코드 완성이나 수학 문제 해결과 같은 작업에서 추론 능력에 한계가 있었습니다.

<br>

이 능력을 향상시키기 위해, OpenAI는 2021년 7월에 Codex를 소개했습니다. Codex는 GitHub 코드의 대규모 코퍼스에서 미세 조정된 GPT 모델입니다.

<br>

Codex는 매우 어려운 프로그래밍 문제를 해결할 수 있는 능력을 입증했으며, 수학 문제 해결에서도 큰 성능 향상을 이끌어 냈습니다.

<br>

2022년 1월에는 텍스트와 코드 임베딩을 훈련하는  contrastive approach 방식이 보고되었습니다. 이 방법은 관련 작업(예: 선형 프로브 분류, 텍스트 검색, 코드 검색)의 성능을 개선하는 데 도움이 되었습니다.

[관련 논문](https://arxiv.org/pdf/2201.10005.pdf)

<br>

또한, 코드 데이터에 대한 훈련이 LLM의 Chain-of-Thought Prompting 능력을 크게 증가시킬 수 있다는 추측이 있습니다. 하지만 이는 더 많은 연구와 검증이 필요한 부분입니다.

<div id="GPT-4"></div>

## GPT-4

### red teaming

OpenAI는 GPT-4의 개발 과정에서 환각, 개인정보 유출, 과도한 의존성 등의 문제를 완화하기 위한 여러 전략을 적용했습니다.

<br>

그 중 red teaming은 해로운 내용 생성을 줄였습니다.

[관련 논문](https://arxiv.org/pdf/2209.07858.pdf)

### predictable scaling

GPT-4는 잘 구축된 딥 러닝 인프라 위에서 개발되었으며, 개선된 최적화 방법이 적용되었습니다.

<br>

특히, 'predictable scaling'이라는 새로운 메커니즘을 도입하여 모델 훈련 중 적은 계산으로 최종 성능을 정확하게 예측할 수 있게 되었습니다.

<br>

트렌스포머 기반 언어 모델에서는 문장을 이해하고, 요약하고, 대답하는 등의 능력이 생기는 것을 확인하면서, LLM의 주목하기 시작하였습니다.

<div id="Library Resource"></div>

## Library Resource

- Transformers

  - Hugging Face에서 개발 및 유지 보수하는 Transformer 아키텍처를 사용하여 모델을 구축하는 오픈 소스 Python 라이브러리입니다.
  - 사용자 친화적이고 간단한 API를 제공하여 다양한 사전 훈련된 모델을 사용하고 사용자 정의하기 쉽습니다.
  - 많은 사용자 및 개발자로 이루어진 활발한 커뮤니티와 함께 작동하여 모델과 알고리즘을 정기적으로 업데이트하고 개선하는 강력한 라이브러리입니다.

- DeepSpeed

  - Microsoft에서 개발한 딥 러닝 최적화 라이브러리로 PyTorch와 호환됩니다.
  - 분산 훈련을 위한 다양한 최적화 기술을 지원하며, 메모리 최적화 (ZeRO 기술, 그래디언트 체크포인팅) 및 파이프라인 병렬성과 같은 기능을 제공합니다.
  - MTNLG 및 BLOOM과 같은 여러 LLMs의 훈련에 사용되었습니다.

- Megatron-LM:

  - NVIDIA에서 개발한 딥 러닝 라이브러리로 대규모 언어 모델을 훈련하기 위한 것입니다.
  - 모델 및 데이터 병렬성, 혼합 정밀도 훈련 및 FlashAttention과 같은 다양한 최적화 기술을 제공합니다.
  - 이러한 최적화 기술은 훈련 효율성과 속도를 크게 향상시켜 GPU 간 효율적인 분산 훈련을 가능하게 합니다.

- JAX

  - Google에서 개발한 Python 라이브러리로 고성능 머신 러닝 알고리즘을 수행할 수 있도록 해줍니다.
  - 하드웨어 가속 (예: GPU 또는 TPU)을 사용하여 배열에서 계산을 쉽게 수행할 수 있습니다.
  - 자동 미분 및 실시간 컴파일링과 같은 기능을 지원하며 다양한 장치에서 효율적인 계산을 가능하게 합니다.
  
- Colossal-AI

  - HPC-AI Tech에서 개발한 대규모 AI 모델을 훈련하기 위한 딥 러닝 라이브러리입니다.
  - PyTorch를 기반으로 구현되었으며 병렬 훈련 전략의 다양한 컬렉션을 지원합니다.
  - PatrickStar에 의해 제안된 메모리 관리 방법을 사용하여 이질적인 메모리 관리를 최적화할 수 있습니다. 
  - Colossal-AI를 기반으로 한 ColossalChat과 같은 ChatGPT와 유사한 모델도 개발되었습니다.

- BMTrain

  - OpenBMB가 개발한 효율적인 라이브러리로, 대규모 파라미터를 가진 모델을 분산 방식으로 훈련하는 데 중점을 둡니다.
  - 코드의 간결성, 낮은 자원 요구 및 높은 가용성을 강조합니다.
  - 다양한 LLMs를 ModelCenter에 통합하여 개발자가 이러한 모델을 직접 사용할 수 있도록 지원합니다.
  
- FastMoE

  - MoE (혼합 전문가) 모델을 위한 전용 훈련 라이브러리로, PyTorch를 기반으로 개발되었습니다.
  - 효율성과 사용자 친화성을 모두 고려하여 설계되었으며, Transformer 모델을 MoE 모델로 전환하는 과정을 간소화합니다.
  - 훈련 중 데이터 병렬성과 모델 병렬성을 모두 지원합니다.

- vLLM

  - 빠른 추론과 서빙을 위한 메모리 효율적이고 사용하기 쉬운 라이브러리입니다.
  - 빠른 추론을 위해 고성능 CUDA 커널을 최적화하고, PagedAttention을 사용하여 효율적인 어텐션 메모리 관리를 제공합니다.
  - 다양한 디코딩 알고리즘, 텐서 병렬성 및 스트리밍 출력을 지원하며 HuggingFace 모델과 호환되고 OpenAI 호환 API 서버를 제공합니다.

- DeepSpeed-MII

  - DeepSpeed가 개발한 메모리 효율적인 Python 라이브러리로, 높은 처리량, 낮은 대기 시간 및 비용 효과적인 LLMs 추론을 중시합니다.
  - Blocked KV 캐싱, 지속적인 배치 처리, 동적 SplitFuse 및 고성능 CUDA 커널을 활용하여 텍스트 생성 추론을 가속화합니다.
  - 현재 LLaMA, Mistral, OPT와 같은 세 가지 인기 있는 모델 아키텍처에서 13,000개 이상의 모델을 지원합니다.

- DeepSpeed-Chat

  - 빠르고 비용 효율적이며 사용하기 쉬운 시스템 프레임워크로, 모델 훈련 중 완전한 RLHF 프로세스를 통합하는 데 사용됩니다.
  - ChatGPT와 유사한 모델의 훈련 및 추론 프로세스를 간소화하고, InstructGPT의 훈련 모드를 복제하여 SFT, 보상 모델 파인튜닝 및 RLHF의 세 가지 훈련 단계를 완벽하게 제공합니다.
  - DeepSpeed 추론에서 다양한 최적화를 활용하여 훈련 및 추론 엔진을 통합하는 통합 하이브리드 엔진 (Deepspeed HE)을 제공합니다.

<div id="PRE-TRAINING"></div>

## PRE-TRAINING

### 대화 데이터

대화 데이터는 LLM의 대화 능력을 강화하고, 다양한 질문-답변 작업의 성능을 향상시킬 수 있습니다.

<br>

온라인 대화 데이터는 종종 여러 참가자 간의 토론을 포함합니다. 이러한 대화를 효과적으로 처리하는 방법은 대화를 트리 구조로 변환하는 것입니다.

<br>

그런데 대화 데이터를 LLM에 과도하게 통합하는 것은 부작용을 초래할 수 있다는 연구가 있습니다.

<br>

모델이 지시문이나 질문을 단순한 대화 개시로만 해석하고, 그 내용에 대한 적절한 반응을 제공하지 못하며 모델이 그 요청을 무시하고 대신 일상적인 대화를 시작할 수 있습니다.

[관련 논문](https://arxiv.org/pdf/2205.01068.pdf)

### tokenizer

일부 언어 모델들(예: OPT와 GPT-3)은 GPT-2의 토크나이저를 그대로 사용합니다. 이는 편리하지만, 모델이 훈련하는 특정 코퍼스의 특성을 완벽히 반영하지 못할 수 있습니다.

<br>

다양한 도메인, 언어, 형식으로 구성된 코퍼스의 경우, 특화된 토크나이저를 개발하는 것이 유익할 수 있습니다.

<br>

최근 언어 모델은 사전 훈련 코퍼스에 특화된 맞춤형 토크나이저를 SentencePiece 라이브러리를 사용하여 훈련합니다. 이 라이브러리는 바이트 레벨의 BPE(Byte-Pair Encoding)와 유니그램 토크나이징 방법을 포함합니다.

<br>

BPE에서 사용되는 정규화 기술은 텍스트를 표준화된 형태로 변환합니다. NFKC(Normalization Form KC)는 문자를 호환성 분해한 다음 합성하는 방식으로, 다양한 문자 변형을 표준 형태로 변환합니다.

<br>

그러나 이러한 정규화 과정은 특정 언어나 문자에 대한 토크나이징 성능을 저하시킬 수 있습니다. 특히, NFKC와 같은 정규화는 언어의 복잡한 문자 구조를 과도하게 단순화시킬 위험이 있습니다.

<br>

결과적으로, 맞춤형 토크나이저는 비영어 데이터를 처리할 때 비효율적일 수 있습니다. 예를 들어, 중국어와 같이 영어와 구조적으로 상이한 언어를 처리할 때 더 긴 추론 지연 시간이 발생할 수 있습니다.

### 데이터 혼합

데이터 혼합은 LLMs의 성능과 범용성을 향상시키기 위해 중요한 역할을 합니다. 

<br>

다양한 데이터 소스를 적절한 비율로 결합함으로써, 모델은 다양한 유형의 텍스트를 이해하고 생성하는 능력을 개발할 수 있습니다. 

<br>

이러한 방법은 모델이 실제 세계의 다양한 언어적 상황에 더 잘 대응할 수 있게 합니다.

<br>

#### 데이터 소스 다양성 증가

<br>

한 특정 도메인에 대한 과도한 데이터로 훈련할 경우, LLMs의 다른 도메인에 대한 일반화 능력이 저하될 수 있다는 것이 연구를 통해 밝혀졌습니다.

[관련 논문](https://arxiv.org/pdf/2112.11446.pdf), [관련 논문](https://arxiv.org/pdf/2211.09085.pdf)

<br>

일부 연구에서는 각 데이터 소스를 하나씩 제거하는 방식으로 실험을 수행하고, 특별히 준비된 데이터셋으로 LLMs를 사전 훈련시켜, 다양한 데이터 소스의 영향을 조사했습니다.

[관련 논문](https://arxiv.org/pdf/2305.13169.pdf), [관련 논문](https://arxiv.org/pdf/2308.12284.pdf), [관련 논문](https://arxiv.org/pdf/2309.10818.pdf)

<br>

또한, 웹 페이지와 같은 고이질성 데이터 소스를 제거하면 학술 코퍼스와 같은 저이질성 데이터 소스를 제거하는 것보다 LLMs의 능력에 더 심각한 영향을 미친다는 사실이 밝혀졌습니다.

*고이질성(high heterogeneity): 웹 페이지와 같은 데이터 소스는 다양한 주제, 스타일, 형식을 포함하여 매우 다양하고 복잡한 정보를 제공

*저이질성(low heterogeneity): 학술 코퍼스와 같은 데이터 소스는 보다 한정된 주제와 형식을 가지고 있어 상대적으로 이질성이 낮음

<br>

#### 데이터 혼합 최적화

<br>

데이터 혼합을 수동으로 설정하는 것 외에도, 모델 사전 훈련을 개선하기 위해 데이터 혼합을 최적화하는 방법이 제안되었습니다.

<br>

target downstream tasks가 주어지면, feature space에서 목표 downstream task와 근접한 데이터를 선택하거나,

[관련 논문](https://arxiv.org/pdf/2302.03169.pdf)

<br> 

downstream tasks에 긍정적인 영향을 제공하는 데이터를 선택할 수 있습니다.

[관련 논문](https://arxiv.org/pdf/2305.12816.pdf)

<br> 

"DoReMi"라는 연구에서는 다양한 데이터 도메인(예: 뉴스, 과학, 문학 등)을 혼합하여 작은 모델을 학습 시켜, 가장 바람직한 혼합 찾아 큰 모델을 학습시키는 방법을 제안합니다.

[관련 논문](https://arxiv.org/pdf/2305.10429.pdf)

<br> 

그러나 이 접근 방식의 가정은 비슷한 방식으로 학습할 때 작은 모델이 모델 능력이나 행동 면에서 큰 모델과 유사할 것이라는 가정이며, 이는 실제로 항상 유지되지는 않습니다.

<br> 

#### LLM의 특정 능력을 향상시키기 위한 데이터 선택 및 혼합 전략

<br> 

LLM의 모델 용량은 데이터 선택 및 혼합에 크게 의존하며 특정 모델 능력을 향상시키기 위해 특정 데이터 소스의 비율을 높일 수 있습니다.

[관련 논문](https://arxiv.org/pdf/2112.11446.pdf), [관련 논문](https://arxiv.org/pdf/2305.13169.pdf)

<br>

LAMBADA 데이터세트에 대한 실험 결과는 책 데이터의 비율을 늘리면 텍스트의 장기적인 의존성을 포착하는 능력을 향상시킨다는 결과가 있습니다.

*장기적인 의존성: 문서의 시작 부분에 나온 주제나 개념이 문서의 끝 부분에서 다시 언급될 때, 이 두 부분 사이의 연관성을 파악하는 것

[관련 논문](https://arxiv.org/pdf/1606.06031.pdf)

<br>

C4 데이터셋의 비율을 늘리면, 모델의 일반화 능력을 검증하는 C4 검증 데이터셋에서 좋은 성능을 낸다는 연구 결과도 있습니다.

*C4 데이터셋: 다양한 웹 소스에서 수집된 방대한 양의 텍스트로 구성

<br>

#### Data Curriculum

<br>

데이터 커리큘럼은 교육의 커리큘럼 개념에서 영감을 받은 것으로, 모델 학습 과정에서 데이터를 특정 순서로 제공하는 방법을 의미합니다.

<br>

특정 기술을 배우기 위해 기술 세트 순서(예: 기본 기술 → 대상 기술)로 학습하는 것이 대상 기술에만 초점을 맞춘 코퍼스에서 직접 학습하는 것보다 성능이 우수한 것으로 나타났습니다.

<br>

다양한 Data Curriculum을 적용한 연구를 아래 소개합니다.

[관련 논문](https://arxiv.org/pdf/2307.14430.pdf), [관련 논문](https://arxiv.org/pdf/2308.12950.pdf), [관련 논문](https://arxiv.org/pdf/2310.02263.pdf), [관련 논문](https://arxiv.org/pdf/2307.03170.pdf)

<br>

#### 추가적인 Tip

<br>

사전 훈련 데이터에는 웹 페이지, 코드, 책, 과학 논문 등과 같은 다양한 고품질 텍스트를 포함하는 것이 권장됩니다.

<br>

특화된 LLM을 훈련할 경우, 해당 기술과 관련된 데이터 소스의 비율을 증가시키는 것이 유용합니다.

(Gopher와 Chinchilla는 책 데이터 약 40%, PaLM 및 LaMDA는 약 50%의 대화 데이터)

<br>

다양한 소스에서 수집된 데이터는 서로 다른 형식을 가질 수 있습니다. 이를 통일하거나 명확하게 지정함으로써, 모든 데이터가 모델에 의해 동일한 방식으로 처리될 수 있습니다.

[관련 논문](https://arxiv.org/pdf/1808.06226.pdf)

### Architecture

#### Prefix Decoder Architecture

<br>

prefix 토큰에 대해서만 양방향 주의(Bidirectional Attention)를 적용합니다.

*prefix 토큰: 입력 시퀀스의 시작 부분에 해당하는 토큰

<br>

디코딩 부분(토큰 생성)은 단방향 주의(Unidirectional Attention)만 적용됩니다.

<br>

사전 학습에서 동일한 토큰을 학습했을 때 Causal Decoder Architecture 보다 언어 모델링 능력은 떨어집니다.

<br>

#### Emergent Architectures

<br>

전통적인 트랜스포머 아키텍처는 입력이 길어질 때 계산 복잡도가 제곱에 비례하여 증가하는 문제가 있습니다. 이러한 문제를 해결하고 효율성을 높이기 위해, 여러 연구들이 새로운 아키텍처를 개발하고 있습니다.

<div id="Model Training"></div>

## Model Training

### 배치 크기

언어 모델 사전 훈련을 위해 기존의 작업은 훈련의 안정성과 처리량을 향상시키기 위해 일반적으로 큰 배치 크기를 설정합니다. (2,048 또는 4M 토큰)

<br>

GPT-3, PaLM과 같은 LLMs에서는 훈련 중에 배치 크기를 동적으로 증가시키는 새로운 전략을 도입했습니다. 

<br>

이는 훈련 초기에는 상대적으로 작은 배치 크기로 시작하여 점차적으로 증가시키며, 최종적으로는 백만 단위의 배치 크기에 도달합니다.

<br>

구체적으로, GPT-3의 경우 배치 크기가 처음에는 32K 토큰에서 시작하여 점차 3.2M 토큰까지 증가합니다.

<br>

dynamic schedule of batch size 대규모 언어 모델의 훈련 과정을 안정화시키는 데 효과적입니다. 

<br>

이는 초기에는 작은 배치 크기를 사용하여 모델이 더 민감하게 학습하도록 하고, 훈련이 진행됨에 따라 큰 배치 크기를 사용하여 안정성을 증가시킵니다.

[관련 논문](https://arxiv.org/pdf/2204.02311.pdf)

### Learning Rate

#### warm-up

<br>

훈련의 초기 단계(대략 훈련 스텝의 0.1%에서 0.5% 사이)에서는 linear warm-up schedule이 사용

<br>

이 단계에서 학습률은 점진적으로 최대값까지 증가합니다. 최대 학습률은 대략 $5 × 10^{−5}$에서 $1 × 10^{−4}$ 사이로 설정됩니다(예를 들어, GPT-3의 경우 $6 × 10^{−5}$).

<br>

#### decay

<br>

초기 웜업 이후, cosine decay strategy이 적용되어 학습률을 점차적으로 감소시킵니다.

<br>

최종적으로 학습률은 최대값의 약 10%까지 감소하며, 이는 훈련 손실의 수렴까지 지속됩니다.

<br>

#### Optimizer

<br>

Adam 옵티마이저 및 AdamW 옵티마이저는 LLMs의 훈련에서 널리 사용됩니다. 

<br>

일반적으로 이러한 옵티마이저의 하이퍼파라미터는 다음과 같이 설정됩니다: 

$β1 = 0.9, β2 = 0.95 및 ϵ = 10^{-8}$

<br>

또한 Adafactor 옵티마이저도 LLMs의 훈련에 사용됩니다. 이것은 GPU 메모리를 보존하기 위해 특별히 설계된 Adam 옵티마이저의 변형입니다.

[관련 논문](https://arxiv.org/pdf/1804.04235.pdf)

<br>

Adafactor 옵티마이저의 하이퍼파라미터는 다음과 같이 설정됩니다: 

$β1 = 0.9, β2 = 1.0 - k^{-0.8}$, 여기서 k는 훈련 단계의 수를 나타냅니다.

<br>

#### 훈련 안정화 방법

<br>

언어 모델 사전 훈련 중에는 종종 훈련 불안정성 문제가 발생할 수 있으며, 이는 모델의 붕괴를 초래할 수 있습니다.

<br>

이러한 문제는 훈련 중에 그래디언트 폭주(gradients exploding) 또는 훈련 손실의 급증(training loss spikes)과 같은 현상으로 나타날 수 있습니다.

<br>

훈련 불안정성 문제를 해결하기 위해 가중치 감쇠(weight decay) 및 그래디언트 클리핑(gradient clipping)과 같은 전략이 널리 사용됩니다.

[관련 논문](https://arxiv.org/pdf/2005.14165.pdf), [관련 논문](https://arxiv.org/pdf/2211.05100.pdf), [관련 논문](https://arxiv.org/pdf/2205.01068.pdf), [관련 논문](https://arxiv.org/pdf/2210.02414.pdf), [관련 논문](https://arxiv.org/pdf/2201.11990.pdf)

<br>

기존 연구들에서는 그래디언트 클리핑의 임계값을 주로 1.0으로 설정하고, 가중치 감쇠 비율을 주로 0.1로 설정합니다. 

<br>

이러한 방법은 훈련 중에 발생할 수 있는 폭주하는 그래디언트를 제한하고 가중치를 정규화하여 훈련의 안정성을 높이는데 도움이 됩니다.