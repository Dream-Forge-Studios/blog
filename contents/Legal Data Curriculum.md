---
date: '2023-12-16'
title: 'Legal Data Curriculum'
categories: ['LLM', 'Legal']
summary: '고성능의 법률 도메인 특화 LLM을 만들기 위한 Data Curriculum의 관한 연구'
thumbnail: './test.png'
---

<br>

<br>

본 내용은 법률 분야에 특화된 언어 모델(Legal Language Model, LLM)을 개발을 위한 Data Curriculum에 관한 연구입니다. 

<br>

Data Curriculum란,  LLM이 학습 데이터를 어떤 방식으로 결합하고, 제공되는 순서에 따라 모델의 성능이 변화할 수 있다는 개념에 기반한 연구입니다.

<br>

기존 연구에서 법률 Task와 관련한 Data Curriculum 연구가 많이 부족한 실정입니다. 이번 연구를 통해 법률 LLM 발전에 기여하고 싶습니다.

<br>

본 llm이 잘 수행했으면 하는 태스크는 사건과 관련된 법률 찾기, 사건과 관련된 판례 찾기, 법적 판단 입니다.

<br>


본 연구는 소규모 데이터 세트를 활용하여 진행됩니다. 방대한 학습 데이터를 사용할 경우 모델의 정확도는 향상될 수 있지만, 그로 인해 학습 시간이 지나치게 길어지는 문제에 직면합니다.

<br>

따라서, 본 연구에서는 DoReMi 연구를 참고하여 초기에는 소량의 데이터를 사용한 연구를 진행한 뒤, 이후에 대규모 데이터로 모델을 학습시키는 접근 방식을 채택합니다.

[관련 논문](https://arxiv.org/pdf/2305.10429.pdf)

<br>

#### 학습 방법

<br>

Mistral-7B-Instruct-v0.1을 기반으로 한국어에 특화한 Synatra-7B-v0.3-dpo를 base model로 4비트 양자화와 LORA를 활용하였습니다.

<br>

gpt의 발전과정에서 영감을 받아 Causal language modeling을 통한 사전학습 방식으로 학습을 진행합니다.

<div id="판례 데이터"></div>

# 판례 데이터

본 연구에서 판례데이터를 활용하여 연구를 진행합니다. 판례 데이터는 법률 분야에서 신뢰도가 높으며, 접근성이 우수한 자료입니다.

<br>

그러므로 법률 LLM 개발에 있어 판례 데이터의 효과적 활용이 핵심적인 요소로 작용합니다.

<br>

위에서 언급했듯이 DoReMi 연구를 참고하여, 소규모 데이터 세트를 활용하여 연구를 진행합니다. 구체적으로는 민사 판례 중 임금 사건에 관련된 데이터만을 대상으로 학습을 진행합니다.

[연구 Datasets](https://huggingface.co/datasets/joonhok-exo-ai/korean_law_open_data_precedents)

<div id="사건과 관련된 법률 찾기"></div>

## 사건과 관련된 법률 찾기

### 법률이 데이터 내에서 나타나는 빈도 조사

제공된 판례 데이터 내에 어떤 법률이 얼마나 자주 등장하는지 분석합니다.

<br>

이 과정을 통해, 모델이 어떤 법률을 학습했는지 확인할 수 있습니다. 또한, 다양한 법률이 데이터 내에서 나타나는 빈도에 따라 모델의 성능 변화를 관찰하고 평가할 수 있습니다.

<img style="width: 100%; margin-top: 40px;" id="output" src="legalData/figure_1.PNG">

### 법률이 데이터 내에서 나타나는 빈도에 따른 영향

조사한 데이터의 법률 빈도 수를 통해 빈도 수의 따른 영향을 연구합니다.

<br>

#### 연구 내용

1. 데이터에서 법률 빈소 수가 몇 번 이상이어야 모델이 해당 법률을 익힐 수 있는가?

임금 판례 데이터의 법률 빈도 수를 조사해보니 1개 ~ 92개까지 다양하게 분포되어 있습니다. 이 부분에서는 법률의 빈도수가 몇번 이상이어야 모델이 법률을 익힐 수 있는지를 관찰합니다.

<br>

구체적인 연구 내용으로는

- 학습데이터 양을 조작하지 않고 그대로 냅둔 상태에서 법률 빈도 수가 몇 개 이상이 되어야 모델이 해당 법률을 익힐 수 있는지
  - 빈도수에서 가장 많은 것 기준으로 근로기준법과 근로기준법이 아닌 법 2개/가장 적은 것 기준으로 근로기준법과 근로기준법 아닌 법 2개 총 6개를 랜덤으로 선택해서 질문을 만든다.
- 빈도수를 동일하게 했을 때 몇개가 적절한지
- 파라미터에 따른 답변에 변화
- 법률 추출 vs 그냥 이유만
  - lawsuit-7B-civil-wage-a vs / lawsuit-7B-civil-wage-f vs lawsuit-7B-civil-wage-reason-f
- 데이터 수에 따른 모델의 사고

를 평가합니다.

<br>

#### Evaluation

<br>

위의 연구 내용을 어떻게 평가할지에 대한 내용입니다.

- 평가 질문 생성

평가 질문 생성은 [Zhen Wan ET AL. (2023)](https://arxiv.org/pdf/2310.03328.pdf)의 연구, 즉 GPT-4가 법률 관련 정보 제공 시 정확한 판단을 내릴 수 있다는 연구를 바탕으로 GPT-4를 활용하여 진행됩니다.

<br>

구체적인 프롬프트:

```
{법률명}

{법률 설명}

법률 LLM을 테스트하기 위한 데이터를 만들고 있는데, 위의 법과 관련된 사건 3가지만 만들어줘
```

- 평가 항목
1. 정답 법률을 올바르게 찾았는지
2. 정답은 아니지만 논리적으로 맞는지

#### Result

- 학습데이터 양을 조작하지 않고 그대로 냅둔 상태에서 법률 빈도 수가 몇 개 이상이 되어야 모델이 해당 법률을 익힐 수 있는지
  - 학습데이터의 양을 조작하지 않고 그대로 사용하니 법률 빈도가 크게 차이가 나서 질문 내용과 상관없이 많은 빈도수의 법률 답변을 하는 경향이 있었습니다.
  - 이는 뒤에 올 말을 예측하는 Causal language modeling을 통해 사전학습을 하였으므로 당연한 결과일 수 있습니다.
  - 이러한 경향성을 고려하여 이후 학습 데이터 내에서 법률의 빈도수를 균등하게 조정하여 연구를 진행하였습니다.
- 빈도수를 동일하게 했을 때 몇개가 적절한지
  1. 법률 빈도수가 1인 데이터만
    - 법률 빈도수가 1인 데이터만을 학습하고 싶었지만, 

### 판례 데이터 제공 순서

판례 데이터는 참조 조문, 참조 판례, 판시 사항, 판결 요지, 전문으로 구성되어 있습니다.

<br>

간단히 설명하면, 참조 조문, 참조 판례, 판시 사항, 판결 요지는 전문의 내용을 주제별로 요약하거나 키워드를 추출한 것으로 볼 수 있습니다.

<br>

이 연구에서는 판례 데이터를 크게 두 부분, 즉 (참조 조문, 참조 판례, 판시 사항, 판결 요지)과 전문으로 나누어, 이들을 제공하는 순서를 달리함으로써 모델의 성능 변화를 관찰했습니다.