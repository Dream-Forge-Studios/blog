---
date: '2024-06-14'
title: 'Modular Deep Learning TEMP'
categories: ['LLM']
summary: 'Adapter Modular의 종류에 대한 상세한 이해를 통해 원하는 Task에 맞게 적절하게 fine tuning 해보자'
thumbnail: './test.png'
---

<div id="Introduction and Motivation"></div>

# Introduction and Motivation

최근 연구에서는 명시적으로 모듈식으로 설계된 신경망에 대한 연구가 활발히 진행되고 있습니다. 이러한 접근 방식은 기능적 특화뿐만 아니라 재사용성과 구성 가능성까지 달성하는 것을 목표로 합니다.

1. 모듈 식별

신경망에서 다른 파라미터에 영향을 주지 않고 개별적으로 업데이트할 수 있는 모듈을 식별합니다.

2. 라우팅 함수

각 입력 예시나 작업에 대해 적절한 모듈을 선택하는 함수를 정의합니다.

3. 집계 함수

활성화된 모듈의 출력을 통합하는 함수를 정의합니다.

### 모듈식 신경망 아키텍처의 주요 이점

1. Positive Transfer

    - 개념: 비슷한 기능을 동일한 모듈로 처리하여 지식 전달을 촉진하고, 각 기능을 별도의 모듈에 할당하여 간섭과 망각을 방지합니다.
    - 예시:
      - 다국어 Transformer 모델: 여러 언어를 동시에 처리하는 모델은 각 언어별 손실 함수의 경사도 간 충돌로 인해 "다국어의 저주"를 겪을 수 있습니다. 이를 해결하기 위해 각 언어에 특화된 모듈을 추가하여 긍정적인 전이를 유도할 수 있습니다.
      - 범용 다중 모달 에이전트: 시각, 언어, 행동 등 다양한 모달을 처리하는 범용 에이전트 개발 시, 모듈화를 통해 각 모달에 특화된 모듈을 설계하고 효율적으로 통합할 수 있습니다.

  2. Compositionality
     - 개념: 다른 기술(작업 수준) 또는 특징(예시 수준)을 나타내는 모듈을 조합하고 개별적으로 업데이트할 수 있습니다.
     - 체계적 일반화의 두 가지 측면:
       - 재구성(Zero-Shot Transfer): 학습된 기술의 새로운 조합으로 구성된 작업이나 관찰된 특징의 새로운 조합으로 구성된 예시에 대해 모듈을 재구성하여 적용합니다. 예: Guaraní 언어와 의존성 파싱에 대한 모듈을 각각 학습한 후, 이를 조합하여 Guaraní 언어에 대한 의존성 파싱을 수행할 수 있습니다.
       - 강건성: 모듈이 독립적이고 재사용 가능한 물리적 메커니즘에 해당하는 경우, 특정 기술이나 특징에 영향을 미치는 분포 변화에 대해 해당 모듈의 매개변수만 업데이트하면 됩니다. 나머지 모델은 변화에 영향을 받지 않습니다.
       
  3. Parameter Efficiency
     - 개념: 모듈별로 학습을 수행하므로 새로운 작업에 모델을 적용하기 위해 필요한 학습 데이터의 양을 줄일 수 있습니다.
     - 이점: 적은 수의 예시만으로도 모델을 새로운 작업에 효과적으로 적응시킬 수 있습니다.
  
  4. Parameter and Time Efficiency
     - 어댑터를 통한 저장 공간 절약: 전체 모델을 복사하는 대신, 특정 작업에 맞춰진 모듈식 어댑터만 저장하면 됩니다. 이는 일반적으로 큰 모델의 저장 공간을 크게 절약할 수 있습니다.
     - 조건부 계산 (Conditional Computation): 작업 복잡도에 따라 필요한 모듈만 동적으로 추가하거나 제거하여 모델 용량을 조절할 수 있습니다. 이는 불필요한 계산을 줄여 시간 효율성을 높입니다.
     - 언어 모델 확장성: 모듈식 접근 방식을 통해 언어 모델은 동일한 시간 복잡도를 유지하면서 더 많은 매개변수를 처리할 수 있습니다. 예시 당 적은 수의 supervised 모듈만 선택하여 사용하기 때문입니다

### 모듈식 딥러닝의 통합적 관점

1. 모듈 구현 방식 (Module Implementation)

최소 계산 단위인 모듈을 어떻게 구현하는지에 대한 다양한 방법을 논의합니다. sparse subnetworks, adapter layers, and prefix tuning 등이 이에 해당합니다. 

<br>

이러한 방법은 대규모 사전 학습 모델을 효과적으로 적응시키는 데 유용하며, 인컨텍스트 학습과 같은 대안보다 더 나은 성능과 샘플 효율성을 제공합니다. 모듈은 사람이 설계한 프롬프트 형태로도 구현될 수 있습니다.

2. 활성 모듈 선택 방식 (Routing Function)

각 예시 또는 작업에 대해 어떤 모듈을 활성화할지 결정하는 라우팅 함수에 대해 다룹니다.

3. 모듈 출력 집계 방식 (Aggregation Function)

활성화된 모듈의 출력을 어떻게 통합하여 최종 결과를 생성하는지에 대한 다양한 방법을 설명합니다.

4. 모듈 및 모델 학습 방식 (Training)

모듈과 나머지 모델을 함께 학습하는 방법에 대해 논의합니다.

<div id="Modular Deep Learning"></div>

# Modular Deep Learning

<div id="Taxonomy"></div>

## Taxonomy

1. 계산 함수 (Computation Function)
   - 모듈의 구현 방식에 초점을 맞춥니다.
   - 모델 전체 또는 특정 레이어를 복사하여 모듈을 구성하는 방법, 사전 학습된 가중치를 사용하는 방법 등이 있습니다.
   - 사전 학습된 가중치를 사용하는 경우, 매개변수 수정, 입력 특징 연결, 함수 합성 등으로 세분화할 수 있습니다.
2. 라우팅 함수 (Routing Function)
   - 활성화될 모듈을 선택하는 방식에 초점을 맞춥니다.
   - 고정 라우팅: 사전에 정의된 규칙에 따라 모듈을 선택합니다.
   - 학습된 라우팅: 학습 과정에서 라우팅 함수의 매개변수를 조정하여 모듈을 선택합니다.
   - 소프트 라우팅: 모든 모듈을 연속적인 점수로 평가하여 활성화 정도를 결정합니다.
   - 하드 라우팅: 각 모듈을 활성화 또는 비활성화하는 이진 점수를 부여합니다.
3. 집계 함수 (Aggregation Function)
   - 활성화된 모듈의 출력을 통합하는 방식에 초점을 맞춥니다.
   - 결정론적 방법: 가중 평균과 같은 미리 정의된 규칙에 따라 출력을 결합합니다.
   - 학습 가능한 신경망: 모든 모듈의 출력을 입력으로 받아 학습 가능한 신경망을 통해 출력을 집계합니다.
4. 훈련 설정 (Training Setting)
   - 모듈과 모델 전체의 학습 방식에 초점을 맞춥니다.
   - 다중 작업 학습: 모듈과 공유 가중치를 함께 학습합니다.
   - Continual Learning: 새로운 작업마다 새로운 모듈을 추가하여 학습합니다.
   - 사후 통합: 사전 학습된 모델에 모듈을 추가하고 미세 조정을 통해 학습합니다.

<div id="Notation"></div>

## Notation

### 기본 개념

  - 신경망 $f_θ$: 입력 $X$를 받아 출력 $Y$를 생성하는 함수이며, 각각 고유한 매개변수 $θ_i$를 가진 $l$개의 하위 함수(레이어)로 구성됩니다.
  - 예시: 트랜스포머 레이어는 선형 매핑, 비선형 피드포워드 네트워크, 잔차 연결 등으로 구성됩니다.
  - 모듈 $f_ϕ$: 매개변수 $ϕ$를 가진 추가적인 함수로, 기존 신경망의 특정 레이어에 적용되어 기능을 수정합니다.
  - $M_i$: 특정 레이어 $i$에 적용 가능한 모듈들의 집합을 나타냅니다.

### 모듈 조합 방법:

- 파라미터 합성 (Parameter Composition)

  - 수식: $f'_i(x) = f_{(θ_i⊕ϕ)}(x)$ (⊕는 파라미터 조합 연산, 예: element-wise addition)
  - 설명: 기존 레이어의 매개변수 $θ_i$와 모듈의 매개변수 $ϕ$를 조합하여 새로운 함수 $f'_i$를 생성합니다.
  - 예시: Low-Rank Adaptation, Sparse Adaptation
  
- 입력 합성 (Input Composition):

  - 수식: $f'_i(x) = f_{θ_i}([ϕ, x])$ ($[·, ·]$는 연결 연산)
  - 설명: 모듈의 출력 ϕ를 기존 레이어의 입력 x에 연결하여 새로운 입력을 생성하고, 이를 기존 함수 fθi에 적용합니다.
  - 예시: Prefix Tuning

- 함수 합성 (Function Composition):

  - 수식: $f'_i(x) = f_ϕ ◦ f_{θ_i}(x)$ ($◦$는 함수 합성 연산)
  - 설명: 기존 레이어의 함수 f_{θ_i}를 먼저 적용한 후, 그 결과를 모듈의 함수 $f_ϕ$에 입력으로 사용하여 최종 출력을 얻습니다.
  - 예시: 어댑터 레이어 (Adapter Layer)


### Routing Function

- 역할: 각 하위 함수(레이어)에 대해 여러 모듈 중 어떤 모듈을 선택할지 결정합니다.
- 입력: 데이터 (예: 언어 토큰, 시각 영역, 전체 입력) 또는 메타데이터 (예: 작업 유형)
- 출력: 각 모듈에 대한 점수 $ \alpha _j$ ($ \alpha $는 사전에 고정되거나 학습을 통해 얻을 수 있음)
- 종류:

  - 하드 라우팅: $α ∈ {0, 1}^{|M|}$ (이진 벡터), 선택된 모듈만 활성화
  - 소프트 라우팅: $α ∈ [0, 1]^{|M|}$ (확률 분포), 모든 모듈이 활성화되지만 가중치가 다름
  - 비정규화 점수 벡터: $α ∈ R^{|M|}$, 선형 하이퍼네트워크에서 사용

### Aggregation Function

- 역할: 활성화된 모듈의 출력을 결합하여 최종 결과를 생성합니다.
- 종류:
  - 결정론적 연산: 가중 평균 등 라우팅 점수를 기반으로 출력을 결합
  - 학습 가능한 신경망: 어텐션 메커니즘 등을 사용하여 모듈 입력과 출력을 고려하여 출력을 결합

### 전체 작동 방식 (Algorithm 1)

1. 공유 매개변수 $θ_i$ ($i$번째 하위 함수)와 모듈 $M_i$가 주어집니다.
2. 작업 $t$와 입력 $x$를 샘플링합니다.
3. 라우팅 함수 $r(·)$를 통해 라우팅 점수 $α$를 얻습니다.
4. 각 모듈 $ϕ_j$에 대해 숨겨진 표현 $h_j$를 계산합니다.
5. 집계 함수 $g(·)$를 사용하여 $h_j$를 집계하여 출력 $y$를 생성합니다.

<img style="width: 50%;" src="modular/Algorithm1.PNG">

<br>

<img style="width: 80%;" src="modular/Table1.PNG">

<div id="Computation Function"></div>

# Computation Function

<img style="width: 100%;" src="modular/figure2.PNG">

<br>

모듈은 다양한 형태로 설계될 수 있습니다. transfer learning에서는 대부분 사전 학습된 모델의 파라미터를 공유하는 방식으로 모듈을 통합합니다.

1. 파라미터 합성 (Parameter Composition)

- 기존 모델의 파라미터에 모듈의 파라미터를 더하거나 곱하는 등의 연산을 통해 통합합니다.
- 예시: 저랭크 어댑터(LoRA), 희소 어댑터(Sparse Adapters)

2. 입력 합성 (Input Composition)

- 모듈의 출력을 기존 모델의 입력에 연결하여 통합합니다.
- 예시: Prefix Tuning

3. 함수 합성 (Function Composition)

- 기존 모델의 함수와 모듈의 함수를 순차적으로 실행하여 통합합니다.
- 예시: 어댑터 레이어 (Adapter Layers)

<div id=" Parameter Composition"></div>

## Parameter Composition

- 핵심 개념

    - 기본 모델 $f_W$: 입력 $x$를 받아 출력 $y$를 생성하는 함수 $f_W$가 존재합니다. $W$는 모델의 가중치 행렬로, 입력 차원 $i$와 출력 차원 $o$를 가집니다. $(W ∈  \mathbb{R}^{o×i})$
    - 모듈 $Φ$: 기본 모델에 추가적인 기능을 제공하는 어댑터 모듈로, $Φ$는 모듈의 가중치 행렬입니다. $(Φ ∈ \mathbb{R}^{o×i})$
    - 파라미터 합성 ($⊕$): 기본 모델의 가중치 W와 모듈의 가중치 $Φ$를 element-wise addition(원소별 덧셈) 연산을 통해 결합하여 새로운 함수 $f_{W⊕Φ}$를 생성합니다.

어댑터 모듈은 기본 모델 전체를 복제하지 않고 작은 변경만을 통해 특정 작업에 적응하도록 설계되었습니다. 따라서 어댑터의 매개변수 Φ는 희소 행렬(Sparse matrix) 또는 저랭크 행렬(Low-rank matrix) 형태를 가집니다. 

<br>

이를 통해 모델의 매개변수 효율성을 높이고 학습 및 저장 비용을 줄일 수 있습니다.

### Sparse Subnetworks

Sparse Subnetworks는 다음 두 가지 가정에 기반한 접근 방식입니다.

1. 과잉 매개변수화된 모델에서 특정 작업에 관련된 매개변수는 소수에 불과하다: 대부분의 딥러닝 모델은 필요 이상으로 많은 매개변수를 가지고 있으며, 실제로 특정 작업 수행에 중요한 역할을 하는 매개변수는 적다는 것입니다.
2. 유사한 작업은 유사한 하위 네트워크를 공유한다: 예를 들어, 다국어 언어 모델에서 특정 언어에 대한 하위 네트워크는 다른 언어에도 유사하게 적용될 수 있다는 것입니다.

- 가지치기 (Pruning): 희소성을 유도하는 가장 일반적인 방법은 pruning입니다.
  - 이진 마스크 (Binary Mask): 학습된 모델의 각 연결을 유지하거나 제거하는 이진 마스크 $b ∈ \left\{0,1 \right\}^{|θ|}$를 적용합니다. 여기서 $θ$는 모델의 파라미터이고 $|θ|$는 파라미터의 개수입니다.
  - 희소 부분 네트워크 생성: 마스크를 적용하여 0으로 설정된 연결을 제거하면 희소 부분 네트워크가 생성됩니다.
  - 밀집 모델 유지: 하드웨어 및 소프트웨어적인 이유로 실제 모델 파라미터는 희소 행렬로 변환되지 않고 밀집 행렬 형태를 유지합니다.

가지치기는 다음과 같은 기준을 사용하여 수행할 수 있습니다.

1. 수렴 후 크기 (Magnitude after convergence): 학습이 완료된 후 가중치의 절대값이 작은 연결을 제거합니다.
2. 초기화와 수렴 사이의 크기 변화 (Change of magnitude between initialization and convergence): 학습 전후 가중치 변화량이 작은 연결을 제거합니다.

신경망에서 pruning 기법을 사용하여 sparse subnetworks를 생성하고, 이러한 sparse 네트워크가 원본 모델과 비슷하거나 더 나은 성능을 보일 수 있다는 Lottery Ticket Hypothesis (LTH) 연구가 있습니다.

<br>

pruning는 일반적으로 모델의 연결을 변경하여 성능 저하를 야기할 수 있습니다. 이를 완화하기 위해 pruning 후, 제거되지 않은 가중치는 초기값으로 되돌리고 재학습을 수행합니다.

<br>

실제로는 한 번에 모든 가중치를 pruning하는 대신, 여러 단계에 걸쳐 반복적으로 pruning를 수행합니다. 이렇게 pruning된 모델은 원본 모델의 성능을 유지하거나 능가하는 경우가 많습니다.

<br>

LTH는 무작위로 초기화된 모델에서 가지치기를 통해 원본 모델과 비슷하거나 더 나은 성능을 보이는 하위 네트워크(winning ticket)가 존재한다는 가설입니다.

<br>

winning ticket이 무작위 초기화 상태에서 고정된 채로 사용되어도 임의 성능 이상의 결과를 얻을 수 있는 경우, 이를 supermask라고 합니다.

<br>

winning ticket은 사전 학습된 모델에서도 존재합니다. 사전 학습된 모델에서 얻은 winning ticket은 무작위로 초기화된 모델에서 얻은 것보다 성능이 우수하고 특정 하이퍼파라미터 선택에 덜 민감합니다.

<br>

fine-tuning 후에도 가중치는 사전 학습된 값과 비슷합니다. 그래서 절대값 기반의 Magnitude pruning은 하위 작업에 관계없이 유사한 가중치를 선택하는 경향이 있습니다.

<br>

이러한 문제를 해결하기 위해 gradient-based pruning을 활용하여 각 가중치의 작업별 관련성을 더 잘 포착할 수 있습니다.

<br>

예를 들어, Movement Pruning은 가중치의 변화량을 기반으로 중요도를 판단합니다. 

<br>

Movement Pruning은 가중치(θ)와 함께 이진 마스크(b)를 학습합니다. 이 마스크는 각 가중치를 유지할지 제거할지를 결정하는 역할을 합니다.

<br>

그런데, 마스크는 이진 변수(0 또는 1)이므로 미분이 불가능합니다. 따라서, 역전파 과정에서 마스크를 미분 가능한 형태로 근사하는 Straight-Through Estimator를 사용합니다.

<br>

마스크를 처음부터 이진 변수가 아닌 실수 값으로 학습한 후, 임계값(threshold)을 기준으로 이진화하는 방법도 사용할 수 있습니다.

<br>

#### 희소 미세 조정 (Sparse Fine-Tuning, SFT)

<br>

Lottery Ticket Hypothesis (LTH)를 재활용하여, 크기 변화가 가장 작은 가중치를 제거하는 대신, 해당 가중치를 고정시킵니다. 즉, 일부 가중치만 미세 조정하는 방법도 있습니다.

<br>

#### Diff Pruning

<br>

밀집된 차이 벡터 ϕ를 미세 조정하고 L0-norm 페널티에 대한 미분 가능한 근사를 사용하여 희소성을 유도하여 희소 어댑터를 얻습니다.

<br>

#### Fisher 정보 기반 가지치기

<br>

Fisher 정보(모델 예측에 대한 매개변수 변화의 영향을 나타내는 2차 정보)를 사용하여 상위 k개 가중치를 선택하고 고정된 희소 마스크를 유도합니다.

<br>

#### 구조적 희소 모델 적응

- 모델의 일부 하위 함수만 미세 조정하고 나머지 파라미터는 고정시키는 방식입니다.
- 가장 일반적인 설정은 특정 레이어(예: 마지막 레이어)만 미세 조정하는 것입니다.
- 더 세분화된 부분(예: 모델의 bias 파라미터)을 조정할 수도 있습니다. 이 경우 모델의 중간 활성화를 저장할 필요가 없어져 효율성이 높아집니다.
- CNN에서는 필터를, 사전 학습된 Transformer에서는 어텐션 헤드를 pruning할 수 있습니다.
- 구조적 diff pruning에서는 그룹의 구성원들이 동일한 마스크 값을 공유하도록 유도합니다.

#### Low-Rank Modules

<br>

sparse와 마찬가지로, 모델 파라미터를 저차원 부분 공간에 위치시키면 매개변수 효율성을 높일 수 있습니다.

<br>

Li et al. (2018) 연구에 따르면, 모델은 전체 파라미터 공간이 아닌 저차원의 무작위 방향 부분 공간에서도 최적화될 수 있습니다.

<br>

모듈 파라미터 $ϕ$는 모델 파라미터 $θ$에 비해 저차원으로 설정합니다. 이에 따라 저차원 공간에서 고차원 공간으로 투영하기 위해 무작위 행렬 $M$을 사용합니다.

<br>

$M$을 계산하는 효율적인 방법은 Fastfood 변환을 사용하는 것입니다. Fastfood 변환은 $M$을 무작위 선형 행렬의 곱으로 분해합니다.

<br>

구체적으로, $M = HGΠHB$로 구성됩니다. 여기서 $H$는 Hadamard 행렬, $G$는 독립적인 표준 정규 항목을 가진 무작위 대각 행렬, $B$는 ±1 항목을 가진 무작위 대각 행렬, $Π$는 무작위 순열 행렬입니다.

<br>

Aghajanyan et al. (2021)은 다양한 NLP 작업에 대한 내재 차원을 조사하여 사전 학습 중에 내재 차원이 감소하고 더 큰 모델이 더 낮은 내재 차원을 갖는다는 것을 발견했습니다.

<br>

저랭크 모듈을 사용하는 것은 딥러닝 모델의 효율적인 적응을 위한 유용한 방법입니다. 특히 LoRA는 모델의 크기를 크게 늘리지 않고도 성능을 향상시킬 수 있는 효과적인 방법으로 주목받고 있습니다.

###  Input Composition

#### Prompt

<br>

모델 입력에 추가적인 정보를 제공하는 텍스트입니다. 선택적으로 지시 사항이나 예시를 포함할 수 있으며, 모델이 원하는 동작을 수행하도록 유도합니다.

<br>

프롬프트의 문구 선택이나 표현 방식에 따라 모델의 성능이 크게 달라질 수 있습니다.

<br>

few-shot 학습에서 예시 선택 및 순서에 따라 모델 성능이 민감하게 변할 수 있습니다.

<br>

#### Continuous Prompts

<br>

이산적인 단어 토큰 대신, 연속적인 벡터 형태의 프롬프트를 사용합니다. 이를 Soft Prompt라고도 합니다.

<br>

텍스트 프롬프트보다 더욱 유연하게 모델의 동작을 제어할 수 있습니다.

<br>

작은 모델에서는 성능이 좋지 않을 수 있으며, 일부 복잡한 작업에서는 성능이 제한될 수 있습니다.

<br>

Multi-layer Prompt Tuning 방식은 모델의 각 레이어에 프롬프트 벡터를 추가하는 방법입니다.

- 모델의 특정 작업에 대한 적응력을 높여 성능을 향상시킬 수 있습니다.
- 매개변수 수가 증가하여 모델의 효율성이 떨어질 수 있습니다.
- 각 멀티 헤드 어텐션 레이어의 키(key)와 값(value)에 프롬프트 벡터 $ϕ_i = P_i^k, P_i^v ∈ R^{l×d}$을 추가합니다.

#### Retrieval Augmentation

<br>

검색 모델에서 가져온 추가적인 정보를 입력에 추가하여 모델의 컨텍스트를 넓힙니다. 매우 적은 수의 매개변수만 추가하므로 효율적입니다.

<br>

모델의 컨텍스트 창을 확장하므로 학습 및 추론 시간이 늘어날 수 있습니다.

### Function Composition

이전에 설명한 방식에서 파라미터 합성은 개별 가중치를 다루고, 입력 합성은 함수의 입력에만 작용하는 반면, 함수 합성은 모델에 새로운 작업 특화적인 하위 함수를 추가합니다.

<br>

함수 합성은 기존 함수 $f_{θ_i}$에 새로운 함수 $f_{ϕ_i}$를 추가하여 $f'i(x)$를 만듭니다. 이때 $f_{ϕ_i}$는 특정 작업에 특화된 기능을 수행합니다. 

<br>

예시: $f'_i(x) = f_{ϕ_i} ◦ f_{θ_i}(x) = f_{ϕi}(f_{θ_i}(x))$ ($◦$는 함수 합성 연산)

### Complex Methods

- 다양한 방법의 결합: 단일 어댑터 메서드들을 조합하여 더욱 강력하고 효율적인 복합 메서드를 만들 수 있습니다.
- ConfigUnion 클래스: Adapters는 ConfigUnion 클래스를 통해 여러 구성 인스턴스를 쉽게 그룹화할 수 있는 유연한 메커니즘을 제공합니다.
- 문헌 속 복합 메서드: Mix-and-Match Adapters (Prefix-Tuning + 병렬 병목 어댑터), UniPELT (LoRA + Prefix Tuning + 병목 어댑터 + 게이트 메커니즘)와 같은 기존 복합 메서드를 쉽게 구현할 수 있습니다.
- 새로운 복합 구성: ConfigUnion을 활용하여 문헌에 아직 등장하지 않은 새로운 복합 구성을 만들고 실험할 수 있습니다.

<div id="Hypernetworks"></div>

## Hypernetworks

Hypernetworks는 모듈 매개변수를 직접 학습하는 대신, 작은 신경망을 통해 생성함으로써 모듈 간 정보 공유를 가능하게 합니다.

<br>

작은 신경망($W$)을 사용하여 모듈 매개변수($ϕ$)를 생성합니다. 이때, 임베딩 벡터($α$)를 조건으로 활용하여 각 작업에 특화된 매개변수를 생성할 수 있습니다.

$ϕ = Wα$ ($W$: 하이퍼네트워크 가중치, $α$: 임베딩 벡터)

<br>

hypernetworks를 통해 생성된 모듈들은 매개변수를 공유하므로, 모듈 간의 정보 교환이 가능해집니다.

<br>

임베딩 벡터($α$)는 각 작업에 대한 비정규화된 라우팅 점수로 해석할 수 있습니다. 즉, 각 작업에 대한 모듈의 활성화 정도를 나타냅니다.

<br>

hypernetworks의 가중치 행렬($W$)은 여러 모듈의 매개변수를 열 방향으로 쌓아놓은 것으로 볼 수 있습니다.

<br>

입력 데이터($x$)를 조건으로 사용하여 모듈 매개변수를 생성할 수도 있습니다.

- 조건부 배치 정규화 (Conditional Batch Normalization): LSTM을 통해 얻은 모델 입력 표현을 기반으로 재조정 매개변수를 생성합니다.
- 특징별 선형 변조 (FiLM): 텍스트-이미지 작업에서 언어 입력을 조건으로 이미지 특징에 적용되는 어파인 변환을 생성합니다.
- 생성적 적대 신경망 (GAN)의 자체 변조: 생성기의 숨겨진 표현에 적용되는 어파인 변환을 노이즈 샘플을 조건으로 생성합니다.
- 일회 학습 (One-shot Learning): 개별 예시를 조건으로 사용하여 매개변수 생성기를 학습합니다.

hypernetworks는 다양한 모듈 매개변수 생성에 사용될 수 있습니다.

- 분류기 헤드 (Classifier heads)
- 연속 프롬프트 (Continuous prompts)
- 어댑터 레이어 (Adapter layers)

주로 작업(task) 또는 언어 임베딩을 조건으로 사용하여 각 작업 또는 언어에 특화된 매개변수를 생성합니다.

<br>

예시 레이블($y$)과 같은 다른 부가 정보도 이항 상호 작용(bi-linear interaction)을 통해 hypernetworks 입력 임베딩에 통합될 수 있습니다.

<br>

매개변수 효율성을 높이기 위해, 작업 인덱스 외에도 신경망 아키텍처 내 모듈 위치를 조건으로 하여 레이어 간에 공유될 수 있습니다.

<br>

또한 작업 인덱스, 언어 인덱스 등 여러 임베딩을 연결하여 조건으로 사용할 수 있습니다. 이를 통해 추론 시 새로운 작업-언어 조합에 체계적으로 일반화할 수 있습니다.

<div id="Unifying Parameter, Input, and Function Composition"></div>

## Unifying Parameter, Input, and Function Composition

본 내용은 딥러닝 모델에 모듈을 통합하는 세 가지 방식(파라미터 합성, 입력 합성, 함수 합성)이 근본적으로 유사한 형태를 공유한다는 점을 설명합니다. 

<br>

He et al. (2022a)의 연구를 확장하여 세 가지 방식 모두 함수 합성 형태로 통합될 수 있음을 보여줍니다.

<br>

모든 모듈 계산 함수는 다음과 같은 함수 합성 형태로 표현될 수 있습니다.

<br>

$f'_i(x) = f_{θ_i}(x) + f_{ϕ_i}(x)$

<br>

- 함수 합성 (Function Composition): 기본적으로 위 형태를 따릅니다.
- 파라미터 합성 (Parameter Composition)

    - 어댑터 함수 $f_{ϕ_i}(x)$를 기존 파라미터 $θ_i$에 대한 함수로 표현하여 위 형태로 변환할 수 있습니다.
    - 모듈 매개변수 $ϕ_i$의 차원이 원래 매개변수 θi의 차원과 정확히 일치해야 합니다.
    - 예: LoRA (Hu et al., 2022)에서 $f_{ϕ_i}(x)$는 $θ_i$에 저랭크 행렬을 추가하는 함수로 볼 수 있습니다.
    - 선형성을 이용하여 $f'_i(x) = f_{θ_i⊕ϕ_i}(x) = f_{W+V}(x) = Wx + Vx = f_{θ_i}(x) + f_{ϕ_i}(x)$로 변환 가능합니다.
  
- 입력 합성 (Input Composition)

    - 어댑터 함수 $f_{ϕ_i}(x)$를 입력 $x$에 대한 함수로 표현하여 위 형태로 변환할 수 있습니다.
    - 예: Prefix Tuning (Li & Liang, 2021)에서 $f_{ϕ_i}(x)$는 입력 $x$에 prefix를 추가하는 함수로 볼 수 있습니다.
    - He et al. (2022a) 연구를 통해 Prefix Tuning을 다음과 같은 가중 합산(weighted addition) 형태로 변환할 수 있음을 보였습니다.
      <br>$f'_i(x) = (1 − λ(x))f_{θ_i}(x) + λ(x)f_{ϕ_i}(x)$

모듈 계산 함수를 함수 합성 형태로 통일하여 표현함으로써, 다양한 어댑터 방식을 비교하고 분석하는 것이 용이해집니다. 또한, 어댑터 구현의 유연성을 높이고 새로운 어댑터 방식을 개발하는 데 도움이 됩니다.

<br>

각 방법의 장단점 비교

<br>

<img style="width: 100%;" src="modular/table3.PNG">

<div id="Routing Function"></div>

# Routing Function

이전 섹션에서는 단일 모듈을 공유 가중치와 함께 적용하는 방법을 설명했습니다. 하지만 실제 모듈식 신경망 아키텍처에서는 여러 모듈 중에서 어떤 모듈을 활성화할지 결정하는 라우팅(Routing) 과정이 필요합니다. 이 과정은 모델 입력 또는 보조 메타데이터를 조건으로 하여 이루어집니다.

- 역할: 각 모듈에 대한 점수($α_i$)를 계산하여 활성화될 모듈을 결정합니다.
- 입력: 모델 입력($x$) 또는 보조 메타데이터(예: 작업 유형)
- 출력: 각 모듈에 대한 점수 $α_i$ (이 점수에 따라 활성화될 모듈이 결정됩니다.)

라우팅 방법:

1. 고정 라우팅 (Fixed Routing)

- 사전 지식 활용: 작업에 필요한 하위 작업(또는 기술)에 대한 supervised 지식을 바탕으로 어떤 모듈을 사용할지 미리 결정합니다.
- 예시: 스와힐리어로 대화를 생성하는 언어 모델의 경우, 대화 생성 작업 모듈과 스와힐리어 언어 모듈을 선택할 수 있습니다.

2. 학습된 라우팅 (Learned Routing)

- 데이터 기반 학습: 사전 지식이 없는 경우(예: 레이블이 없는 데이터), 주어진 예시에 대한 라우팅을 학습해야 합니다.
- 조건부 학습: 현재 예시 x를 조건으로 라우팅 함수를 학습합니다.

학습된 라우팅의 문제점:

- 제약 부족: 여러 작업을 하위 작업으로 분해하는 방법이 다양하기 때문에 학습된 라우팅은 제약이 부족할 수 있습니다.
- 과소 활용 및 특화 부족: 학습된 라우팅은 고정 라우팅에 비해 모듈을 덜 활용하고 특화 정도가 낮아지는 경향이 있습니다. 특히 데이터의 작업 수가 증가할수록 이러한 문제가 심화됩니다.
- 성능 문제: 실제 응용 분야에서 학습된 라우팅은 supervised의 모듈 선택보다 성능이 떨어질 수 있습니다. 단, 특정 상황(예: 지시 따르기)에서는 학습된 라우팅이 더 나은 성능을 보일 수도 있습니다.

3. 학습 기반 라우팅 (Learning-to-route)

- supervised 지식 없이 데이터를 기반으로 어떤 모듈을 활성화할지 학습하는 방식입니다.
- 크게 하드 라우팅(Hard Routing)과 소프트 라우팅(Soft Routing)으로 나뉩니다.
  - 하드 라우팅 (Hard Routing)
    - 개념: 고정 라우팅과 유사하게, 각 의사 결정 단계에서 일부 모듈만 선택하는 이진 선택 방식을 학습합니다.
    - 추론 방법: 점수 함수 추정(Score function estimators)이나 확률적 재매개변수화(Stochastic Reparameterization)를 사용합니다.
    - 장점: 선택되지 않은 모듈은 연산에 참여하지 않으므로 계산 복잡도를 줄이고 모델 용량을 늘릴 수 있습니다.
    - 단점: 이산적인 선택으로 인해 미분 불가능 문제가 발생하여 학습이 어려울 수 있습니다.
  - 소프트 라우팅 (Soft Routing)
    - 개념: 모듈에 대한 확률 분포를 학습하는 방식입니다.
    - 장점: 연속적인 값을 사용하므로 경사 하강법(Gradient Descent)을 통한 학습이 용이합니다.
    - 단점: 모든 모듈이 연산에 참여하므로 계산 비용이 높고, 모듈 특화가 어렵습니다.

<div id="Fixed Routing"></div>

## Fixed Routing

고정 라우팅에서는 라우팅 함수 $r(·)$가 단순화되어, 특정 메타데이터를 가진 예시에 대해 특정 모듈 집합 $K ⊆ M$를 선택합니다.

<br>

$A ∈  \left\{ 0, 1\right\}^{|T| × |M|}$ 형태의 이진 행렬로 표현할 수 있습니다. 여기서 $|T|$는 가능한 작업 수, $|M|$는 모듈 개수입니다. 행렬 A의 각 요소는 해당 작업에서 특정 모듈을 사용할지 여부를 나타냅니다 (1은 사용, 0은 사용하지 않음).

<br>

고정 라우팅의 예시: 다중 작업 학습 (Multi-task Learning)

<br>

다중 작업 학습에서 마지막 분류 레이어를 제외한 모든 파라미터를 공유하는 경우가 고정 라우팅의 간단한 예시입니다. 이 경우, 모든 작업에 대해 동일한 네트워크를 통과시키고, 마지막 레이어 직전에서 작업 유형에 따라 각 작업에 해당하는 분류 레이어로 라우팅합니다. 

<br>

즉, 각 작업에 대해 하나의 모듈만 선택($|K| = 1$)하고, 작업 간에 모듈을 공유하지 않도록 제약을 둡니다. 이는 할당 행렬 $A$가 단위 행렬($A = I$)이 되는 것과 같습니다.

<br>

사전 학습된 모델을 개별 작업에 적응시키는 방법들(예: Rebuffi et al., 2017; 2018; Houlsby et al., 2019; Bapna & Firat, 2019; Li & Liang, 2021; Liu et al., 2022b; Hu et al., 2022; Ansell et al., 2022; Ben Zaken et al., 2022)도 고정 라우팅의 한 형태로 볼 수 있습니다. 

<br>

새로운 모듈 $f_ϕ$를 통해 표현을 결정적으로 라우팅하며, 사전 학습된 가중치는 고정됩니다.

1. supervised 모듈의 독립적 학습 (Hampshire & Waibel, 1992)

여러 하위 작업에 대해 독립적인 supervised 모듈을 훈련하는 초기 연구 중 하나입니다.
각 작업 t에 관련된 supervised 모듈의 고정된 크기의 부분 집합 K가 미리 주어지며, 이는 할당 행렬 A의 행이 k-way 벡터가 됨을 의미합니다.

2. 다국어 전이 학습 (Pfeiffer et al., 2020b; Ponti et al., 2021; Üstün et al., 2022)

다국어 전이 학습 문제는 작업과 언어 종류로 분해될 수 있습니다.
고정 라우팅을 통해 언어 및 작업 구성 요소를 분리하여 선택하고, 추론 시 새로운 작업과 언어 조합에 일반화할 수 있습니다.
이 경우, 선택되는 모듈의 수는 2개 ($|K| = 2$)입니다.

3. 강화 학습 (Heess et al., 2016; Devin et al., 2017)

로봇 특정 모듈과 작업 특정 모듈로 구성된 모듈식 정책을 설계합니다.
이러한 모듈을 합성하여 보지 못한 로봇-작업 조합에도 일반화할 수 있습니다.

4. 다국어 언어 모델 (Pfeiffer et al., 2022b):

레이블 없는 텍스트에 대한 사전 훈련 중에 각 언어에 대한 어댑터를 추가합니다.

5. 다국어 기계 번역 (Fan et al., 2021):

언어 계통(language family)에 따라 결정적으로 라우팅하여 동일한 계통의 모든 언어가 동일한 supervised를 공유하도록 합니다.

6. 도메인 특화 어댑터 (Gururangan et al., 2022; Li et al., 2022b):

텍스트 소스 도메인에 따라 결정적으로 라우팅하여 도메인 특화 어댑터를 언어 모델에 추가합니다.
Li et al. (2022b)는 동일한 모델의 복사본을 여러 도메인에서 학습시킨 후 평균을 내는 branch-train-merge 방법을 제안합니다.

7. 시각 및 언어 모델 (Pfeiffer et al., 2022a):

모달 정보를 기반으로 고정 라우팅을 수행하여 다양한 모달 스트림의 인코더를 적응시킵니다.

<div id="Learned Routing"></div>

## Learned Routing

본 내용은 모듈식 딥러닝에서 라우팅 함수(routing function)를 사전에 알 수 없는 경우, 이를 학습 가능한 신경망으로 구현하는 방법에 대해 설명합니다.

<br>

- 학습된 라우팅 함수 $rρ(·)$

    - 개념: supervised 지식 없이 데이터를 기반으로 어떤 모듈을 활성화할지 결정하는 함수입니다.
    - 입력: 모델 입력(x) 또는 작업(t)과 같은 메타데이터를 받습니다.
    - 출력: 각 모듈에 대한 라우팅 점수 α를 반환합니다.
    - 구현: 일반적으로 선형 투영(Linear Projection) 또는 다층 퍼셉트론(Multi-Layer Perceptron, MLP)으로 구현됩니다.
    - 선형 투영: 표현력이 낮지만, 구현이 간단합니다.
    - MLP: 표현력이 높지만, 입력 특징을 무시하고 특정 모듈에만 집중하는 문제가 발생할 수 있습니다. (module collapse)
    - 모듈 특화 학습: 라우팅 함수를 학습하는 것은 각 모듈의 특화 역할 또한 학습함을 의미합니다. 즉, 각 모듈은 별도의 데이터셋으로 학습되는 것이 아니라, 라우팅 함수와 함께 전체 데이터셋을 사용하여 학습됩니다.

### Challenges of Learned Routing

본 내용은 딥러닝 모델에서 학습된 라우팅 방식을 사용할 때 발생하는 문제점과 이를 해결하기 위한 다양한 전략을 설명합니다.

<br>

#### 학습된 라우팅의 문제점

1. 훈련 불안정성 (Training Instability): 훈련 초기 단계에서 모듈들이 무작위로 초기화되어 특화되지 않았기 때문에 라우터가 모듈을 선택하는 데 어려움을 겪습니다. 이로 인해 훈련 과정이 불안정해질 수 있습니다.

2. 모듈 붕괴 (Module Collapse): 소수의 모듈만 선택되어 나머지 모듈은 훈련되지 않는 현상입니다. 이는 탐색(exploration)보다 활용(exploitation)을 지나치게 선호하여 발생하며, 전체적인 성능을 저하시킵니다.

3. 과적합 (Overfitting): 모델이 특정 예시에 지나치게 집중하여 일반화 성능이 떨어지는 현상입니다. 특히 토큰 수준 라우팅을 사용하는 MoE(Mixture-of-Experts) 모델에서 두드러지게 나타납니다.

#### 해결 방안

- 훈련 불안정성 해결

    - 커리큘럼 학습(Curriculum Learning): 간단한 작업부터 점진적으로 어려운 작업을 학습하여 훈련 안정성을 높입니다.
    - 라우터와 모듈 매개변수에 다른 학습률 적용: 라우터 학습률을 낮추거나 높여 훈련 과정을 안정화합니다.
    - 메타데이터 기반 라우팅: 작업 유형, 텍스트 장르 등 메타데이터를 기반으로 라우팅하여 훈련 초기에 모듈 특화를 유도합니다.

- 모듈 붕괴 해결

    - ε-greedy 라우팅: 초기에 모든 모듈을 탐색하고 이후 학습된 라우팅으로 전환합니다.
    - 부하 분산(Load Balancing): 보조 손실 함수를 사용하여 모듈 선택의 균형을 유지합니다.
    - 내재 보상(Intrinsic Rewards): 모듈 선택의 다양성을 높이도록 보상을 제공합니다.
    - 샘플링 온도 조절: 불균형한 분포에서 예시가 적은 도메인을 더 자주 샘플링하여 모듈 붕괴를 방지합니다.

- 과적합 해결

    - 메타데이터 기반 라우팅: 예시 수준이 아닌 메타데이터 기반으로 라우팅하여 과적합을 줄입니다.
    - 조합적 행동 유도: 모듈 간의 조합적 행동을 유도하여 모델의 일반화 성능을 향상시킵니다.


### Hard Learned Routing

#### Reinforcement Learning

- 강화 학습 기반 라우팅 모델

    - Routing Networks (Rosenbaum et al., 2018): 다중 에이전트 강화 학습(MARL)을 사용하여 각 모듈을 독립적인 에이전트로 간주하고, 협력적으로 최적의 모듈 선택을 학습합니다.
    - Modular Networks (Kirsch et al., 2018): 점수 함수 추정(REINFORCE) 알고리즘을 사용하여 라우팅 함수를 학습합니다.
    - Compositional Recursive Learner (CRL) (Chang et al., 2019): 근접 정책 최적화(PPO) 알고리즘을 사용하여 라우팅 함수를 학습합니다.

- 강화 학습 기반 라우팅의 학습 과정

    - 점수 함수 추정과 SGD 교대: 라우팅 매개변수 ρ는 점수 함수 추정(REINFORCE)으로 학습하고, 모듈 매개변수는 확률적 경사 하강법(SGD)으로 학습하는 과정을 반복합니다.
    - 점수 함수 추정 업데이트: 라우팅 함수는 입력 예시($x_i$)에 대해 특정 모듈($m$)을 선택할 확률($p(m|x_i)$)과 해당 모듈을 선택했을 때 얻는 보상(모델 출력의 정확도 등)을 기반으로 업데이트됩니다.
    - 레이어별 상태와 행동: 각 레이어의 숨겨진 표현($h_t$)을 상태로 간주하고, 라우팅 정책은 모듈 인덱스($m$)를 선택하는 행동을 결정합니다.
    - 전이 함수: 선택된 모듈의 변환을 입력에 적용하는 것은 다음 레이어의 숨겨진 상태($h_{t+1}$)로 전이하는 함수에 해당합니다.
    - 보상: 최상위 레이어에서의 손실 함수는 지연된 음의 보상($-R$)으로 해석됩니다.

<br>

위 식에서 $e_{xi}$는 $x_i(x_i∈masked)$의 임베딩을 나타내며, 추가적인 위치 임베딩 $p_i$가 더해집니다.

<br>

최종적으로, 디코더 $Φ_{dec}$는 다음 목적 함수를 최적화하여 원본 문장 $X$를 재구성하도록 학습됩니다.

<br>

$L_{dec} =\sum_{x_i∈masked}CE(x_i |Φ_{dec}(H_{\widetilde{X}_{dec}}  ))$

<br>

CE는 cross-entropy loss를 의미합니다. 앞서 언급했듯이, 디코더는 1층 트랜스포머 기반으로 구성됩니다.

<br>

공격적인 마스킹과 매우 단순화된 네트워크 구조로 인해 디코딩은 어려운 작업이 되며, 이는 원본 입력을 높은 충실도로 복원하기 위해 고품질의 문장 임베딩 생성을 강제합니다.

<div id="Enhanced Decoding"></div>

## Enhanced Decoding

디코딩 과정의 한 가지 제약은 학습 신호(cross-entropy loss)가 마스크된 토큰에서만 얻어진다는 점입니다.

<br>

또한, 모든 마스크된 토큰은 항상 동일한 컨텍스트$(H_{\widetilde{X}_{dec}})$를 기반으로 재구성됩니다. 우리는 다음 두 가지 조건을 충족하면 사전 학습 효과를 더욱 향상시킬 수 있다고 주장합니다.

1. 입력 문장에서 더 많은 학습 신호를 얻을 수 있어야 합니다.
2. 재구성 작업이 다양한 컨텍스트를 기반으로 수행될 수 있어야 합니다.

이를 위해  two-stream self-attention(Yang et al., 2019)과 position-specific attention mask(Dong et al., 2019)에서 영감을 얻은 향상된 디코딩 방법을 제안합니다. 구체적으로, 디코딩 작업을 위해 두 개의 입력 스트림 $H_1$(쿼리) 및 $H_2$(컨텍스트)를 생성합니다.

<br>

$H_1 ← [h_{\widetilde{X}} + p_0, ..., h_{\widetilde{X}} + p_N ]$

$H_2 ← [h_{\widetilde{X}} , e_{x_1} + p_1, ..., e_{x_N} + p_N ]$

<br>

여기서 $e_{x_i}$는 마스킹 하지 않고 입력 문장 $X$의 모든 토큰에 대한 임베딩을 활용합니다.

<br>

또한, 위치 특정 어텐션 마스크 $M ∈ R^{L×L}$을 도입하여 self-attention을 수행합니다.

<br>

$Q = H_1W^Q, K = H_2W^K, V = H_2W^V$

<br>

$M_{ij}=\left\{\begin{matrix}
0, \; can \, be \, attended,\\−∞, \; masked;
\end{matrix}\right.$

<br>

$A = softmax(\frac{Q^T K }{\sqrt{d}} + M)V.$


<br>

출력 $A$는 $H_1$과 함께 원본 입력을 재구성하는 데 사용됩니다. 최종적으로 다음 목적 함수를 최적화합니다.

<br>

$L_{dec} = \sum_{x_i∈X} CE(x_i |A, H_1)$

<br>

<div id="sic7"></div>

디코더는 단 하나의 트랜스포머 레이어로 구성되어 있으므로, 각 토큰 $x_i$는 행렬 $M$의 $i$번째 행에서 볼 수 있는 컨텍스트를 기반으로 재구성됩니다. 

<br>

<img style="width: 46%;" src="retroMAE/sic1.PNG">

<br>

$s(X$≠$i)$: 현재 토큰 $x_i$를 제외한 나머지 입력 문장 $X$에서 일부 토큰들을 무작위로 선택

<br>

$(i$≠$0)$: 문장 시작 토큰 [CLS]에 해당하는 첫 번째 위치는 항상 모든 토큰에게 공개됩니다. 이는 문장 전체의 의미를 담고 있는 [CLS] 토큰을 모든 토큰이 참조할 수 있도록 하여 문맥 정보를 더 잘 활용하도록 합니다.

<br>

본 논문에서는 향상된 디코딩을 포함한 RetroMAE 사전 학습 워크플로우를 알고리즘 1로 요약합니다.

<br>

<img style="width: 50%;" src="retroMAE/algo1.PNG">

<br>

BERT의 기존 마스크된 언어 모델링(MLM) 작업은 인코더에 유지됩니다. 인코더의 손실 $L_{enc}$는 디코더의 손실 $L_{dec}$와 함께 최종 학습 손실을 구성합니다.

<br>

### RetroMAE 사전 학습 워크플로우의 특징

1. 까다로운 재구성 작업

공격적인 마스킹 비율과 매우 단순화된 디코더 네트워크 구조로 인해 재구성 작업이 어려워졌습니다. 이는 인코더가 입력 문장의 의미를 충분히 포착하도록 강제하여 고품질의 문장 임베딩을 생성하게 합니다.

2. 풍부한 사전 학습 신호

입력 문장의 모든 토큰이 재구성에 사용될 수 있으므로 비지도 말뭉치에서 풍부한 사전 학습 신호를 얻을 수 있습니다. 이는 기존 MLM 방식(마스크된 토큰의 15%만 사용)보다 더 많은 정보를 활용하여 모델을 학습시킬 수 있음을 의미합니다.

3. 간단한 구현

정교한 데이터 증강 및 부정 샘플링이 필요하지 않습니다. 디코더의 단순성으로 인해 BERT/RoBERTa 스타일의 기존 사전 학습과 유사한 계산 비용을 유지합니다.

<div id="Experimental Studies"></div>

# Experimental Studies

<div id="Experiment Settings"></div>

## Experiment Settings

###  Pre-training

- 영어 Wikipedia 및 BookCorpus

BERT (Devlin et al., 2019)에서 사용된 것과 동일한 사전 학습 말뭉치를 재사용합니다. SEED (Lu et al., 2021), Condenser (Gao and Callan, 2021)와 같은 이전 검색 지향 사전 학습 연구에서도 자주 사용되는 데이터셋입니다.

- MS MARCO 말뭉치

coCondenser (Gao and Callan, 2022)를 따라 MS MARCO(Bing 검색 엔진에서 얻은 질의와 문서 쌍으로 구성된 대규모 데이터셋) 말뭉치를 사용하여 밀집 검색을 위한 도메인 내 사전 학습 효과를 분석합니다. 

<br> 

MS MARCO 데이터셋을 사용한 in-domain pre-training이 MS MARCO 자체의 검색 성능에는 중요한 영향을 미치지만, 다른 데이터셋에는 큰 영향을 미치지 않는다는 것을 발견했습니다.

### Evaluation

1. MS MARCO (Nguyen et al., 2016)

Bing 검색에서 가져온 질의를 포함하며, 본 논문에서는 502,939개의 학습 질의와 6,980개의 평가 질의(Dev)를 포함하는 passage retrieval task를 사용합니다. 880만 개의 후보 passage 중에서 답변을 검색해야 합니다.

2. Natural Questions (Kwiatkowski et al., 2019)

Google에서 가져온 질의로 구성되며, 79,168개의 학습 질의, 8,757개의 개발 질의, 3,610개의 테스트 질의가 있습니다. 21,015,324개의 Wikipedia passage 중에서 답변을 검색해야 합니다.

3. BEIR benchmark (Thakur et al., 2021)

zero-shot 검색 성능을 평가합니다. BEIR은 사전 학습된 모델을 MS MARCO 질의로 미세 조정하고 다른 18개 데이터셋에 대한 zero-shot transferability을 평가합니다. 

<br>

저희 실험 연구에서는 세 가지 유형의 기준 방법(baseline methods)을 고려합니다.

### Generic models

본 실험에서는 다음과 같은 일반적인 사전 학습된 언어 모델을 사용합니다.

1. BERT (Devlin et al., 2019): 실제 응용에서 가장 널리 사용되는 사전 학습된 언어 모델입니다. 또한, 밀집 검색을 위한 인코딩 네트워크로 자주 미세 조정됩니다.

2. RoBERTa (Liu et al., 2019): 상당히 확장된 학습 데이터와 개선된 학습 설정을 통해 BERT를 향상시킨 모델입니다.

3. DeBERTa (He et al., 2020b): 분리된 어텐션 메커니즘과 향상된 마스크 디코더를 통해 BERT 및 RoBERTa를 더욱 개선한 모델입니다. GLUE 및 SuperGLUE와 같은 NLU 벤치마크에서 가장 강력한 사전 학습 모델 중 하나입니다.

### Retrieval oriented models

1. 자기 대조 학습 (Self-Contrastive Learning, SCL) 기반 모델

- SimCSE (Gao et al., 2021): 드롭아웃으로 증강된 앵커 문장의 여러 버전을 구별하도록 언어 모델을 학습합니다.
- LaPraDoR (Xu et al., 2022): 기존 ICT 사전학습(Guu et al., 2020; Chang et al., 2020)을 개선하여 쿼리 및 문서 인코더를 반복적으로 학습시켜 부정 샘플의 규모를 확장합니다.
- DiffCSE (Chuang et al., 2022): 자기 대조 학습과 조건부 차이 예측을 함께 활용하여 SimCSE를 향상시킵니다.

2. 오토인코딩 (Auto-Encoding, AE) 기반 모델

- Condenser (Gao and Callan, 2021): 문장 임베딩을 인코더의 중간 hidden state와 결합하여 마스크 언어 모델링(MLM) 디코더를 활용하여 마스크된 토큰을 예측합니다.
- SEED (Lu et al., 2021): 문장 임베딩을 사용하여 auto-regression 방식으로 원본 입력을 복구합니다.

### Implementation details

RetroMAE는 인코더로 bi-directional transformers를 사용하며, 12개의 레이어, 768개의 hidden dimension, 30522개의 토큰 어휘(BERT base와 동일)를 가지고 있습니다. 

<br>

디코더는 1개의 레이어로 구성된 트랜스포머입니다. 기본 마스킹 비율은 인코더의 경우 0.3, 디코더의 경우 0.5입니다.

- 학습 환경

  - 8개의 Nvidia A100 (40GB) GPU를 갖춘 머신에서 학습이 진행됩니다.
  - AdamW 옵티마이저를 사용하며, 학습률은 1e-4, 배치 크기는 디바이스당 32, 총 8 에폭 동안 학습합니다.
  
- 소프트웨어 환경

    - PyTorch 1.8 및 HuggingFace transformers 4.16으로 구현되었습니다.

- 평가 방법

  - Zero-shot 평가: BEIR의 공식 스크립트를 사용하여 사전 학습된 모델을 준비하고 평가합니다.
  
    <br>
  
  - 지도 학습 평가: DPR (Karpukhin et al., 2020) 및 ANCE (Xiong et al., 2020)를 사용하여 사전 학습된 모델을 미세 조정하고 평가합니다.

    <br>

  - MS MARCO 평가: standard knowledge distillation 기법을 사용하여 모델 성능을 평가합니다. <br>구체적으로, ANCE로 미세 조정된 bi-encoder가 질문과 관련 없지만 bi-encoder가 관련 있다고 잘못 판단하는 문서 hard negatives에 대해 BERT base scale cross-encoder를 학습시키고, KL-divergence를 최소화하여 bi-encoder를 추가로 미세 조정합니다. <br> <br> cross-encoder: 질문과 문서를 함께 입력으로 받아 관련성을 직접적으로 예측하는 모델 

<div id="Main Results"></div>

## Main Results

### Zero-shot evaluations

<img style="width: 100%;" src="retroMAE/table1.PNG">

<br>

RetroMAE는 대부분의 데이터셋에서 최고 성능을 보이며, 가장 강력한 기준 모델보다 총 평균 4.5% 높은 성능을 달성했습니다. 

<br>

Zero-shot 성능 향상은 모델 규모 증가나 사전 학습 데이터 증강이 아닌, 순전히 사전 학습 알고리즘 업그레이드를 통해 이루어졌다는 점에서 주목할 만합니다.

### supervised evaluations

pre-trained models을 DPR 및 ANCE로 미세 조정하여 지도 학습 평가를 수행했습니다. 기준 모델은 일반 사전 학습 모델과 검색 지향 사전 학습 모델로 나누어 비교했습니다.

<br>

<img style="width: 100%;" src="retroMAE/table23.PNG">

<br>

RetroMAE는 DPR 및 ANCE 미세 조정 모두에서 기준 모델들보다 뛰어난 성능을 유지했습니다.
  - DPR 미세 조정: 두 데이터셋에서 가장 강력한 기준 모델보다 MRR@10 1.96%, Recall@10 1.48% 높은 성능을 보였습니다.
  - ANCE 미세 조정: 두 데이터셋에서 가장 강력한 기준 모델보다 MRR@10 1.42%, Recall@10 1.41% 높은 성능을 보였습니다.

본 논문에서는 위 결과 외에도 몇 가지 흥미로운 관찰 결과를 제시하고 있습니다.

1. 일반적인 사전학습 방법의 한계

일반적인 자연어 이해(NLU) 분야에서 성능 향상을 가져온 고급 사전학습 방법이 밀집 검색 성능 향상에는 반드시 기여하지 않는다는 점이 확인되었습니다. 

<br>

특히, RoBERTa와 DeBERTa는 BERT를 크게 개선한 모델이지만, 일반적인 NLU 벤치마크에서 보여준 성능 향상만큼 dense retrieval에서는 BERT보다 더 나은 성능을 보이지 못했습니다. 

<br>

이는 검색 지향 사전 학습 모델 개발의 필요성을 뒷받침하는 결과입니다.

2. 오토인코딩 기반 사전학습의 우수성

SEED, Condenser, RetroMAE와 같은 오토인코딩(AE) 기반 사전 학습 방식은 zero-shot 및 지도 학습 평가 모두에서 일반적인 사전 학습 모델과  self-contrastive learning(SCL) 기반 사전 학습 모델보다 훨씬 더 우수한 성능을 보였습니다. 

<br>

이는 dense retrieval에는 오토인코딩 방식이 더 적합하다는 것을 실증적으로 증명합니다

3. self-contrastive learning 기반 사전학습 모델의 미세 조정 한계

SCL 기반 사전 학습 모델은 미세 조정을 통해 일반적인 사전 학습 모델에 비해 약간의 성능 향상만을 가져올 뿐입니다.

<br>

지도 학습 및 zero-shot 평가에서 두 모델의 성능이 비슷하게 나타난다는 점에서 이를 확인할 수 있습니다.

<br>

이러한 결과는 최근 dense retrieval(BERT vs. ICT) 및 이미지 처리(BEiT vs. MoCo/DINO) 연구에서도 보고된 바 있으며, SCL 모델은 미세 조정 잠재력이 상대적으로 제한적이라는 점을 시사합니다.

<div id="Ablation Studies"></div>

## Ablation Studies

<img style="width: 100%;" src="retroMAE/table6.PNG">

### decoding method

enhanced decoding (w.)이 basic decoding (w.o.)보다 성능이 월등히 뛰어난 것을 확인했습니다.

<br>

basic decoding은 입력 토큰의 50%만 재구성에 사용하며, 모든 토큰이 동일한 컨텍스트를 기반으로 예측됩니다.

<br>

enhanced decoding은 입력 토큰 전체를 재구성에 사용되며, 각 토큰은 <a href="#sic7">해당 수식</a>에 따라 샘플링된 고유한 컨텍스트를 기반으로 재구성됩니다.

### decoder size

디코더의 트랜스포머 레이어 수를 1개에서 3개로 늘려 실험을 진행했습니다. (향상된 디코딩은 단일 레이어 트랜스포머에만 적용 가능하므로 이 실험에서는 비활성화되었습니다.)

<br>

계산 비용은 증가했지만, 디코더 크기를 키우는 것이 실질적인 성능 향상을 가져오지 않았습니다. 향상된 디코딩을 사용할 수 없다는 점을 고려하면, 1개 레이어 디코더가 최선의 선택임을 알 수 있습니다.

### masking ratios of decoder

디코더 마스킹 비율을 0.15에서 0.9까지 증가시키며, enhanced decoding 사용 여부에 따라 두가지 실험을 진행하였습니다.

<br>

두 실험 모두 공격적인 마스킹 비율을 적용할수록 검색 품질이 크게 향상되는 것을 확인했습니다.

<br>

enhanced decoding (w.)을 사용한 경우 최적 성능은 0.5에서, basic decoding (w.o.)는 0.7에서 달성되었습니다.

<br>

이는 enhanced decoding에서는 모든 입력 토큰을 재구성하지만, basic decoding에서는 마스크된 토큰만 재구성하기 때문에 더 많은 학습 신호를 얻기 위해 더 높은 마스킹 비율을 사용하기 때문으로 추정됩니다.

### encoder’s masking ratio

흥미롭게도, 일반적으로 사용되는 0.15보다 약간 높은 0.3의 마스킹 비율에서도 실험 성능이 향상되었습니다.

<br>

인코더와 디코더 모두 마스킹 비율을 높이면 재구성 난이도가 증가하여 검색 품질이 향상되는 공통적인 이유가 있습니다.

<br>

하지만 디코더와 달리, 인코더의 마스킹 비율이 너무 높으면 (예: 0.9) 검색 성능이 크게 저하됩니다. 이는 입력 문장의 유용한 정보 대부분이 버려지기 때문에 고품질의 문장 임베딩 생성이 어려워지기 때문입니다.

### concluded as follows

1. RetroMAE의 성능은 enhanced decoding을 통해 크게 향상될 수 있습니다.
2. 디코더에는 1층 트랜스포머가 가장 적합합니다.
3. 디코더의 마스킹 비율을 높이고, 인코더의 마스킹 비율을 적절하게 높이면 검색 품질을 향상시킬 수 있습니다.
