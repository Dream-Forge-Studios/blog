---
date: '2024-05-03'
title: '야구 승부예측'
categories: ['ml']
summary: '야구 승부예측 모델을 만들어보자'
thumbnail: './test.png'
---

<div id="train data"></div>

# train data

{
s_no:
[
{
venue: 0, #어웨이
result: 승리(1)/패배(0),
win_rate: 승률,
score: 경기당 득점,
conceded: 경기당 실점,
ERA_all: 전체 선발 투수 평균 자책,
ERA_30: 최근 30일 선발 투수 평균 자책,
win_rate_10: 최근 10경기 승률,
score_10: 최근 10경기 득점,
conceded_10: 최근 10경기 실점,
},
{
venue: 1, #홈
result: 승리(1)/패배(0),
win_rate: 승률,
score: 경기당 득점,
conceded: 경기당 실점,
ERA_all: 전체 선발 투수 평균 자책,
ERA_30: 최근 30일 선발 투수 평균 자책,
win_rate_10: 최근 10경기 승률,
score_10: 최근 10경기 득점,
conceded_10: 최근 10경기 실점,
}
]
}

분석할 데이터가 쌓이는 기간을 고려하여 시즌의 시작인 4월은 제외하고 5월 부터 데이터를 수집하였습니다.

<br>

결측치 0.0 값을 제외하였으며, 0.2를 테스트 데이터로 사용하였습니다.

<div id="Experiment"></div>

# Experiment

우리의 실험 목표는 승부 예측 확률이 60%가 넘어갔을 때, 가장 잘 예측하는 모델을 찾는 것 입니다.

<div id="machine learning"></div>

## machine learning

승부 예측을 위해 세 가지 머신러닝 모델인 SVM(서포트 벡터 머신), 로지스틱 회귀, 그리고 랜덤 포레스트를 사용하여 학습과 성능 비교하였습니다.

1. 서포트 벡터 머신 (SVM): [해당 논문]('https://intapi.sciendo.com/pdf/10.1515/ijcss-2016-0007')에서 머신 러닝 모델 중 가장 뛰어난 성능을 보였다는 결과가 있어 채택하였습니다. 다만, 확률은 다른 모델에 비해 정확하지 않습니다.
2. 로지스틱 회귀: 확률을 예측하는데 뛰어난 모델이여서 선택하게 되었습니다.
3. 랜덤 포레스트: 과적합을 방지하여, 일반화 성능이 뛰어난 모델이므로 선택하게 되었습니다.

### 특성 스케일링 (feature scaling)

svm과 logistic regression에서 표준화(Standardization)를 사용하였습니다.

<br>

표준화는 데이터의 평균을 0으로, 표준편차를 1로 조정합니다. 이는 데이터가 정규 분포를 따른다는 가정 하에 사용되며, 이상치에 덜 민감하고, 많은 머신러닝 알고리즘에서 좋은 성능을 낼 때 사용됩니다. 

<br>

야구 데이터는 정규 분포를 따르므로 해당 방법을 사용하였습니다.

<br>

random forest는 결정 트리를 기반으로 하기 때문인데, 결정 트리는 각 특성의 임계값을 사용하여 데이터를 분할합니다. 따라서 특성의 스케일이나 단위가 모델의 학습 과정이나 결정 경계의 형성에 영향을 미치지 않습니다.

### result

1. svm

- accuracy: 0.55
- 60% 이상
  - 개수: 2

clasffication 특이값에 강인하다.
확률은 의미가 없다