{"componentChunkName":"component---src-templates-post-template-tsx","path":"/A Survey of Large Language Models/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<div id=\"대규모 언어 모델의 효율적인 훈련\"></div>\n<h2>대규모 언어 모델의 효율적인 훈련</h2>\n<h3>분산 훈련 알고리즘</h3>\n<ol>\n<li>병렬 전략 사용:</li>\n</ol>\n<p>대규모 모델을 효과적으로 훈련하기 위해, 네트워크 파라미터를 학습하는 과정에서 여러 병렬 전략이 사용됩니다. 이러한 전략은 모델을 여러 컴퓨팅 장치에 분산시켜 각 장치가 모델의 일부를 학습하도록 합니다.</p>\n<ol start=\"2\">\n<li>효율적인 리소스 관리</li>\n</ol>\n<p>이 접근법은 계산 자원을 최적화하고, 학습 시간을 단축하며, 대규모 모델을 실제로 훈련 가능하게 만듭니다.</p>\n<h3>최적화 프레임워크</h3>\n<ol>\n<li>DeepSpeed와 Megatron-LM</li>\n</ol>\n<p>이러한 프레임워크는 분산 훈련을 지원하고, 병렬 알고리즘의 구현과 배포를 용이하게 합니다. DeepSpeed는 학습 속도를 높이고 메모리 사용을 최적화하는 반면, Megatron-LM은 모델 병렬화에 초점을 맞춥니다.</p>\n<ol start=\"2\">\n<li>프레임워크의 중요성</li>\n</ol>\n<p>이러한 프레임워크는 대규모 모델을 효율적으로 학습시키는 데 필수적입니다. 그들은 개발자가 복잡한 하드웨어 설정을 직접 관리하지 않고도 대규모 모델을 학습할 수 있도록 도와줍니다.</p>\n<h3>최적화 기법</h3>\n<ol>\n<li>재시작 전략</li>\n</ol>\n<p>훈련 중 손실이 갑자기 증가하는 경우, 모델 훈련을 재시작하여 이 문제를 해결할 수 있습니다.</p>\n<ol start=\"2\">\n<li>혼합 정밀도 훈련</li>\n</ol>\n<p>이 기법은 다른 데이터 유형(예: float32 대신 float16)을 사용하여 메모리 사용량을 줄이고, 계산 속도를 높입니다. 이는 모델 성능에 영향을 미치지 않으면서 훈련 속도를 개선합니다.</p>\n<div id=\"코드 데이터 학습\"></div>\n<h2>코드 데이터 학습</h2>\n<p>원래 GPT-3 모델은 일반 텍스트에 대한 사전 훈련을 받았지만, 복잡한 작업, 예를 들어 코드 완성이나 수학 문제 해결과 같은 작업에서 추론 능력에 한계가 있었습니다.</p>\n<br>\n<p>이 능력을 향상시키기 위해, OpenAI는 2021년 7월에 Codex를 소개했습니다. Codex는 GitHub 코드의 대규모 코퍼스에서 미세 조정된 GPT 모델입니다.</p>\n<br>\n<p>Codex는 매우 어려운 프로그래밍 문제를 해결할 수 있는 능력을 입증했으며, 수학 문제 해결에서도 큰 성능 향상을 이끌어 냈습니다.</p>\n<br>\n<p>2022년 1월에는 텍스트와 코드 임베딩을 훈련하는  contrastive approach 방식이 보고되었습니다. 이 방법은 관련 작업(예: 선형 프로브 분류, 텍스트 검색, 코드 검색)의 성능을 개선하는 데 도움이 되었습니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2201.10005.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br>\n<p>또한, 코드 데이터에 대한 훈련이 LLM의 Chain-of-Thought Prompting 능력을 크게 증가시킬 수 있다는 추측이 있습니다. 하지만 이는 더 많은 연구와 검증이 필요한 부분입니다.</p>\n<div id=\"GPT-4\"></div>\n<h2>GPT-4</h2>\n<h3>red teaming</h3>\n<p>OpenAI는 GPT-4의 개발 과정에서 환각, 개인정보 유출, 과도한 의존성 등의 문제를 완화하기 위한 여러 전략을 적용했습니다.</p>\n<br>\n<p>그 중 red teaming은 해로운 내용 생성을 줄였습니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2209.07858.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<h3>predictable scaling</h3>\n<p>GPT-4는 잘 구축된 딥 러닝 인프라 위에서 개발되었으며, 개선된 최적화 방법이 적용되었습니다.</p>\n<br>\n<p>특히, ‘predictable scaling’이라는 새로운 메커니즘을 도입하여 모델 훈련 중 적은 계산으로 최종 성능을 정확하게 예측할 수 있게 되었습니다.</p>\n<br>\n<p>트렌스포머 기반 언어 모델에서는 문장을 이해하고, 요약하고, 대답하는 등의 능력이 생기는 것을 확인하면서, LLM의 주목하기 시작하였습니다.</p>\n<div id=\"Library Resource\"></div>\n<h2>Library Resource</h2>\n<ul>\n<li>\n<p>Transformers</p>\n<ul>\n<li>Hugging Face에서 개발 및 유지 보수하는 Transformer 아키텍처를 사용하여 모델을 구축하는 오픈 소스 Python 라이브러리입니다.</li>\n<li>사용자 친화적이고 간단한 API를 제공하여 다양한 사전 훈련된 모델을 사용하고 사용자 정의하기 쉽습니다.</li>\n<li>많은 사용자 및 개발자로 이루어진 활발한 커뮤니티와 함께 작동하여 모델과 알고리즘을 정기적으로 업데이트하고 개선하는 강력한 라이브러리입니다.</li>\n</ul>\n</li>\n<li>\n<p>DeepSpeed</p>\n<ul>\n<li>Microsoft에서 개발한 딥 러닝 최적화 라이브러리로 PyTorch와 호환됩니다.</li>\n<li>분산 훈련을 위한 다양한 최적화 기술을 지원하며, 메모리 최적화 (ZeRO 기술, 그래디언트 체크포인팅) 및 파이프라인 병렬성과 같은 기능을 제공합니다.</li>\n<li>MTNLG 및 BLOOM과 같은 여러 LLMs의 훈련에 사용되었습니다.</li>\n</ul>\n</li>\n<li>\n<p>Megatron-LM:</p>\n<ul>\n<li>NVIDIA에서 개발한 딥 러닝 라이브러리로 대규모 언어 모델을 훈련하기 위한 것입니다.</li>\n<li>모델 및 데이터 병렬성, 혼합 정밀도 훈련 및 FlashAttention과 같은 다양한 최적화 기술을 제공합니다.</li>\n<li>이러한 최적화 기술은 훈련 효율성과 속도를 크게 향상시켜 GPU 간 효율적인 분산 훈련을 가능하게 합니다.</li>\n</ul>\n</li>\n<li>\n<p>JAX</p>\n<ul>\n<li>Google에서 개발한 Python 라이브러리로 고성능 머신 러닝 알고리즘을 수행할 수 있도록 해줍니다.</li>\n<li>하드웨어 가속 (예: GPU 또는 TPU)을 사용하여 배열에서 계산을 쉽게 수행할 수 있습니다.</li>\n<li>자동 미분 및 실시간 컴파일링과 같은 기능을 지원하며 다양한 장치에서 효율적인 계산을 가능하게 합니다.</li>\n</ul>\n</li>\n<li>\n<p>Colossal-AI</p>\n<ul>\n<li>HPC-AI Tech에서 개발한 대규모 AI 모델을 훈련하기 위한 딥 러닝 라이브러리입니다.</li>\n<li>PyTorch를 기반으로 구현되었으며 병렬 훈련 전략의 다양한 컬렉션을 지원합니다.</li>\n<li>PatrickStar에 의해 제안된 메모리 관리 방법을 사용하여 이질적인 메모리 관리를 최적화할 수 있습니다.</li>\n<li>Colossal-AI를 기반으로 한 ColossalChat과 같은 ChatGPT와 유사한 모델도 개발되었습니다.</li>\n</ul>\n</li>\n<li>\n<p>BMTrain</p>\n<ul>\n<li>OpenBMB가 개발한 효율적인 라이브러리로, 대규모 파라미터를 가진 모델을 분산 방식으로 훈련하는 데 중점을 둡니다.</li>\n<li>코드의 간결성, 낮은 자원 요구 및 높은 가용성을 강조합니다.</li>\n<li>다양한 LLMs를 ModelCenter에 통합하여 개발자가 이러한 모델을 직접 사용할 수 있도록 지원합니다.</li>\n</ul>\n</li>\n<li>\n<p>FastMoE</p>\n<ul>\n<li>MoE (혼합 전문가) 모델을 위한 전용 훈련 라이브러리로, PyTorch를 기반으로 개발되었습니다.</li>\n<li>효율성과 사용자 친화성을 모두 고려하여 설계되었으며, Transformer 모델을 MoE 모델로 전환하는 과정을 간소화합니다.</li>\n<li>훈련 중 데이터 병렬성과 모델 병렬성을 모두 지원합니다.</li>\n</ul>\n</li>\n<li>\n<p>vLLM</p>\n<ul>\n<li>빠른 추론과 서빙을 위한 메모리 효율적이고 사용하기 쉬운 라이브러리입니다.</li>\n<li>빠른 추론을 위해 고성능 CUDA 커널을 최적화하고, PagedAttention을 사용하여 효율적인 어텐션 메모리 관리를 제공합니다.</li>\n<li>다양한 디코딩 알고리즘, 텐서 병렬성 및 스트리밍 출력을 지원하며 HuggingFace 모델과 호환되고 OpenAI 호환 API 서버를 제공합니다.</li>\n</ul>\n</li>\n<li>\n<p>DeepSpeed-MII</p>\n<ul>\n<li>DeepSpeed가 개발한 메모리 효율적인 Python 라이브러리로, 높은 처리량, 낮은 대기 시간 및 비용 효과적인 LLMs 추론을 중시합니다.</li>\n<li>Blocked KV 캐싱, 지속적인 배치 처리, 동적 SplitFuse 및 고성능 CUDA 커널을 활용하여 텍스트 생성 추론을 가속화합니다.</li>\n<li>현재 LLaMA, Mistral, OPT와 같은 세 가지 인기 있는 모델 아키텍처에서 13,000개 이상의 모델을 지원합니다.</li>\n</ul>\n</li>\n<li>\n<p>DeepSpeed-Chat</p>\n<ul>\n<li>빠르고 비용 효율적이며 사용하기 쉬운 시스템 프레임워크로, 모델 훈련 중 완전한 RLHF 프로세스를 통합하는 데 사용됩니다.</li>\n<li>ChatGPT와 유사한 모델의 훈련 및 추론 프로세스를 간소화하고, InstructGPT의 훈련 모드를 복제하여 SFT, 보상 모델 파인튜닝 및 RLHF의 세 가지 훈련 단계를 완벽하게 제공합니다.</li>\n<li>DeepSpeed 추론에서 다양한 최적화를 활용하여 훈련 및 추론 엔진을 통합하는 통합 하이브리드 엔진 (Deepspeed HE)을 제공합니다.</li>\n</ul>\n</li>\n</ul>\n<div id=\"PRE-TRAINING\"></div>\n<h2>PRE-TRAINING</h2>\n<h3>대화 데이터</h3>\n<p>대화 데이터는 LLM의 대화 능력을 강화하고, 다양한 질문-답변 작업의 성능을 향상시킬 수 있습니다.</p>\n<br>\n<p>온라인 대화 데이터는 종종 여러 참가자 간의 토론을 포함합니다. 이러한 대화를 효과적으로 처리하는 방법은 대화를 트리 구조로 변환하는 것입니다.</p>\n<br>\n<p>그런데 대화 데이터를 LLM에 과도하게 통합하는 것은 부작용을 초래할 수 있다는 연구가 있습니다.</p>\n<br>\n<p>모델이 지시문이나 질문을 단순한 대화 개시로만 해석하고, 그 내용에 대한 적절한 반응을 제공하지 못하며 모델이 그 요청을 무시하고 대신 일상적인 대화를 시작할 수 있습니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2205.01068.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<h3>tokenizer</h3>\n<p>일부 언어 모델들(예: OPT와 GPT-3)은 GPT-2의 토크나이저를 그대로 사용합니다. 이는 편리하지만, 모델이 훈련하는 특정 코퍼스의 특성을 완벽히 반영하지 못할 수 있습니다.</p>\n<br>\n<p>다양한 도메인, 언어, 형식으로 구성된 코퍼스의 경우, 특화된 토크나이저를 개발하는 것이 유익할 수 있습니다.</p>\n<br>\n<p>최근 언어 모델은 사전 훈련 코퍼스에 특화된 맞춤형 토크나이저를 SentencePiece 라이브러리를 사용하여 훈련합니다. 이 라이브러리는 바이트 레벨의 BPE(Byte-Pair Encoding)와 유니그램 토크나이징 방법을 포함합니다.</p>\n<br>\n<p>BPE에서 사용되는 정규화 기술은 텍스트를 표준화된 형태로 변환합니다. NFKC(Normalization Form KC)는 문자를 호환성 분해한 다음 합성하는 방식으로, 다양한 문자 변형을 표준 형태로 변환합니다.</p>\n<br>\n<p>그러나 이러한 정규화 과정은 특정 언어나 문자에 대한 토크나이징 성능을 저하시킬 수 있습니다. 특히, NFKC와 같은 정규화는 언어의 복잡한 문자 구조를 과도하게 단순화시킬 위험이 있습니다.</p>\n<br>\n<p>결과적으로, 맞춤형 토크나이저는 비영어 데이터를 처리할 때 비효율적일 수 있습니다. 예를 들어, 중국어와 같이 영어와 구조적으로 상이한 언어를 처리할 때 더 긴 추론 지연 시간이 발생할 수 있습니다.</p>\n<h3>데이터 혼합</h3>\n<p>데이터 혼합은 LLMs의 성능과 범용성을 향상시키기 위해 중요한 역할을 합니다.</p>\n<br>\n<p>다양한 데이터 소스를 적절한 비율로 결합함으로써, 모델은 다양한 유형의 텍스트를 이해하고 생성하는 능력을 개발할 수 있습니다.</p>\n<br>\n<p>이러한 방법은 모델이 실제 세계의 다양한 언어적 상황에 더 잘 대응할 수 있게 합니다.</p>\n<br>\n<h4>데이터 소스 다양성 증가</h4>\n<br>\n<p>한 특정 도메인에 대한 과도한 데이터로 훈련할 경우, LLMs의 다른 도메인에 대한 일반화 능력이 저하될 수 있다는 것이 연구를 통해 밝혀졌습니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2112.11446.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2211.09085.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br>\n<p>일부 연구에서는 각 데이터 소스를 하나씩 제거하는 방식으로 실험을 수행하고, 특별히 준비된 데이터셋으로 LLMs를 사전 훈련시켜, 다양한 데이터 소스의 영향을 조사했습니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2305.13169.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2308.12284.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2309.10818.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br>\n<p>또한, 웹 페이지와 같은 고이질성 데이터 소스를 제거하면 학술 코퍼스와 같은 저이질성 데이터 소스를 제거하는 것보다 LLMs의 능력에 더 심각한 영향을 미친다는 사실이 밝혀졌습니다.</p>\n<p>*고이질성(high heterogeneity): 웹 페이지와 같은 데이터 소스는 다양한 주제, 스타일, 형식을 포함하여 매우 다양하고 복잡한 정보를 제공</p>\n<p>*저이질성(low heterogeneity): 학술 코퍼스와 같은 데이터 소스는 보다 한정된 주제와 형식을 가지고 있어 상대적으로 이질성이 낮음</p>\n<br>\n<h4>데이터 혼합 최적화</h4>\n<br>\n<p>데이터 혼합을 수동으로 설정하는 것 외에도, 모델 사전 훈련을 개선하기 위해 데이터 혼합을 최적화하는 방법이 제안되었습니다.</p>\n<br>\n<p>target downstream tasks가 주어지면, feature space에서 목표 downstream task와 근접한 데이터를 선택하거나,</p>\n<p><a href=\"https://arxiv.org/pdf/2302.03169.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br> \n<p>downstream tasks에 긍정적인 영향을 제공하는 데이터를 선택할 수 있습니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2305.12816.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br> \n<p>“DoReMi”라는 연구에서는 다양한 데이터 도메인(예: 뉴스, 과학, 문학 등)을 혼합하여 작은 모델을 학습 시켜, 가장 바람직한 혼합 찾아 큰 모델을 학습시키는 방법을 제안합니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2305.10429.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br> \n<p>그러나 이 접근 방식의 가정은 비슷한 방식으로 학습할 때 작은 모델이 모델 능력이나 행동 면에서 큰 모델과 유사할 것이라는 가정이며, 이는 실제로 항상 유지되지는 않습니다.</p>\n<br> \n<h4>LLM의 특정 능력을 향상시키기 위한 데이터 선택 및 혼합 전략</h4>\n<br> \n<p>LLM의 모델 용량은 데이터 선택 및 혼합에 크게 의존하며 특정 모델 능력을 향상시키기 위해 특정 데이터 소스의 비율을 높일 수 있습니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2112.11446.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2305.13169.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br>\n<p>LAMBADA 데이터세트에 대한 실험 결과는 책 데이터의 비율을 늘리면 텍스트의 장기적인 의존성을 포착하는 능력을 향상시킨다는 결과가 있습니다.</p>\n<p>*장기적인 의존성: 문서의 시작 부분에 나온 주제나 개념이 문서의 끝 부분에서 다시 언급될 때, 이 두 부분 사이의 연관성을 파악하는 것</p>\n<p><a href=\"https://arxiv.org/pdf/1606.06031.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br>\n<p>C4 데이터셋의 비율을 늘리면, 모델의 일반화 능력을 검증하는 C4 검증 데이터셋에서 좋은 성능을 낸다는 연구 결과도 있습니다.</p>\n<p>*C4 데이터셋: 다양한 웹 소스에서 수집된 방대한 양의 텍스트로 구성</p>\n<br>\n<h4>Data Curriculum</h4>\n<br>\n<p>데이터 커리큘럼은 교육의 커리큘럼 개념에서 영감을 받은 것으로, 모델 학습 과정에서 데이터를 특정 순서로 제공하는 방법을 의미합니다.</p>\n<br>\n<p>특정 기술을 배우기 위해 기술 세트 순서(예: 기본 기술 → 대상 기술)로 학습하는 것이 대상 기술에만 초점을 맞춘 코퍼스에서 직접 학습하는 것보다 성능이 우수한 것으로 나타났습니다.</p>\n<br>\n<p>다양한 Data Curriculum을 적용한 연구를 아래 소개합니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2307.14430.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2308.12950.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2310.02263.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2307.03170.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br>\n<h4>추가적인 Tip</h4>\n<br>\n<p>사전 훈련 데이터에는 웹 페이지, 코드, 책, 과학 논문 등과 같은 다양한 고품질 텍스트를 포함하는 것이 권장됩니다.</p>\n<br>\n<p>특화된 LLM을 훈련할 경우, 해당 기술과 관련된 데이터 소스의 비율을 증가시키는 것이 유용합니다.</p>\n<p>(Gopher와 Chinchilla는 책 데이터 약 40%, PaLM 및 LaMDA는 약 50%의 대화 데이터)</p>\n<br>\n<p>다양한 소스에서 수집된 데이터는 서로 다른 형식을 가질 수 있습니다. 이를 통일하거나 명확하게 지정함으로써, 모든 데이터가 모델에 의해 동일한 방식으로 처리될 수 있습니다.</p>\n<p><a href=\"https://arxiv.org/pdf/1808.06226.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<h3>Architecture</h3>\n<h4>Prefix Decoder Architecture</h4>\n<br>\n<p>prefix 토큰에 대해서만 양방향 주의(Bidirectional Attention)를 적용합니다.</p>\n<p>*prefix 토큰: 입력 시퀀스의 시작 부분에 해당하는 토큰</p>\n<br>\n<p>디코딩 부분(토큰 생성)은 단방향 주의(Unidirectional Attention)만 적용됩니다.</p>\n<br>\n<p>사전 학습에서 동일한 토큰을 학습했을 때 Causal Decoder Architecture 보다 언어 모델링 능력은 떨어집니다.</p>\n<br>\n<h4>Emergent Architectures</h4>\n<br>\n<p>전통적인 트랜스포머 아키텍처는 입력이 길어질 때 계산 복잡도가 제곱에 비례하여 증가하는 문제가 있습니다. 이러한 문제를 해결하고 효율성을 높이기 위해, 여러 연구들이 새로운 아키텍처를 개발하고 있습니다.</p>\n<div id=\"Model Training\"></div>\n<h2>Model Training</h2>\n<h3>배치 크기</h3>\n<p>언어 모델 사전 훈련을 위해 기존의 작업은 훈련의 안정성과 처리량을 향상시키기 위해 일반적으로 큰 배치 크기를 설정합니다. (2,048 또는 4M 토큰)</p>\n<br>\n<p>GPT-3, PaLM과 같은 LLMs에서는 훈련 중에 배치 크기를 동적으로 증가시키는 새로운 전략을 도입했습니다.</p>\n<br>\n<p>이는 훈련 초기에는 상대적으로 작은 배치 크기로 시작하여 점차적으로 증가시키며, 최종적으로는 백만 단위의 배치 크기에 도달합니다.</p>\n<br>\n<p>구체적으로, GPT-3의 경우 배치 크기가 처음에는 32K 토큰에서 시작하여 점차 3.2M 토큰까지 증가합니다.</p>\n<br>\n<p>dynamic schedule of batch size 대규모 언어 모델의 훈련 과정을 안정화시키는 데 효과적입니다.</p>\n<br>\n<p>이는 초기에는 작은 배치 크기를 사용하여 모델이 더 민감하게 학습하도록 하고, 훈련이 진행됨에 따라 큰 배치 크기를 사용하여 안정성을 증가시킵니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2204.02311.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<h3>Learning Rate</h3>\n<h4>warm-up</h4>\n<br>\n<p>훈련의 초기 단계(대략 훈련 스텝의 0.1%에서 0.5% 사이)에서는 linear warm-up schedule이 사용</p>\n<br>\n<p>이 단계에서 학습률은 점진적으로 최대값까지 증가합니다. 최대 학습률은 대략 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>5</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">5 × 10^{−5}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">5</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">5</span></span></span></span></span></span></span></span></span></span></span></span></span>에서 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">1 × 10^{−4}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span></span></span></span></span></span> 사이로 설정됩니다(예를 들어, GPT-3의 경우 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mn>6</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">6 × 10^{−5}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">6</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">5</span></span></span></span></span></span></span></span></span></span></span></span></span>).</p>\n<br>\n<h4>decay</h4>\n<br>\n<p>초기 웜업 이후, cosine decay strategy이 적용되어 학습률을 점차적으로 감소시킵니다.</p>\n<br>\n<p>최종적으로 학습률은 최대값의 약 10%까지 감소하며, 이는 훈련 손실의 수렴까지 지속됩니다.</p>\n<br>\n<h4>Optimizer</h4>\n<br>\n<p>Adam 옵티마이저 및 AdamW 옵티마이저는 LLMs의 훈련에서 널리 사용됩니다.</p>\n<br>\n<p>일반적으로 이러한 옵티마이저의 하이퍼파라미터는 다음과 같이 설정됩니다:</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi><mn>1</mn><mo>=</mo><mn>0.9</mn><mo separator=\"true\">,</mo><mi>β</mi><mn>2</mn><mo>=</mo><mn>0.95</mn><mtext>및</mtext><mi>ϵ</mi><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>8</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">β1 = 0.9, β2 = 0.95 및 ϵ = 10^{-8}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\">0.9</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord\">0.95</span><span class=\"mord hangul_fallback\">및</span><span class=\"mord mathnormal\">ϵ</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">8</span></span></span></span></span></span></span></span></span></span></span></span></span></p>\n<br>\n<p>또한 Adafactor 옵티마이저도 LLMs의 훈련에 사용됩니다. 이것은 GPU 메모리를 보존하기 위해 특별히 설계된 Adam 옵티마이저의 변형입니다.</p>\n<p><a href=\"https://arxiv.org/pdf/1804.04235.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br>\n<p>Adafactor 옵티마이저의 하이퍼파라미터는 다음과 같이 설정됩니다:</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>β</mi><mn>1</mn><mo>=</mo><mn>0.9</mn><mo separator=\"true\">,</mo><mi>β</mi><mn>2</mn><mo>=</mo><mn>1.0</mn><mo>−</mo><msup><mi>k</mi><mrow><mo>−</mo><mn>0.8</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">β1 = 0.9, β2 = 1.0 - k^{-0.8}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\">0.9</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"mord\">2</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7278em;vertical-align:-0.0833em;\"></span><span class=\"mord\">1.0</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">0.8</span></span></span></span></span></span></span></span></span></span></span></span></span>, 여기서 k는 훈련 단계의 수를 나타냅니다.</p>\n<br>\n<h4>훈련 안정화 방법</h4>\n<br>\n<p>언어 모델 사전 훈련 중에는 종종 훈련 불안정성 문제가 발생할 수 있으며, 이는 모델의 붕괴를 초래할 수 있습니다.</p>\n<br>\n<p>이러한 문제는 훈련 중에 그래디언트 폭주(gradients exploding) 또는 훈련 손실의 급증(training loss spikes)과 같은 현상으로 나타날 수 있습니다.</p>\n<br>\n<p>훈련 불안정성 문제를 해결하기 위해 가중치 감쇠(weight decay) 및 그래디언트 클리핑(gradient clipping)과 같은 전략이 널리 사용됩니다.</p>\n<p><a href=\"https://arxiv.org/pdf/2005.14165.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2211.05100.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2205.01068.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2210.02414.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a>, <a href=\"https://arxiv.org/pdf/2201.11990.pdf\" target=\"_blank\" rel=\"nofollow\">관련 논문</a></p>\n<br>\n<p>기존 연구들에서는 그래디언트 클리핑의 임계값을 주로 1.0으로 설정하고, 가중치 감쇠 비율을 주로 0.1로 설정합니다.</p>\n<br>\n<p>이러한 방법은 훈련 중에 발생할 수 있는 폭주하는 그래디언트를 제한하고 가중치를 정규화하여 훈련의 안정성을 높이는데 도움이 됩니다.</p>","frontmatter":{"title":"A Survey of Large Language Models","summary":"A Survey of Large Language Models에서 내가 몰랐거나 도움이 될 만한 내용을 요약해보자!","date":"2024.01.30.","categories":["LLM"],"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEZklEQVR42j2TCU8bVxDH9wNUvRRE1IQkrTh87PpcY0OIACGaqmoKSJFCA4ratFVDOJoAbShpEVcSEQg4YByccBgaKBgM5rC963O959tdr20gBkSq9qv0EaRKT6N5evrp/5+ZN0j151/gRo0Vx8pseJnNbMP1Zr3GgBah6nyLCRsbs8di8VA4Go8nGJbnOEEQRAAkUZRhRCoqq2zFeiuOXraZS63GElxvMWiMmArV5BebsOf28TiViERiFEWfwjwPIC8ACSZISemV8itWo05lxQ3FZoNRrzWgapNOhUHYiI2POyAWjsTiFE1DmAenMDiFTSa8orxMpy2wmPTwGHVaVF2IaQpObBsxh2Pyf5h5B5/IChKMMEdQFCsrK1UXfWrUo2YDZtBpMG2RujBfq8rHT5THw+FIMBiCPJVgGIZjT8zzLMsmEjSiRXUohkKdYrPOYkRNek1RwaWi/M8uXcgzYWr7mH17eydEkhRFwXJFIAABqvMCz8WiEaSgUGOx4MUmFLbKgKrOnc358P33Pv7og/qaamF7WiCXiIA/CYS0LO0qyTeZdHYvc/hmL7ub5hNxJCc3r6KiHJrMO/cJqtXU1V7Lzc2xGlS+lwNLjgHfVN/KrDOTlAHLSDwn8pzEswoQUiIPr8iZM2fP513EcUtHZ/uGz3twuLeyvDjy8M7wr9+vTo8+aPlpYqj/aD8jMicwJNl4TEhQgGFiIRIxmS0XLhY8HHgKW5g9SO1m0qzknbf/3Hnr676OHwf/6PK4XUf7u1AqKfApwAMmARg6Hg75N31IZWXVjMsVIYJPno5u7mylFMGx0vR7X03r9er6St3zwVY6sg3JjAwykrCXFCHPURSXoOhoGKmtrYuQ/sNdJSPxrlevJhc7+53XG1v1N25it78z9A7WhcitKOGPEH7YIeVEmYLOZY6TORZpbm4Ok8FEggGi4vP5Oga+bH9c9e09w602rKnb+EvvtUAgGCLDm+veTe9KIhKiwmQkGIiHSBqOqqfnt/U1D8tJHJBpGnTea+gaqW5o0TXexWpuFH5z2wp/JMXKKx7v0p/uDc/Sltez5V3bXl+DCdLa0rSxuhwORYGcTqWzronH3aNXq2vUZlxVbCv4qh4jAuubo22+sVbvutc9O/vaPTczNbkw8/KvBTdSWVG+uvya8O/EKfbg8B8yTtzts/3QdrXxZr21RFNaef5+c0N7jXlu6AHD8AQZDRDheffC2PCQffgJXAzLYF+P17M8NzMN32iWcb5sn50f8a77Rp4NdXfcmbA/o1hp/+BvJbXLC7Isp3leJoio68UUYrRchiJOx/j87PTc9DTgBZFYySip/ezx4dHb47f/Zg+OFSUtAjkJByKl4Eq922qJoQHS2fXIpNfdb2ueck5srHpIMsrxopLa298/lJNpUUrCvYUxmcyIkgITjoO/i4MlxKI04l5YLbfqK0pMj/p7XzgmXE7n/MIiw0IgJQBoUpEkBQA4V8BxIsuJ8ImiGJKIbG36/wPG3qQZ7mlVkwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/3672896cbb49cb2a4050c9744a3e8496/d89b0/test.jpg","srcSet":"/static/3672896cbb49cb2a4050c9744a3e8496/aaa13/test.jpg 374w,\n/static/3672896cbb49cb2a4050c9744a3e8496/b3c6b/test.jpg 748w,\n/static/3672896cbb49cb2a4050c9744a3e8496/d89b0/test.jpg 1496w","sizes":"(min-width: 1496px) 1496px, 100vw"},"sources":[{"srcSet":"/static/3672896cbb49cb2a4050c9744a3e8496/0dfd6/test.webp 374w,\n/static/3672896cbb49cb2a4050c9744a3e8496/8acfa/test.webp 748w,\n/static/3672896cbb49cb2a4050c9744a3e8496/06565/test.webp 1496w","type":"image/webp","sizes":"(min-width: 1496px) 1496px, 100vw"}]},"width":1496,"height":1496}},"publicURL":"/static/3672896cbb49cb2a4050c9744a3e8496/test.png"}}}}]}},"pageContext":{"slug":"/A Survey of Large Language Models/"}},"staticQueryHashes":[],"slicesMap":{}}