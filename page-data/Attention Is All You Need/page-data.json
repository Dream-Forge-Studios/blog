{"componentChunkName":"component---src-templates-post-template-tsx","path":"/Attention Is All You Need/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<div id=\"Introduction\"></div>\n<h2>Introduction</h2>\n<p>과거 언어 모델링과 기계 번역에서는 순환 신경망(RNN,LSTM,GRU) 모델을 활용하였습니다.</p>\n<br>\n<p>하지만 순차적 특성은 이전 요소의 처리 결과에 의존하여 시퀀스의 각 부분을 독립적으로 동시에 처리하기 때문에 병렬처리가 어렵고, 특히 긴 시퀀스 길이에서는 메모리 제약으로 인해 배치 처리가 제한됩니다.</p>\n<br>\n<p>Attention mechanisms는 입력 데이터의 모든 부분이 동등한 중요도를 갖지 않는다는 아이디어에서 출발합니다. 모델이 특정 부분에 더 많은 ‘attention’를 기울여 그 부분의 중요도를 높입니다.</p>\n<br>\n<p><strong>Attention mechanisms 작동 원리</strong></p>\n<ol>\n<li>Query, Key, Value:</li>\n</ol>\n<ul>\n<li>\n<p>Query: 현재 타겟 또는 출력 상태를 나타냅니다.</p>\n<br>\n</li>\n<li>\n<p>Key: 입력 데이터의 각 요소를 나타내며, 쿼리와 비교되어 유사도를 계산하는 데 사용됩니다. <br>=> Query 부분에서 해당 토큰이 얼마나 중요한지</p>\n<br>\n</li>\n<li>\n<p>Value: 입력 데이터의 각 요소에 대응하며, 가중치가 적용된 후 최종 출력에 기여합니다. <br>=> 토큰의 실제 정보</p>\n<br>\n</li>\n<li>\n<p>입력 시퀀스의 각 토큰(예: 단어, 문자)마다 고유한 Key와 Value가 할당</p>\n<br>\n</li>\n<li>\n<p>Query는 입력 시퀀스의 각 토큰마다 별도로 생성되지 않고, 대신 현재의 타겟 상태 또는 출력에 대한 Query가 할당 <br> 예) 시퀀스-투-시퀀스 모델(기계번역)에서는 디코더의 각 층마다 하나씩 생성 <br>*Self-Attention에서 Query는 입력 시퀀스의 각 토큰마다 별도로 생성</p>\n</li>\n</ul>\n<ol start=\"2\">\n<li>유사도 계산 및 가중치 할당:</li>\n</ol>\n<ul>\n<li>\n<p>Query와 각 Key 사이의 유사도를 계산(내적 dot product)하여 attention weight를 결정합니다.</p>\n<br>\n</li>\n<li>\n<p>이 weight는 입력 데이터의 어느 부분이 현재 출력에 더 중요한지 나타냅니다.</p>\n<br>\n</li>\n<li>\n<p>attention weight는 보통 Softmax 함수를 통해 정규화되어, 모든 weight의 합이 1이 되도록 합니다.</p>\n<br>\n</li>\n<li>\n<p>이후 Value와 결합하여 context vector를 생성합니다. <br> (현재 출력에 중요성에 따라 입력 데이터의 정보가 반영되도록 하는 계산의 사용)</p>\n<br>\n</li>\n<li>\n<p>최종적으로 생성된 context vector와 현재의 타겟 상태를 결합하여 최종 출력(예: 번역된 단어, 다음 단어)을 생성하는 데 사용됩니다.</p>\n</li>\n</ul>\n<p><strong>Transformer의 제안</strong></p>\n<br>\n<p>이전에는 attention mechanisms을 순환 신경망과 결합하여 사용하였습니다.</p>\n<br>\n<p>그런데 Transformer 모델은 순환을 제외하고 전적으로 attention mechanisms에 의존하는 Self-Attention을 활용합니다. 이는 입력과 출력 사이의 전역 의존성을 효과적으로 포착할 수 있게 해주며, 병렬 처리를 크게 향상시킵니다.</p>\n<br>\n<p>transformer 더 많은 병렬 처리를 가능하게 함으로써, 트레이닝 시간을 단축시키고 번역 품질에서 새로운 최고 기록을 달성할 수 있습니다. 예를 들어, P100 GPU 8개에서 단 12시간만에 트레이닝을 완료할 수 있습니다.</p>\n<div id=\"Background\"></div>\n<h2>Background</h2>\n<p>transformer 기본 목표 중 하나는 순차적 계산을 줄이는 것입니다. 이는 Extended Neural GPU, ByteNet, ConvS2S와 같은 모델들에서도 공통적인 목표로, 이들 모델은 모두 CNN을 기본 구성 요소로 사용합니다.</p>\n<br>\n<p>하지만 ConvS2S, ByteNet 등에서 두 입력 또는 출력 위치 사이의 관계를 파악하는 데 필요한 연산은 위치 간 거리에 따라 증가합니다. ConvS2S는 선형적으로, ByteNet은 로그 함수적으로 증가합니다.</p>\n<br>\n<p>이러한 모델들에서 거리가 멀어질수록 서로 관련 있는 신호를 연결하는 것이 더 어려워집니다.</p>\n<br>\n<p>transformer는 RNN이나 CNN 없이 오로지 Self-Attention에만 의존하는 transduction 모델입니다. 이 점에서 기존 모델들과 크게 차별화됩니다.</p>\n<div id=\"Model Architecture\"></div>\n<h2>Model Architecture</h2>\n<p>transformer는 거리에 따라 필요한 연산 수가 증가하는 cnn 기반 모델과 다르게 self-attention을 통해 이 문제를 해결합니다.</p>\n<br>\n<p>하지만, 이 방식은 모든 입력 토큰들을 하나의 context vector로 평균화함으로써, 개별 토큰들의 고유한 정보나 미묘한 차이가 손실될 수 있습니다.</p>\n<br>\n<p>이러한 문제는 Multi-Head Attention을 통해 해결합니다.</p>\n<img style=\"width:60%; margin-top: 40px;\" id=\"output\" src=\"/703f8ed71cee6ca0d4b74a5d13485822/architecture.png\">\n<h3>Encoder and Decoder Stacks</h3>\n<p><strong>Encoder</strong></p>\n<ol>\n<li>구조</li>\n</ol>\n<ul>\n<li>encoder는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>=</mo><mn>6</mn></mrow><annotation encoding=\"application/x-tex\">N=6</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">6</span></span></span></span></span>개의 동일한 층으로 구성됩니다.</li>\n<li>각 층에는 두 개의 sub-layer가 있습니다.</li>\n</ul>\n<ol start=\"2\">\n<li>서브층</li>\n</ol>\n<ul>\n<li>첫 번째 sub-layer는 multi-head self-attention mechanism입니다.</li>\n<li>두 번째 sub-layer는 positionwise fully connected feed-forward network입니다.</li>\n</ul>\n<ol start=\"3\">\n<li>residual connection과 layer normalization</li>\n</ol>\n<ul>\n<li>각 sub-layer 주변에는 Residual Connection이 적용됩니다.</li>\n<li>이후 각 sub-layer의 출력에는 Layer Normalization가 수행됩니다.</li>\n<li>즉, 각 sub-layer의 출력은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo>+</mo><mi>S</mi><mi>u</mi><mi>b</mi><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">LayerNorm(x + Sublayer(x))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">L</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">yer</span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">or</span><span class=\"mord mathnormal\">m</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">yer</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">))</span></span></span></span></span> 형태를 갖습니다. 여기서 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>S</mi><mi>u</mi><mi>b</mi><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">Sublayer(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">b</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">yer</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span></span></span></span></span>는 서브층 자체에 의해 구현된 함수입니다.</li>\n</ul>\n<ol start=\"4\">\n<li>출력 차원</li>\n</ol>\n<ul>\n<li>모델 내의 모든 sub-layer과 embedding layer은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi><mo>=</mo><mn>512</mn></mrow><annotation encoding=\"application/x-tex\">dmodel = 512</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">512</span></span></span></span></span>의 출력 차원을 가집니다.</li>\n</ul>\n<br>\n<p><strong>Decoder</strong></p>\n<ol>\n<li>구조</li>\n</ol>\n<ul>\n<li>decoder 역시 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>=</mo><mn>6</mn></mrow><annotation encoding=\"application/x-tex\">N=6</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">6</span></span></span></span></span>개의 동일한 층으로 구성됩니다.</li>\n<li>각 층에는 세 개의 sub-layer가 있습니다.</li>\n</ul>\n<ol start=\"2\">\n<li>서브층</li>\n</ol>\n<ul>\n<li>encoder와 동일한 두 개의 sub-layer에서 추가로 encoder 출력에 대해 multi-head attention을 수행하는 세 번째 sub-layer 추가</li>\n</ul>\n<ol start=\"3\">\n<li>residual connection과 layer normalization</li>\n</ol>\n<ul>\n<li>encoder와 동일</li>\n</ul>\n<ol start=\"4\">\n<li>self-attention sub-layer 수정</li>\n</ol>\n<ul>\n<li>decoder의 self-attention layer는 Masking과 출력 임베딩의 Offset이 추가됩니다.</li>\n<li>Masking\n<ul>\n<li>디코더는 현재 시점의 출력을 생성할 때, 현재 시점 이후의 정보를 참조하지 못하도록 해야 합니다.</li>\n<li>특정 위치에서는 해당 위치와 그 이후의 위치에 대한 정보를 참조하지 못하도록 마스킹 처리됩니다.</li>\n</ul>\n</li>\n<li>출력 임베딩의 Offset\n<ul>\n<li>출력 임베딩이 offset by one position된다는 것은, 디코더가 출력을 생성할 때 출력하기 이전 까지만 참조한다는 의미입니다.</li>\n</ul>\n</li>\n</ul>\n<h3>Scaled Dot-Product Attention</h3>\n<p><strong>Scaled Dot-Product Attention의 구조</strong></p>\n<ol>\n<li>입력 차원</li>\n</ol>\n<ul>\n<li>Query와 Key는 차원 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>를 가지며, 값(Value)은 차원 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>를 가집니다.</li>\n</ul>\n<ol start=\"2\">\n<li>연산 과정</li>\n</ol>\n<ul>\n<li>Query와 모든 Key의 내적(dot product)을 계산합니다.</li>\n<li>각 내적 결과를 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{d_k}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.1828em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8572em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.8172em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"1.08em\" viewBox=\"0 0 400000 1080\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1828em;\"><span></span></span></span></span></span></span></span></span></span>로 나누어 스케일링합니다.</li>\n<li>Softmax 함수를 적용하여 값을 가중치로 변환합니다.</li>\n</ul>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><msqrt><msub><mi>d</mi><mi>k</mi></msub></msqrt></mfrac><mo stretchy=\"false\">)</mo><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">Attention(Q,K,V)=softmax( \\frac{QK^T}{\\sqrt{d_k}} )V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">tt</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.6275em;vertical-align:-0.538em;\"></span><span class=\"mord mathnormal\">so</span><span class=\"mord mathnormal\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">ma</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.0895em;\"><span style=\"top:-2.5864em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord sqrt mtight\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8622em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mtight\" style=\"padding-left:0.833em;\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1512em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.8222em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail mtight\" style=\"min-width:0.853em;height:1.08em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"1.08em\" viewBox=\"0 0 400000 1080\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1778em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.4461em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">Q</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9191em;\"><span style=\"top:-2.931em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.538em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span></span></span></span></span></p>\n<h3>Multi-Head Attention</h3>\n<p><strong>Multi-Head Attention의 개념</strong></p>\n<ol>\n<li>linearly project의 사용</li>\n</ol>\n<ul>\n<li>\n<p>Multi-Head Attention에서는 single attention function를 사용하는 대신, Query, Key, Value를 ℎ번 서로 다른 linearly project을 통해 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>k</mi></msub><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_k, d_k, d_v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>차원으로 변환합니다.</p>\n<br>\n</li>\n<li>\n<p>각 head 각기 다른 Query, Key, Value 값을 가지며, 이는 입력 데이터를 서로 다른 방식으로 해석하고, 다양한 정보를 추출할 수 있도록 합니다.</p>\n</li>\n</ul>\n<ol start=\"2\">\n<li>병렬 attention 실행</li>\n</ol>\n<ul>\n<li>이렇게 투영된 각 Query, Key, Value에 대해 attention function를 병렬로 수행합니다.</li>\n<li>이 과정은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>차원의 출력 값을 생성합니다.</li>\n</ul>\n<ol start=\"3\">\n<li>결합 및 최종 투영</li>\n</ol>\n<ul>\n<li>어텐션의 결과를 연결(concatenate)한 후, 다시 한 번 project하여 최종 값으로 변환합니다.</li>\n</ul>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>M</mi><mi>u</mi><mi>l</mi><mi>t</mi><mi>i</mi><mi>H</mi><mi>e</mi><mi>a</mi><mi>d</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><mo separator=\"true\">,</mo><mi>K</mi><mo separator=\"true\">,</mo><mi>V</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>C</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy=\"false\">(</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mi mathvariant=\"normal\">.</mi><mo separator=\"true\">,</mo><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>h</mi></msub><mo stretchy=\"false\">)</mo><msup><mi>W</mi><mi>O</mi></msup></mrow><annotation encoding=\"application/x-tex\">MultiHead(Q, K, V ) = Concat(head_1, ..., head_h)W^O</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">lt</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">He</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">d</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.22222em;\">V</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0913em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">C</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">...</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">h</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">O</span></span></span></span></span></span></span></span></span></span></span></span></p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mi>i</mi></msub><mo>=</mo><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>Q</mi><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo separator=\"true\">,</mo><mi>K</mi><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo separator=\"true\">,</mo><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">head_i = Attention(QW_i^Q , KW_i^K , W_i^V )</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">a</span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2361em;vertical-align:-0.2769em;\"></span><span class=\"mord mathnormal\">A</span><span class=\"mord mathnormal\">tt</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">n</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">Q</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9592em;\"><span style=\"top:-2.4231em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.1809em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2769em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.07153em;\">K</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2587em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2587em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<br>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi>W</mi><mi>i</mi><mi>Q</mi></msubsup><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><mi>d</mi><mi>k</mi></mrow></msup><mo separator=\"true\">,</mo><msubsup><mi>W</mi><mi>i</mi><mi>K</mi></msubsup><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><mi>d</mi><mi>k</mi></mrow></msup><mo separator=\"true\">,</mo><msubsup><mi>W</mi><mi>i</mi><mi>V</mi></msubsup><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><mi>d</mi><mi>v</mi></mrow></msup><mo separator=\"true\">,</mo><msup><mi>W</mi><mi>O</mi></msup><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>h</mi><mi>d</mi><mi>v</mi><mo>×</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup></mrow><annotation encoding=\"application/x-tex\">W_i^Q ∈ \\mathbb{R}^{d_{model}×dk} , W_i^K ∈ \\mathbb{R}^{d_{model}×dk} , W_i^V  ∈ \\mathbb{R}^{d_{model}×dv}, W^O ∈ \\mathbb{R}^{ hdv×d_{model}} </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2361em;vertical-align:-0.2769em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9592em;\"><span style=\"top:-2.4231em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.1809em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">Q</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2769em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1078em;vertical-align:-0.2587em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1512em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.07153em;\">K</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2587em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1078em;vertical-align:-0.2587em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1512em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-2.4413em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.22222em;\">V</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2587em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0435em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1512em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">×</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">O</span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8491em;\"></span><span class=\"mord\"><span class=\"mord mathbb\">R</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">h</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"mbin mtight\">×</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1512em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></p>\n<br>\n<p><strong>Multi-Head Attention의 구현</strong></p>\n<ul>\n<li>모델은 총 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding=\"application/x-tex\">h=8</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">8</span></span></span></span></span>개의 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">head</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">d</span></span></span></span></span>를 사용합니다.</li>\n<li>각 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">head</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">h</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">d</span></span></span></span></span>의 차원 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mi>k</mi></msub><mo separator=\"true\">,</mo><msub><mi>d</mi><mi>v</mi></msub></mrow><annotation encoding=\"application/x-tex\">d_k, d_v</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mi mathvariant=\"normal\">/</mi><mi>h</mi><mo>=</mo><mn>64</mn></mrow><annotation encoding=\"application/x-tex\">d_{model}/h=64</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">/</span><span class=\"mord mathnormal\">h</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">64</span></span></span></span></span>로 설정됩니다.</li>\n<li>각 헤드의 차원이 줄어들기 때문에, 전체 계산 비용은 전체 차원을 사용하는 single head attention과 유사합니다.</li>\n</ul>\n<img style=\"width: 80%; margin-top: 40px;\" id=\"output\" src=\"/e7403c70492c16192fa97c1027fe4462/attention.png\">\n<h3>Applications of Attention in our Model</h3>\n<ol>\n<li>encoder-decoder attention</li>\n</ol>\n<ul>\n<li>decoder의 multi-head attention 부분</li>\n<li>이 층에서의 Query는 이전 디코더 층에서 오며, Key와 Value는 인코더의 출력에서 옵니다.</li>\n<li>이 구조는 decoder 내의 모든 위치가 입력 시퀀스의 모든 위치에 주목할 수 있도록 합니다.</li>\n<li>이는 전형적인 sequence-to-sequence models에서 볼 수 있는 encoder-decoder attention mechanisms을 모방합니다.</li>\n</ul>\n<ol start=\"2\">\n<li>encoder 내의 self-attention</li>\n</ol>\n<ul>\n<li>모든 Query, Key, Value가 같은 곳, 즉 인코더의 이전 층의 출력에서 옵니다.</li>\n</ul>\n<ol start=\"3\">\n<li>decoder 내의 self-attention</li>\n</ol>\n<ul>\n<li>masking 기법이 사용되어, 아직 생성되지 않은 미래의 단어들에 대한 정보를 차단(−∞로 설정)하고 생성 중인 현재 위치까지만 정보를 참조할 수 있도록 합니다.</li>\n</ul>\n<h3>Position-wise Feed-Forward Networks</h3>\n<p><strong>구성 요소</strong></p>\n<br>\n<p>두 개의 linear transformations과 그 사이의 ReLU 활성화 함수로 구성됩니다.</p>\n<br>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>F</mi><mi>F</mi><mi>N</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>x</mi><msub><mi>W</mi><mn>1</mn></msub><mo>+</mo><msub><mi>b</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo><msub><mi>W</mi><mn>2</mn></msub><mo>+</mo><msub><mi>b</mi><mn>2</mn></msub></mrow><annotation encoding=\"application/x-tex\">FFN(x)=max(0, xW_1+b_1)W_2+b_2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">FFN</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">ma</span><span class=\"mord mathnormal\">x</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">x</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">W</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">b</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n<br>\n<p><strong>linear transformations의 일관성과 다양성</strong></p>\n<br>\n<p>각 위치에서의 linear transformations은 동일하지만, 층마다 다른 파라미터를 사용합니다. 다시 말해, 인코더와 디코더의 각 층은 독립적인 피드포워드 네트워크 파라미터를 가집니다.</p>\n<br>\n<p><strong>kernel size 1의 convolutions으로의 해석</strong></p>\n<br>\n<p>이 네트워크는 kernel size가 1인 2개의 convolution으로 해석될 수 있습니다. 이는 각 위치에서의 연산이 주변 위치의 값에 영향을 받지 않는다는 것을 의미합니다.</p>\n<br>\n<p>입력과 출력의 차원은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>=</mo><mn>512</mn></mrow><annotation encoding=\"application/x-tex\">d_{model} = 512</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">512</span></span></span></span></span>입니다.</p>\n<br>\n<p>inner-layer(첫번째 linear transformations)의 차원은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>f</mi><mi>f</mi></mrow></msub><mo>=</mo><mn>2048</mn></mrow><annotation encoding=\"application/x-tex\">d_{ff}=2048</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9805em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10764em;\">ff</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">2048</span></span></span></span></span>입니다.</p>\n<h3>Embeddings and Softmax</h3>\n<br>\n<p><strong>Embeddings</strong></p>\n<ul>\n<li>\n<p>입력 토큰과 출력 토큰을 벡터로 변환하기 위해 학습된 임베딩을 사용합니다.</p>\n<br>\n</li>\n<li>\n<p>각 토큰은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_{model}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span> 차원의 벡터로 변환됩니다.</p>\n<br>\n</li>\n<li>\n<p>임베딩 벡터의 차원 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_{model}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>은 모델의 다른 부분과 일관되게 유지됩니다. (self-attention layer과 feed forword 등 인코더와 디코더의 각 서브층의 입력과 출력은 모두 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_{model}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>차원을 유지)</p>\n</li>\n</ul>\n<br>\n<p><strong>Softmax</strong></p>\n<ul>\n<li>\n<p>디코더의 출력을 다음 토큰의 확률로 변환하기 위해 linear transformations과 softmax funtion를 사용합니다.</p>\n<br>\n</li>\n</ul>\n<p><strong>가중치 공유</strong></p>\n<ul>\n<li>모델은 입력 embeddings 층, 출력 embeddings 층, 그리고 softmax 이전의 linear transformations 간에 동일한 가중치 행렬(임베딩 행렬)을 공유합니다.</li>\n</ul>\n<p>*softmax 이전의 linear transformations: <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi><mo>⋅</mo><msup><mi>E</mi><mi>T</mi></msup></mrow><annotation encoding=\"application/x-tex\">d⋅E^T</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">d</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8413em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span></span></span></span></span> (<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">E</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span></span></span></span></span> 임베딩 행렬, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>d</mi></mrow><annotation encoding=\"application/x-tex\">d</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">d</span></span></span></span></span> 디코더 출력)</p>\n  <br>\n<ul>\n<li>이는 모델의 파라미터 수를 줄이고, 효율성을 높이는 데 도움이 됩니다.</li>\n</ul>\n<br>\n<p><strong>임베딩 가중치의 스케일링</strong></p>\n<br>\n<ul>\n<li>\n<p>임베딩 층에서는 가중치(임베딩 행렬)에 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{d_{model}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.1828em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8572em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-2.8172em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg xmlns=\"http://www.w3.org/2000/svg\" width=\"400em\" height=\"1.08em\" viewBox=\"0 0 400000 1080\" preserveAspectRatio=\"xMinYMin slice\"><path d=\"M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z\"></path></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1828em;\"><span></span></span></span></span></span></span></span></span></span>을 곱하여 스케일링합니다.</p>\n<br>\n</li>\n<li>\n<p>이는 임베딩 벡터의 크기를 조정하고, 학습 과정을 안정화하는 데 도움이 됩니다.</p>\n</li>\n</ul>\n<h3>Positional Encoding</h3>\n<p>트랜스포머는 순환 구조나 합성곱 구조를 사용하지 않습니다. 따라서 모델이 토큰의 순서를 인식하고, 이를 기반으로 정보를 처리할 수 있도록 위치 정보를 제공해야 합니다.</p>\n<br>\n<p><strong>Positional Encoding 구현</strong></p>\n<ul>\n<li>\n<p>입력 임베딩에 위치 인코딩을 더하여, 각 토큰의 위치 정보를 모델에 제공합니다.</p>\n<br>\n</li>\n<li>\n<p>이 위치 인코딩은 인코더와 디코더 스택의 하단에서 입력 임베딩과 합쳐집니다.</p>\n<br>\n</li>\n<li>\n<p>위치 인코딩의 차원은 임베딩 벡터의 차원 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">d_{model}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span>과 동일하므로, 두 벡터를 직접 더할 수 있습니다.</p>\n<br>\n</li>\n</ul>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator=\"true\">,</mo><mn>2</mn><mi>i</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant=\"normal\">/</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup></mrow></mfrac><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">PE(pos,2i)=sin(\\frac{pos}{10000^{2i/d_{model}}})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">PE</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">os</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">i</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1852em;vertical-align:-0.4352em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">in</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7475em;\"><span style=\"top:-2.5648em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1000</span><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8932em;\"><span style=\"top:-2.8932em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5357em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mtight\">/</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:0em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.6944em;\"></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3496em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.4461em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">os</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4352em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><mi>E</mi><mo stretchy=\"false\">(</mo><mi>p</mi><mi>o</mi><mi>s</mi><mo separator=\"true\">,</mo><mn>2</mn><mi>i</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mo>=</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mfrac><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><mrow><mn>1000</mn><msup><mn>0</mn><mrow><mn>2</mn><mi>i</mi><mi mathvariant=\"normal\">/</mi><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup></mrow></mfrac><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">PE(pos,2i+1)=cos(\\frac{pos}{10000^{2i/d_{model}}})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">PE</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">os</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\">2</span><span class=\"mord mathnormal\">i</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1852em;vertical-align:-0.4352em;\"></span><span class=\"mord mathnormal\">cos</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.7475em;\"><span style=\"top:-2.5648em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1000</span><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8932em;\"><span style=\"top:-2.8932em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5357em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mtight\">/</span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3448em;margin-left:0em;margin-right:0.1em;\"><span class=\"pstrut\" style=\"height:2.6944em;\"></span><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3496em;\"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.4461em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">os</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4352em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow><annotation encoding=\"application/x-tex\">pos</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">p</span><span class=\"mord mathnormal\">os</span></span></span></span></span>는 토큰의 위치(시퀀스 내의 순서), <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>i</mi></mrow><annotation encoding=\"application/x-tex\">i</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6595em;\"></span><span class=\"mord mathnormal\">i</span></span></span></span></span>는 임베딩 벡터 내에서의 특정 차원</p>\n<br>\n<p><strong>cos, sin 함수 표현의 이점</strong></p>\n<br>\n<p>사인과 코사인 함수를 사용한 위치 인코딩은 모델이 상대적 위치 정보를 쉽게 알 수 있도록 합니다. 어떤 고정된 오프셋 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span>에 대해서, <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi><mo>+</mo><mi>k</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">PE_{pos+k}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">os</span><span class=\"mbin mtight\">+</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span>는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>P</mi><msub><mi>E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">PE_{pos}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.9694em;vertical-align:-0.2861em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">P</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0576em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">p</span><span class=\"mord mathnormal mtight\">os</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span></span></span></span></span>의 선형 함수로 표현될 수 있습니다.</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo>+</mo><mi mathvariant=\"normal\">Δ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">Δ</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">Δ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">sin(x+\\Delta)=sin(x)cos(\\Delta)+cos(x)sin(\\Delta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">in</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">Δ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">in</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">cos</span><span class=\"mopen\">(</span><span class=\"mord\">Δ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">cos</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">in</span><span class=\"mopen\">(</span><span class=\"mord\">Δ</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo>+</mo><mi mathvariant=\"normal\">Δ</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi>c</mi><mi>o</mi><mi>s</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">Δ</mi><mo stretchy=\"false\">)</mo><mo>+</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo><mi>s</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi mathvariant=\"normal\">Δ</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">cos(x+\\Delta)=cos(x)cos(\\Delta)+sin(x)sin(\\Delta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">cos</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">Δ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">cos</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">cos</span><span class=\"mopen\">(</span><span class=\"mord\">Δ</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">in</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">in</span><span class=\"mopen\">(</span><span class=\"mord\">Δ</span><span class=\"mclose\">)</span></span></span></span></span></p>\n<br>\n<p>학습된 위치 인코딩과 비교했을 때, 사인과 코사인 함수를 사용한 인코딩은 거의 동일한 결과를 보여주었습니다.</p>\n<br>\n<p>사인과 코사인 함수를 사용하는 이 인코딩 방식은 훈련 중에 보지 못한 더 긴 시퀀스 길이에 대해 모델이 잘 확장될 수 있도록 합니다.</p>\n<div id=\"Why Self-Attention\"></div>\n<h2>Why Self-Attention</h2>\n<p><strong>순환층(recurrent layer)과 비교</strong></p>\n<ol>\n<li>계산 복잡성</li>\n</ol>\n<ul>\n<li>\n<p>self-attention 층은 모든 위치를 한 번에 연결하므로, 계산 복잡성이 일정합니다. 반면, 순환 층은 시퀀스 길이에 비례하여 계산 복잡성이 증가합니다(<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">)</span></span></span></span></span>).</p>\n<br>\n</li>\n<li>\n<p>특히, 시퀀스 길이(n)가 표현 차원(d)보다 작은 경우, self-attention 층은 순환 층보다 계산적으로 더 효율적입니다. 이는 최신 기계 번역 모델에서 사용되는 문장 표현(예: 단어 조각 또는 바이트 쌍 표현)에 자주 해당합니다.</p>\n</li>\n</ul>\n<ol start=\"2\">\n<li>병렬 처리 능력</li>\n</ol>\n<ul>\n<li>\n<p>self-attention 층은 최소한의 순차적 연산만 필요로 하므로, 대부분의 계산을 병렬로 처리할 수 있습니다. 이는 특히 대규모 데이터 처리에 있어 중요한 이점을 제공합니다.</p>\n<br>\n</li>\n<li>\n<p>반면, 순환 층은 각 타임스텝마다 이전 타임스텝의 결과에 의존하기 때문에, 병렬 처리가 어렵습니다.</p>\n</li>\n</ul>\n<ol start=\"3\">\n<li>장거리 의존성 학습</li>\n</ol>\n<ul>\n<li>\n<p>네트워크에서 입력과 출력 위치 사이의 경로 길이가 짧을수록 장거리 의존성을 학습하기가 더 쉽습니다. self-attention 층은 모든 입력과 출력 위치 간에 짧은 경로를 제공합니다.</p>\n<br>\n</li>\n<li>\n<p>순환 층은 장거리 의존성 학습에 있어 불리한데, 이는 입력과 출력 사이의 경로 길이가 시퀀스 길이에 따라 증가하기 때문입니다.</p>\n</li>\n</ul>\n<ol start=\"4\">\n<li>제한된 self-attention</li>\n</ol>\n<ul>\n<li>\n<p>매우 긴 시퀀스를 처리할 때, 자기 주의는 입력 시퀀스 내의 특정 크기(r)의 이웃만을 고려하도록 제한될 수 있습니다. 이는 최대 경로 길이를 O(n/r)로 증가시키지만, 계산 효율성을 개선할 수 있습니다.</p>\n<br>\n</li>\n<li>\n<p>순환 층은 장거리 의존성 학습에 있어 불리한데, 이는 입력과 출력 사이의 경로 길이가 시퀀스 길이에 따라 증가하기 때문입니다.</p>\n</li>\n</ul>\n<p><strong>CNNs과 비교</strong></p>\n<ul>\n<li>\n<p>CNNs의 특징</p>\n<ol>\n<li>\n<p>하나의 합성곱 층은 커널 너비(k)가 시퀀스 길이(n)보다 작으면, 모든 입력과 출력 위치를 직접 연결하지 않습니다.</p>\n <br>\n</li>\n<li>\n<p>필요한 층의 수</p>\n<ul>\n<li>연속적인 커널의 경우: 모든 쌍의 입력-출력 위치를 연결하려면 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>n</mi><mi mathvariant=\"normal\">/</mi><mi>k</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(n/k)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mord\">/</span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mclose\">)</span></span></span></span></span>의 합성곱 층이 필요합니다.</li>\n<li>확장된(dilated) 커널의 경우: <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>l</mi><mi>o</mi><msub><mi>g</mi><mi>k</mi></msub><mo stretchy=\"false\">(</mo><mi>n</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(log_k(n))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\">o</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">n</span><span class=\"mclose\">))</span></span></span></span></span>의 합성곱 층이 필요합니다.</li>\n</ul>\n</li>\n<li>\n<p>이러한 층을 쌓는 것은 네트워크 내에서 임의의 두 위치 사이의 최장 경로 길이를 증가시킵니다.</p>\n <br>\n</li>\n<li>\n<p>일반적으로 CNNs 층은 recurrent 층보다 계산 비용이 더 많이 듭니다. 그 비용은 커널의 너비(k)에 비례합니다.</p>\n <br>\n</li>\n<li>\n<p>분리 가능한 합성곱(Separable Convolution)은 계산 복잡성을 크게 줄일 수 있으며, 복잡성은 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mo stretchy=\"false\">(</mo><mi>k</mi><mo separator=\"true\">⋅</mo><mi>n</mi><mo separator=\"true\">⋅</mo><mi>d</mi><mo>+</mo><mi>n</mi><mo separator=\"true\">⋅</mo><msup><mi>d</mi><mn>2</mn></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">O(k·n·d + n·d^2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">O</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">d</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0641em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span>가 됩니다.</p>\n</li>\n</ol>\n</li>\n<li>\n<p>self-attention의 특징</p>\n<ol>\n<li>\n<p>self-attention의 계산 복잡성은 커널의 크기(k)가 시퀀스 길이(n)와 같은 경우에도 separable convolution과 동일합니다.</p>\n <br>\n</li>\n<li>\n<p>시퀀스 내 모든 위치 간의 직접적인 정보 전달을 가능하게 합니다.</p>\n <br>\n</li>\n<li>\n<p>individual attention heads가 수행하는 작업이나 문장의 구문적 및 의미적 구조와 관련된 행동을 파악하기 용이합니다.</p>\n</li>\n</ol>\n</li>\n</ul>\n<img style=\"width: 100%; margin-bottom: 40px;\" id=\"output\" src=\"/fdeab4d19a02a1157648da585e916bae/length.png\">\n<div id=\"Training\"></div>\n<h2>Training</h2>\n<h3>Training Data and Batching</h3>\n<ul>\n<li>\n<p>데이터셋</p>\n<ul>\n<li>영어-독일어: WMT 2014 English-German 데이터셋을 사용했습니다. 이 데이터셋은 약 450만 문장 쌍으로 구성되어 있습니다.</li>\n<li>영어-프랑스어: 더 큰 WMT 2014 English-French 데이터셋을 사용했습니다. 이 데이터셋은 3600만 문장으로 구성되어 있습니다.</li>\n</ul>\n</li>\n<li>\n<p>Sentences Encoding</p>\n<ul>\n<li>영어-독일어: 바이트 쌍 인코딩(Byte-Pair Encoding, BPE)을 사용하여 약 37,000개 토큰의 공유 소스-타겟 어휘를 생성했습니다.</li>\n<li>영어-프랑스어: 32,000개 단어 조각(word-piece) 어휘를 사용했습니다.</li>\n</ul>\n</li>\n<li>\n<p>batch 처리</p>\n<ul>\n<li>문장 쌍은 대략적인 시퀀스 길이에 따라 배치되었습니다.</li>\n<li>각 훈련 배치는 대략 25,000개의 소스 토큰과 25,000개의 타겟 토큰을 포함했습니다.</li>\n</ul>\n</li>\n</ul>\n<h3>Hardware and Schedule</h3>\n<ul>\n<li>\n<p>8개의 NVIDIA P100 GPUs를 탑재한 한 대의 머신에서 모델을 훈련했습니다.</p>\n  <br>\n</li>\n<li>\n<p>훈련시간</p>\n<ul>\n<li>기본 모델: 논문에서 나온 hyperparameters 설정을 따른 기본 모델은 각 훈련 단계에 대략 0.4초가 소요되었으며, 총 100,000 단계 또는 12시간 동안 훈련되었습니다.</li>\n<li>큰 모델: 훈련 단계에 1.0초가 소요되었으며, 총 300,000 단계 또는 3.5일 동안 훈련되었습니다.</li>\n</ul>\n</li>\n</ul>\n<h3>Optimizer</h3>\n<p>Adam 최적화 알고리즘을 사용했습니다. 설정된 하이퍼파라미터는 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn><mo separator=\"true\">,</mo><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0.98</mn><mo separator=\"true\">,</mo><mi>ε</mi><mo>=</mo><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>9</mn></mrow></msup></mrow><annotation encoding=\"application/x-tex\">β_1 = 0.9, β_2 = 0.98, ε = 10^{-9}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\">0.9</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.05278em;\">β</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:-0.0528em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8389em;vertical-align:-0.1944em;\"></span><span class=\"mord\">0.98</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">ε</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8141em;\"></span><span class=\"mord\">1</span><span class=\"mord\"><span class=\"mord\">0</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">9</span></span></span></span></span></span></span></span></span></span></span></span></span> 입니다.</p>\n<br>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>l</mi><mi>r</mi><mi>a</mi><mi>t</mi><mi>e</mi><mo>=</mo><msubsup><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow><mrow><mo>−</mo><mn>0.5</mn></mrow></msubsup><mo separator=\"true\">⋅</mo><mi>m</mi><mi>i</mi><mi>n</mi><mo stretchy=\"false\">(</mo><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi mathvariant=\"normal\">_</mi><mi>n</mi><mi>u</mi><msup><mi>m</mi><mrow><mo>−</mo><mn>0.5</mn></mrow></msup><mo separator=\"true\">,</mo><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><mi mathvariant=\"normal\">_</mi><mi>n</mi><mi>u</mi><mi>m</mi><mo separator=\"true\">⋅</mo><mi>w</mi><mi>a</mi><mi>r</mi><mi>m</mi><mi>u</mi><mi>p</mi><mi mathvariant=\"normal\">_</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>p</mi><msup><mi>s</mi><mrow><mo>−</mo><mn>1.5</mn></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">lrate = d^{−0.5}_{model} · min(step\\_num^{−0.5} , step\\_num · warmup\\_steps^{−1.5} ) </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">e</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1642em;vertical-align:-0.31em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">d</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8542em;\"><span style=\"top:-2.3987em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">m</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\">d</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span></span></span></span><span style=\"top:-3.1031em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">0.5</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3013em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">min</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">p</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">u</span><span class=\"mord\"><span class=\"mord mathnormal\">m</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">0.5</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">p</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">m</span><span class=\"mpunct\">⋅</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\">p</span><span class=\"mord\" style=\"margin-right:0.02778em;\">_</span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">p</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1.5</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n<br>\n<p>이는 첫 warmup_steps 동안 학습률을 선형적으로 증가시킨 다음, 이후에는 단계 번호의 역 제곱근에 비례하여 감소시킵니다.</p>\n<br>\n<p>warmup_steps는 4000으로 설정되었습니다.</p>\n<h3>Regularization</h3>\n<br>\n<p><strong>Residual Dropout</strong></p>\n<ul>\n<li>\n<p>적용 방법: dropout은 각 sub-layer의 출력에 적용되며, sub-layer 입력에 더해지기 전에 수행됩니다. 이는 또한 인코더와 디코더 스택에서 임베딩과 위치 인코딩의 합에도 적용됩니다.</p>\n  <br>\n</li>\n<li>\n<p>dropout의 목적: dropout은 모델이 특정 뉴런이나 경로에 과도하게 의존하는 것을 방지하고, 일반화 능력을 향상시키기 위해 사용됩니다. 이는 훈련 과정에서 무작위로 일부 뉴런의 활성화를 drop하여, 네트워크가 더 견고해지도록 합니다.</p>\n  <br>\n</li>\n<li>\n<p>기본 모델의 dropout 비율: base model의 경우 드롭아웃 비율(Pdrop)은 0.1로 설정됩니다.</p>\n</li>\n</ul>\n<p><strong>Label Smoothing</strong></p>\n<br>\n<p>5개의 클래스 중 1번 클래스가 정답일 경우, 레이블은 [1, 0, 0, 0, 0]처럼 표현하는데 레이블 스무딩이 적용된 새로운 레이블은 [0.9, 0.025, 0.025, 0.025, 0.025]가 됩니다.</p>\n<ul>\n<li>\n<p>적용 방법: 훈련 중에 레이블 스무딩을 적용하며, 이는 값 <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>ϵ</mi><mrow><mi>l</mi><mi>s</mi></mrow></msub><mo>=</mo><mn>0.1</mn></mrow><annotation encoding=\"application/x-tex\">ϵ_{ls}=0.1</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">ϵ</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">0.1</span></span></span></span></span>을 사용합니다.</p>\n  <br>\n</li>\n<li>\n<p>레이블 스무딩의 목적: 레이블 스무딩은 모델이 너무 확신에 찬 예측을 하는 것을 방지하고, 모델이 불확실성을 더 잘 처리하도록 합니다. 이는 각 훈련 샘플의 레이블을 약간씩 smooth 만들어, 모델이 더욱 smooth한 확률 분포를 학습하게 합니다.</p>\n  <br>\n</li>\n<li>\n<p>영향: 레이블 스무딩은 perplexity(모델의 불확실성을 나타내는 지표)에 부정적인 영향을 미칠 수 있지만, 정확도와 BLEU 점수(기계 번역의 성능을 평가하는 지표)를 개선하는 데 도움이 됩니다.</p>\n</li>\n</ul>\n<div id=\"Results\"></div>\n<h2>Results</h2>\n<p>이전에 발표된 모든 모델과 앙상블을 능가했으며, 경쟁 모델들보다 훨씬 적은 훈련 비용(1/4)이 들었습니다.</p>\n<h3>Model Variations</h3>\n<img style=\"width: 100%; margin-bottom: 40px;\" id=\"output\" src=\"/e9fb58f4762babc96ed67a58e270449f/results.png\">\n<p><strong>(A) 어텐션 헤드 수와 차원 변화</strong></p>\n<ul>\n<li>실험은 어텐션 헤드의 수와 키(key) 및 값(value) 차원을 변화시키면서 성능 변화를 측정했습니다.</li>\n<li>단일 헤드 어텐션은 최적 설정보다 0.9 BLEU 점수가 낮았으며, 너무 많은 헤드를 사용할 경우에도 성능이 감소했습니다.</li>\n</ul>\n<p><strong>(B) 어텐션 키 차원 크기 감소의 영향</strong></p>\n<ul>\n<li>어텐션 키의 차원 크기를 줄이는 것이 모델 품질에 부정적인 영향을 미쳤습니다.</li>\n<li>이는 어텐션의 호환성 결정이 쉽지 않으며, 단순한 내적(dot product)보다 더 정교한 호환성 함수가 유용할 수 있음을 시사합니다.</li>\n</ul>\n<p><strong>(C) 및 (D) 큰 모델과 드롭아웃의 중요성</strong></p>\n<ul>\n<li>예상대로 더 큰 모델이 더 좋은 성능을 보였으며, 드롭아웃은 과적합을 방지하는 데 매우 유용했습니다.</li>\n</ul>\n<p><strong>(E) 위치 인코딩의 변형</strong></p>\n<ul>\n<li>실험에서는 트랜스포머 모델의 기본적인 사인파 위치 인코딩을 학습된 위치 임베딩으로 대체했을 때 거의 동일한 성능을 관찰했습니다.</li>\n</ul>\n<p>이러한 실험 결과는 트랜스포머 모델의 다양한 구성 요소가 전체 성능에 중요한 영향을 미치며, 특히 어텐션 메커니즘의 구조와 드롭아웃의 적용이 모델의 품질에 중요한 역할을 한다는 것을 보여줍니다. 또한, 위치 인코딩 방법을 변형해도 성능에 큰 영향이 없음을 확인했습니다. 이러한 결과는 트랜스포머 모델을 최적화하고 개선하는 데 중요한 통찰을 제공합니다.</p>\n<div id=\"Conclusion\"></div>\n<h2>Conclusion</h2>\n<p>트랜스포머는 전적으로 attention 메커니즘에 기반한 첫 번째 시퀀스 변환(sequence transduction) 모델로, 인코더-디코더 구조에서 흔히 사용되는 순환 층을 multi head self-attention로 대체했습니다.</p>\n<br>\n<p>트랜스포머는  recurrent 또는 convolutional 층을 기반으로 하는 아키텍처보다 번역 작업에서 훨씬 빠르게 훈련될 수 있습니다.</p>\n<br>\n<p>WMT 2014 영어-독일어 및 영어-프랑스어 번역 작업에서 트랜스포머는 새로운 최고 성능(state of the art)을 달성했습니다. 특히 영어-독일어 작업에서는 이전에 보고된 모든 앙상블 모델보다도 뛰어난 성능을 보였습니다.</p>\n<br>\n<p>연구팀은 텍스트 외의 다른 입력 및 출력 modality를 가진 문제에 트랜스포머를 확장할 계획입니다.</p>\n<br>\n<p>이미지, 오디오, 비디오와 같이 큰 입력과 출력을 효율적으로 다루기 위한 지역적이고 제한된 attention 메커니즘에 대한 연구를 계획하고 있습니다.</p>","frontmatter":{"title":"Attention Is All You Need 논문 리뷰","summary":"Attention Is All You Need 완벽 이해하기.","date":"2024.01.02.","categories":["LLM"],"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEZklEQVR42j2TCU8bVxDH9wNUvRRE1IQkrTh87PpcY0OIACGaqmoKSJFCA4ratFVDOJoAbShpEVcSEQg4YByccBgaKBgM5rC963O959tdr20gBkSq9qv0EaRKT6N5evrp/5+ZN0j151/gRo0Vx8pseJnNbMP1Zr3GgBah6nyLCRsbs8di8VA4Go8nGJbnOEEQRAAkUZRhRCoqq2zFeiuOXraZS63GElxvMWiMmArV5BebsOf28TiViERiFEWfwjwPIC8ACSZISemV8itWo05lxQ3FZoNRrzWgapNOhUHYiI2POyAWjsTiFE1DmAenMDiFTSa8orxMpy2wmPTwGHVaVF2IaQpObBsxh2Pyf5h5B5/IChKMMEdQFCsrK1UXfWrUo2YDZtBpMG2RujBfq8rHT5THw+FIMBiCPJVgGIZjT8zzLMsmEjSiRXUohkKdYrPOYkRNek1RwaWi/M8uXcgzYWr7mH17eydEkhRFwXJFIAABqvMCz8WiEaSgUGOx4MUmFLbKgKrOnc358P33Pv7og/qaamF7WiCXiIA/CYS0LO0qyTeZdHYvc/hmL7ub5hNxJCc3r6KiHJrMO/cJqtXU1V7Lzc2xGlS+lwNLjgHfVN/KrDOTlAHLSDwn8pzEswoQUiIPr8iZM2fP513EcUtHZ/uGz3twuLeyvDjy8M7wr9+vTo8+aPlpYqj/aD8jMicwJNl4TEhQgGFiIRIxmS0XLhY8HHgKW5g9SO1m0qzknbf/3Hnr676OHwf/6PK4XUf7u1AqKfApwAMmARg6Hg75N31IZWXVjMsVIYJPno5u7mylFMGx0vR7X03r9er6St3zwVY6sg3JjAwykrCXFCHPURSXoOhoGKmtrYuQ/sNdJSPxrlevJhc7+53XG1v1N25it78z9A7WhcitKOGPEH7YIeVEmYLOZY6TORZpbm4Ok8FEggGi4vP5Oga+bH9c9e09w602rKnb+EvvtUAgGCLDm+veTe9KIhKiwmQkGIiHSBqOqqfnt/U1D8tJHJBpGnTea+gaqW5o0TXexWpuFH5z2wp/JMXKKx7v0p/uDc/Sltez5V3bXl+DCdLa0rSxuhwORYGcTqWzronH3aNXq2vUZlxVbCv4qh4jAuubo22+sVbvutc9O/vaPTczNbkw8/KvBTdSWVG+uvya8O/EKfbg8B8yTtzts/3QdrXxZr21RFNaef5+c0N7jXlu6AHD8AQZDRDheffC2PCQffgJXAzLYF+P17M8NzMN32iWcb5sn50f8a77Rp4NdXfcmbA/o1hp/+BvJbXLC7Isp3leJoio68UUYrRchiJOx/j87PTc9DTgBZFYySip/ezx4dHb47f/Zg+OFSUtAjkJByKl4Eq922qJoQHS2fXIpNfdb2ueck5srHpIMsrxopLa298/lJNpUUrCvYUxmcyIkgITjoO/i4MlxKI04l5YLbfqK0pMj/p7XzgmXE7n/MIiw0IgJQBoUpEkBQA4V8BxIsuJ8ImiGJKIbG36/wPG3qQZ7mlVkwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/3672896cbb49cb2a4050c9744a3e8496/d89b0/test.jpg","srcSet":"/static/3672896cbb49cb2a4050c9744a3e8496/aaa13/test.jpg 374w,\n/static/3672896cbb49cb2a4050c9744a3e8496/b3c6b/test.jpg 748w,\n/static/3672896cbb49cb2a4050c9744a3e8496/d89b0/test.jpg 1496w","sizes":"(min-width: 1496px) 1496px, 100vw"},"sources":[{"srcSet":"/static/3672896cbb49cb2a4050c9744a3e8496/0dfd6/test.webp 374w,\n/static/3672896cbb49cb2a4050c9744a3e8496/8acfa/test.webp 748w,\n/static/3672896cbb49cb2a4050c9744a3e8496/06565/test.webp 1496w","type":"image/webp","sizes":"(min-width: 1496px) 1496px, 100vw"}]},"width":1496,"height":1496}},"publicURL":"/static/3672896cbb49cb2a4050c9744a3e8496/test.png"}}}}]}},"pageContext":{"slug":"/Attention Is All You Need/"}},"staticQueryHashes":[],"slicesMap":{}}