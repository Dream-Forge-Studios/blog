{"componentChunkName":"component---src-templates-post-template-tsx","path":"/BiSeNet V2/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<p>semantic segmentation 기존 논문에서는 inference 속도를 향상시키기 위해 low-level detail을 포기했다.</p>\n<ul>\n<li>\n<p>Low-level Information (저수준 정보)</p>\n<ol>\n<li>기본적인 이미지 특성: 픽셀 값, 색상, 밝기, 그라디언트, 질감, 가장자리 및 방향과 같은 기본적인 이미지 특성을 나타냅니다.</li>\n<li>세부 사항: Low-level 정보는 이미지의 구체적인 세부 사항을 포착합니다.</li>\n<li>필터 응답: 초기 CNN 계층에서 추출되는 특성은 주로 low-level 정보에 중점을 둡니다. 예를 들어, Sobel, Scharr 및 Gabor와 같은 필터는 가장자리, 방향, 질감과 같은 low-level 정보를 포착하는 데 사용됩니다.</li>\n</ol>\n</li>\n<li>\n<p>High-level Information (고수준 정보)</p>\n<ol>\n<li>추상화: 이미지의 고수준 의미나 맥락을 나타냅니다. 객체의 유형, 관계, 액션 및 씬의 전반적인 의미를 포함합니다.</li>\n<li>객체 인식 및 분류: High-level 정보는 특정 객체나 개체의 카테고리를 인식하는 데 중점을 둡니다.</li>\n<li>CNN의 깊은 계층: CNN 아키텍처의 깊은 계층들은 high-level 정보를 포착합니다. 초기 계층은 가장자리나 질감과 같은 low-level 특성을 학습하는 반면, 더 깊은 계층은 얼굴, 자동차, 개 등의 복잡한 객체를 포착하는 특성을 학습합니다.</li>\n</ol>\n</li>\n</ul>\n<p>본 논문에서는 spatial detail(Low-level)과 categorical semantics(High-level)를 모두 충족시키는 네트워크를 제안하며 real-time으로 semantic segmentation을 진행합니다.</p>\n<div id=\"Bilateral Segmentation Network\"></div>\n<h1>Bilateral Segmentation Network</h1>\n<img style=\"width: 100%; margin-bottom: 40px;\" id=\"output\" src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbmyWHR%2FbtrcVkFsuAf%2FihgtgxdaDnKruAxgjkWzS1%2Fimg.png\">\n이 네트워크는 빠른 추론 속도와 높은 정확도를 모두 달성하기 위해 설계되었습니다.\n  <div id=\"1. Detail Branch\"></div>\n<h2>1. Detail Branch</h2>\n<blockquote>\n<p>이미지의 저수준 특징, 즉 세부적인 정보와 구조를 포착하는 데 중점을 둔 부분입니다.</p>\n<p>이러한 세부 정보는 세맨틱 분할의 정확성에 매우 중요합니다.</p>\n</blockquote>\n<ul>\n<li>\n<p>저수준(low-level)의 정보를 효과적으로 캡처하기 위해 풍부한 채널 수(channel capacity)를 갖는다.</p>\n<ul>\n<li>특징의 다양성: 저수준 정보는 주로 이미지의 세밀한 질감, 모서리, 색상 변화와 같은 부분에 포함됩니다. 이러한 정보는 다양한 특징들로 구성되어 있습니다. 따라서 이런 다양한 정보를 효과적으로 표현하려면 네트워크에 충분한 채널 용량이 필요합니다.</li>\n<li>Spatial Details: 저수준의 정보는 고수준의 의미 정보보다 공간적 세부 정보(spatial details)를 갖는 경향이 있습니다. 이러한 세부 정보를 잘 캡처하려면 더 많은 채널이 필요할 수 있습니다.</li>\n</ul>\n</li>\n<li>\n<p>넓은 공간적 크기(spatial size)를 가지고 있기 때문에 residual connection을 사용하지 않는다.</p>\n<ul>\n<li>\n<p>계산 및 메모리 효율성</p>\n<ul>\n<li>넓은 spatial size를 가진 feature map에 residual connection을 적용하면 연산과 메모리 사용량이 늘어납니다.</li>\n<li>BiSeNet V2는 효율성을 중요하게 생각하기 때문에, 추가적인 연산량을 줄이기 위해 Detail Branch에서는 residual connection을 사용하지 않을 수 있습니다.</li>\n</ul>\n</li>\n<li>\n<p>정보의 통합</p>\n<ul>\n<li>Residual connections는 주로 네트워크가 깊어질 때, 그래디언트 소실 문제를 완화하는 데 도움을 줍니다.</li>\n<li>하지만 Detail Branch에서는 이미 저수준의 특징을 충분히 추출할 수 있으므로, 추가적인 residual connection 없이도 학습에 필요한 정보를 충분히 전달할 수 있을 것입니다.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>구조</p>\n<ul>\n<li>총 3개의 layer로 이루어져 있으며 각각 convolution과 batch normalization, ReLu 활성화 함수가 포함</li>\n<li>최종적으로 input의 1/8 크기의 feature map이 출력</li>\n</ul>\n<div id=\"2. Semantic Branch\"></div>\n</li>\n</ul>\n<h2>2. Semantic Branch</h2>\n<blockquote>\n<p>이미지의 고수준 의미 정보를 포착하는 데 중점을 둔 부분입니다.</p>\n</blockquote>\n<img style=\"width: 100%; margin-bottom: 40px;\" id=\"output\" src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FtRwXY%2FbtrcNkzPqPK%2FwHjQUjRkHRYPF2K0VL0Vf0%2Fimg.png\">\n<ol>\n<li>Stem Block</li>\n</ol>\n<ul>\n<li>입력 이미지의 초기 특징을 추출하는 역할을 합니다.</li>\n<li>여러 합성곱 계층, 배치 정규화, 그리고 활성화 함수를 통해 이미지의 기본적인 특징들을 캡처합니다.</li>\n</ul>\n<ol start=\"2\">\n<li>Fast-down sampling</li>\n</ol>\n<ul>\n<li>이미지의 해상도를 빠르게 줄이는 동시에 중요한 특징 정보를 보존합니다.</li>\n<li>여러 합성곱 계층과 최대 풀링(Max Pooling) 또는 스트라이드가 2 이상인 합성곱을 통해 이미지의 해상도를 줄입니다.</li>\n<li>네트워크의 연산량을 줄이고, receptive field를 확장시키는 데 사용됩니다.</li>\n</ul>\n<p>*Receptive field란, 출력에 영향을 주는 입력 이미지의 영역을 의미하는데, 이 영역을 넓히면 네트워크 출력의 한 부분이 입력 이미지의 더 큰 부분을 고려하게 해줍니다.</p>\n<ol start=\"3\">\n<li>Gather and Expansion Layer\r\n<img style=\"width: 100%; margin-top: 40px;\" id=\"output\" src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FLFwgq%2FbtrcOd1F6AH%2FIPsV9KsdRk6I3Ocof2dBv0%2Fimg.png\"></li>\n</ol>\n<ul>\n<li>MobileNetv2(a)의 역병목과 달리, GE Layer(c)에는 하나의 추가적인 3x3 합성곱이 있습니다. 그러나 이 레이어는 계산 비용과 메모리 접근 비용에도 친화적입니다. 또한, 이 레이어 덕분에 GE Layer는 역병목보다 더 높은 특징 표현 능력을 가지게 됩니다.</li>\n<li>이 계층은 특징 맵의 공간 해상도를 조절하고 특징을 확장하는 역할을 합니다.</li>\n<li>특징 맵의 해상도를 줄이는 (Gather) 합성곱 연산과 해상도를 높이는 (Expansion) 전치 합성곱 (Transposed Convolution) 연산을 결합하여 사용합니다.</li>\n</ul>\n<ol start=\"4\">\n<li>Context Embedding Block</li>\n</ol>\n<ul>\n<li>Global Average Pooling (GAP)을 사용하여 특징 맵의 전역적인 맥락 정보를 파악합니다.</li>\n<li>GAP은 특징 맵의 각 채널에 대해 평균 값을 계산하여 고수준의 의미론적 정보를 캡처합니다.</li>\n<li>이후, 이 정보는 다시 원래의 공간 해상도로 확장되어 원래의 특징 맵과 결합됩니다.</li>\n</ul>\n<br>\n<ul>\n<li>\n<p>Stem Block 이 후 Context Embedding Block</p>\n<ul>\n<li>global contextual 정보를 효율적으로 얻기 위해서 average pooling과 resisual connection을 사용</li>\n</ul>\n<div id=\"3. Gather and Expansion Layer\"></div>\n</li>\n</ul>\n<h2>3. Gather and Expansion Layer</h2>\n<blockquote>\n<p>고수준 의미 정보와 저수준 세부 정보를 효과적으로 통합하는 데 도움을 줍니다.</p>\n</blockquote>","frontmatter":{"title":"BiSeNet V2: Bilateral Network with Guided Aggregation for Real-time Semantic Segmentation","summary":"BiSeNet V2: Bilateral Network with Guided Aggregation for Real-time Semantic Segmentation 논문 리뷰","date":"2020.07.29.","categories":["CV"],"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEZklEQVR42j2TCU8bVxDH9wNUvRRE1IQkrTh87PpcY0OIACGaqmoKSJFCA4ratFVDOJoAbShpEVcSEQg4YByccBgaKBgM5rC963O959tdr20gBkSq9qv0EaRKT6N5evrp/5+ZN0j151/gRo0Vx8pseJnNbMP1Zr3GgBah6nyLCRsbs8di8VA4Go8nGJbnOEEQRAAkUZRhRCoqq2zFeiuOXraZS63GElxvMWiMmArV5BebsOf28TiViERiFEWfwjwPIC8ACSZISemV8itWo05lxQ3FZoNRrzWgapNOhUHYiI2POyAWjsTiFE1DmAenMDiFTSa8orxMpy2wmPTwGHVaVF2IaQpObBsxh2Pyf5h5B5/IChKMMEdQFCsrK1UXfWrUo2YDZtBpMG2RujBfq8rHT5THw+FIMBiCPJVgGIZjT8zzLMsmEjSiRXUohkKdYrPOYkRNek1RwaWi/M8uXcgzYWr7mH17eydEkhRFwXJFIAABqvMCz8WiEaSgUGOx4MUmFLbKgKrOnc358P33Pv7og/qaamF7WiCXiIA/CYS0LO0qyTeZdHYvc/hmL7ub5hNxJCc3r6KiHJrMO/cJqtXU1V7Lzc2xGlS+lwNLjgHfVN/KrDOTlAHLSDwn8pzEswoQUiIPr8iZM2fP513EcUtHZ/uGz3twuLeyvDjy8M7wr9+vTo8+aPlpYqj/aD8jMicwJNl4TEhQgGFiIRIxmS0XLhY8HHgKW5g9SO1m0qzknbf/3Hnr676OHwf/6PK4XUf7u1AqKfApwAMmARg6Hg75N31IZWXVjMsVIYJPno5u7mylFMGx0vR7X03r9er6St3zwVY6sg3JjAwykrCXFCHPURSXoOhoGKmtrYuQ/sNdJSPxrlevJhc7+53XG1v1N25it78z9A7WhcitKOGPEH7YIeVEmYLOZY6TORZpbm4Ok8FEggGi4vP5Oga+bH9c9e09w602rKnb+EvvtUAgGCLDm+veTe9KIhKiwmQkGIiHSBqOqqfnt/U1D8tJHJBpGnTea+gaqW5o0TXexWpuFH5z2wp/JMXKKx7v0p/uDc/Sltez5V3bXl+DCdLa0rSxuhwORYGcTqWzronH3aNXq2vUZlxVbCv4qh4jAuubo22+sVbvutc9O/vaPTczNbkw8/KvBTdSWVG+uvya8O/EKfbg8B8yTtzts/3QdrXxZr21RFNaef5+c0N7jXlu6AHD8AQZDRDheffC2PCQffgJXAzLYF+P17M8NzMN32iWcb5sn50f8a77Rp4NdXfcmbA/o1hp/+BvJbXLC7Isp3leJoio68UUYrRchiJOx/j87PTc9DTgBZFYySip/ezx4dHb47f/Zg+OFSUtAjkJByKl4Eq922qJoQHS2fXIpNfdb2ueck5srHpIMsrxopLa298/lJNpUUrCvYUxmcyIkgITjoO/i4MlxKI04l5YLbfqK0pMj/p7XzgmXE7n/MIiw0IgJQBoUpEkBQA4V8BxIsuJ8ImiGJKIbG36/wPG3qQZ7mlVkwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/story/static/3672896cbb49cb2a4050c9744a3e8496/d89b0/test.jpg","srcSet":"/story/static/3672896cbb49cb2a4050c9744a3e8496/aaa13/test.jpg 374w,\n/story/static/3672896cbb49cb2a4050c9744a3e8496/b3c6b/test.jpg 748w,\n/story/static/3672896cbb49cb2a4050c9744a3e8496/d89b0/test.jpg 1496w","sizes":"(min-width: 1496px) 1496px, 100vw"},"sources":[{"srcSet":"/story/static/3672896cbb49cb2a4050c9744a3e8496/0dfd6/test.webp 374w,\n/story/static/3672896cbb49cb2a4050c9744a3e8496/8acfa/test.webp 748w,\n/story/static/3672896cbb49cb2a4050c9744a3e8496/06565/test.webp 1496w","type":"image/webp","sizes":"(min-width: 1496px) 1496px, 100vw"}]},"width":1496,"height":1496}},"publicURL":"/story/static/3672896cbb49cb2a4050c9744a3e8496/test.png"}}}}]}},"pageContext":{"slug":"/BiSeNet V2/"}},"staticQueryHashes":[],"slicesMap":{}}