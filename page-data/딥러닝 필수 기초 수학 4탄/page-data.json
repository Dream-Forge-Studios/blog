{"componentChunkName":"component---src-templates-post-template-tsx","path":"/딥러닝 필수 기초 수학 4탄/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"html":"<div id=\"13. 평균과 분산\"></div>\n<h1>13. 평균과 분산</h1>\n<blockquote>\n<p>확률 분포를 설명하는 두 가지 대푯값</p>\n</blockquote>\n<div id=\"평균\"></div>\n<h2>평균</h2>\n<p>평균에는 산술 평균, 기하 평균, 조화 평균이 있는데,</p>\n<p>딥러닝에서는 시행을 무한번 반복하고 산술 평균을 구하는 <strong>기댓값(Expectation)</strong>\r\n을 의미</p>\n<ul>\n<li>질량 함수의 기대값 정의</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 180px; margin-right: 8px; margin-left: 0px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?E[X]=\\sum_ix_ip_i \">\n</div>\n<ul>\n<li>밀도(연속) 함수의 기대값 정의</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 250px; margin-right: 8px; margin-left: 0px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?E[X]=\\int_{-\\infty }^{\\infty }xp(x)dx \">\n</div>\n<div style=\"display: flex; margin-top: 36px\">\n<div style=\"margin-top: 10px\">보통</div>\n<img style=\"width: 120px; margin-right: 8px; margin-left: 10px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?E[X]=\\mu \">\n<div style=\"margin-top: 10px\">로 표기</div>\n</div>\n<div id=\"분산\"></div>\n<h2>분산</h2>\n<ul>\n<li>퍼진 정도</li>\n</ul>\n<div style=\"display: flex; margin-top: -30px\"></div>\n<ul>\n<li>\n<p>편차(평균과의 차이)를 제곱</p>\n<p>*절댓값을 안 쓰는 이유는 (-7, -1, 1, 7)과 (-4,-4, 4, 4)을 절댓값으로 분산을 구하면 같게 나온다.</p>\n</li>\n</ul>\n<div style=\"display: flex; margin-top: -30px\"></div>\n<ul>\n<li>질량 함수의 분산 정의</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 280px; margin-right: 8px; margin-left: 0px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?V[X]=\\sum_i(x_i-\\mu)^2p_i \">\n</div>\n<ul>\n<li>밀도(연속) 함수의 분산 정의</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 340px; margin-right: 8px; margin-left: 0px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?V[X]=\\int_{-\\infty }^{\\infty }(x_i-\\mu)^2p(x)dx \">\n</div>\n<div style=\"display: flex; margin-top: 20px\"></div>\n<ul>\n<li>표준편차 (<img style=\"width: 14px; margin-right: 2px; margin-left: 2px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?\\sigma \">)</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 90px; margin-right: 8px; margin-left: 0px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?\\sqrt{V[X]} \">\n</div>\n<div style=\"display: flex; margin-top: 24px\"></div>\r\n*루트를 하기 전에는 값이 너무 커지므로 단위를 맞춰주기 위해 사용\n<hr>\n<div id=\"14. 균등 분포와 정규 분포\"></div>\n<h1>14. 균등 분포와 정규 분포</h1>\n<div id=\"균등 분포\"></div>\n<h2>균등 분포</h2>\n<div style=\"margin-top: 10px;\">\n<img style=\"width: 440px;\" id=\"output\" src=\"/story/d07e7c1b489b0bcf85efb83636861c66/ud_graph.png\">\n</div>\n<ul>\n<li>Uniform distribution</li>\n</ul>\n<div style=\"display: flex; margin-top: -30px\"></div>\n<ul>\n<li>평평하게 생겼다. (주사위, 동전)</li>\n</ul>\n<div style=\"display: flex; margin-top: -30px\"></div>\n<ul>\n<li>식</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 168px; margin-right: 8px; margin-left: 20px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(x)=\\left\\{\\begin{matrix}\\frac{1}{b-a}  \\\\ 0 \\end{matrix}\\right.\">\n<img style=\"width: 90px; margin-right: 8px; margin-left: 20px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?\\begin{matrix} a\\leq x\\leq b\\\\otherwise \\end{matrix}\">\n</div>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 140px; margin-right: 8px; margin-left: 20px; margin-top: 40px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?X \\sim U(a,b)\">\n</div>\n<ul>\n<li>평균</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 100px; margin-right: 8px; margin-left: 20px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?\\frac{1}{2}(a+b)\">\n</div>\n<ul>\n<li>분산</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 130px; margin-right: 8px; margin-left: 20px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?\\frac{1}{12}(b-a)^2\">\n</div>\n<div id=\"정규 분포\"></div>\n<h2>정규 분포</h2>\n<div style=\"margin-top: 10px;\">\n<img style=\"width: 440px;\" id=\"output\" src=\"http://infoso.kr/wp/wp-content/uploads/2020/10/%EC%A0%95%EA%B7%9C%EB%B6%84%ED%8F%AC1.png\">\n</div>\n<ul>\n<li>Normal distribution or Gaussian distribution</li>\n</ul>\n<div style=\"display: flex; margin-top: -30px\"></div>\n<ul>\n<li>종모양 (키)</li>\n</ul>\n<div style=\"display: flex; margin-top: -30px\"></div>\n<ul>\n<li>식</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 280px; margin-right: 8px; margin-left: 20px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(x)=\\frac{1}{\\sqrt{2\\pi \\sigma^2}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\">\n</div>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 160px; margin-right: 8px; margin-left: 20px; margin-top: 40px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?X \\sim N(\\mu,\\sigma^2)\">\n</div>\n<div style=\"display: flex; margin-top: 10px\"></div>\n<ul>\n<li>평균</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 22px; margin-right: 8px; margin-left: 20px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?\\mu\">\n</div>\n<div style=\"display: flex; margin-top: 10px\"></div>\n<ul>\n<li>분산</li>\n</ul>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 36px; margin-right: 8px; margin-left: 20px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?\\sigma^2\">\n</div>\n<hr>\n<div id=\"15. 최대 우도 추정 (MLE)\"></div>\n<h1>15. 최대 우도 추정 (MLE)</h1>\n<div id=\"조건부확률과 likelihood\"></div>\n<h2>조건부확률과 likelihood</h2>\n<div style=\"margin-top: 10px;\">\n<img style=\"width: 440px;\" id=\"output\" src=\"/story/1052e0b0d949bd1212e99db37c789480/abBox.png\">\n</div>\n<div style=\"display: flex; margin-top: 0px\">\n<img style=\"width: 140px; margin-right: 8px; margin-left: 26px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(cb|A)=\\frac{1}{2}\">\n<img style=\"width: 140px; margin-right: 8px; margin-left: 94px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(cb|B)=\\frac{2}{3}\">\n<img style=\"width: 100px; margin-right: 8px; margin-left: 40px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?likelihood\">\n</div>\n<div style=\"display: flex; margin-top: 10px\">\n<img style=\"width: 140px; margin-right: 8px; margin-left: 26px; margin-top: 8px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(b|A)=\\frac{1}{2}\">\n<img style=\"width: 140px; margin-right: 8px; margin-left: 94px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(b|B)=\\frac{1}{3}\">\n<img style=\"width: 100px; margin-right: 8px; margin-left: 40px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?likelihood\">\n</div>\n<div style=\"display: flex; margin-top: 20px\">\r\n<div style=\"font-size: 24px; margin-left: 40px;\">조건부확률</div>\r\n<div style=\"font-size: 24px; margin-left: 124px;\">조건부확률</div>\r\n</div>\n<ul>\n<li>likelihood\n<ul>\n<li>예를 들어 어떤 상자에서 꺼낸지 모르는 상태에서 색 공을 뽑았을 때 두 상자에서 색공이 나올 가능도(likelihood)</li>\n<li>어떤 값이 관측되었을 때, 이것이 어떤 확률 분포에서 왔을 지.</li>\n<li>조건부 확률 값, but 확률 분포는 아니다. (합이 1이 아님)</li>\n</ul>\n</li>\n</ul>\n<div id=\"MLE란\"></div>\n<h2>MLE란</h2>\n<blockquote>\n<p>Maximum Likelihood Estimation</p>\n</blockquote>\n<img style=\"width: 100%;\" src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&amp;fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99CDF1435B20DEC20A\">\n* 가우시안 분포로 가정\n<hr>\n<div id=\"16. 최대 사후 확률 (MAP)\"></div>\n<h1>16. 최대 사후 확률 (MAP)</h1>\n<blockquote>\n<p>likelihood 뿐만 아니라 prior distribution(사전 분포)까지 고려한 posterior(사후 확률)를 maximize 하는 것</p>\n</blockquote>\n<div id=\"Bayesian rule\"></div>\n<h2>Bayesian rule</h2>\n<div style=\"display: flex; margin-top: 10px\">\n<img style=\"width: 400px; margin-right: 0px; margin-left: 8px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(x|z)=\\frac{p(x,z)}{p(z)}=\\frac{p(z|x)p(x)}{p(z)}\">\n</div>\n<br>\n<p>어떻게 저런 식이 나왔을까?</p>\n<div style=\"display: flex; margin-top: 26px\">\n<img style=\"width: 240px; margin-right: 0px; margin-left: 0px; margin-top: 10px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(A|B)=\\frac{p(A \\cap B)}{p(B)}\">\n</div>\n<div style=\"display: flex; margin-top: 26px\">\n<img style=\"width: 240px; margin-right: 0px; margin-left: 0px; margin-top: 10px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(B|A)=\\frac{p(A \\cap B)}{p(A)}\">\n<div style=\"margin-top: 32px; margin-left: 10px;\">이면</div>\n<img style=\"width: 280px; margin-right: 0px; margin-left: 24px; margin-top: 10px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(A \\cap B)=p(B|A)p(A)\">\n</div>\n<div id=\"MAP 식\"></div>\n<h2>MAP 식</h2>\n<div style=\"display: flex; margin-top: 26px\">\n<img style=\"width: 600px; margin-right: 0px; margin-left: 0px; margin-top: 10px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?\\hat{x}=argmax_x\\frac{p(z|x)p(x)}{p(z)}=argmax_x p(z|x)p(x)\">\n</div>\n<div style=\"display: flex; margin-top: 26px\">\n<div style=\"margin-top: 24px\">MLE와 비교했을 때</div>\n<img style=\"width: 50px; margin-right: 0px; margin-left: 10px; margin-top: 20px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p(x)\">\n<div style=\"margin-top: 24px; margin-left: 10px;\">가 추가된 것으로 x의 분포를 사전에 알고 있다는 의미이다. (prior distribution)</div></div>\n<p>단, 잘못된 사전 정보는 오히려 추정 성능에 악영향을 미친다.</p>\n<hr>\n<div id=\"17. 정보 이론 기초\"></div>\n<h1>17. 정보 이론 기초</h1>\n<div id=\"Entropy\"></div>\n<h2>Entropy</h2>\n<ul>\n<li>\n<p>불확실성</p>\n<ul>\n<li>정보 이론에서 많이 나오는 글자는 짧은 비트로 적게 나오는 글자는 긴 비트로 표현하여 가장 효율적으로 표현하는 방법은 평균 코드 길이를 가장 적게 하는 것이다. 그런데 발생 확률이 균등하게 분포되어 있으면 평균 코드 길이는 길어지게 된다.</li>\n<li>즉, 평균 코드 길이가 최소화되기 위해서는 엔트로피(불확실성)을 최소화 해야한다.</li>\n</ul>\n</li>\n<li>\n<p>식 : 가장 이상적인 함수(그래프를 보면 확인 가능)</p>\n</li>\n</ul>\n<img style=\"width: 140px; margin-right: 0px; margin-left: 10px; margin-top: 0px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image? \\sum_{i}-p_ilogp_i\">\n<img style=\"width: 50%; margin-right: 0px; margin-left: 10px; margin-top: 10px; margin-bottom: 0px;\" id=\"output\" src=\"https://melonicedlatte.com/assets/images/201912/BB240ECE-0EEB-4601-B2FD-69D07553BBCB.jpeg\">\n<div id=\"Cross-entropy\"></div>\n<h2>Cross-entropy</h2>\n<ul>\n<li>\n<p>실제로는 <img style=\"width: 20px; margin-right: 4px; margin-left: 4px; margin-top: 20px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p_i\">를 따르지만 <img style=\"width: 18px; margin-right: 4px; margin-left: 4px; margin-top: 20px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?q_i\">로 구하는 경우</p>\n<p>(실제 값을 모르는 경우, 결과로 정수값이 필요한데 정수값으로 나오지 않는 경우 등)</p>\n</li>\n<li>\n<p>딥러닝에서는 <img style=\"width: 20px; margin-right: 4px; margin-left: 4px; margin-top: 20px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?q_i\">가 출력, 최대한 <img style=\"width: 18px; margin-right: 4px; margin-left: 4px; margin-top: 20px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p_i\">와 비슷하게 만드려고 노력</p>\n</li>\n</ul>\n<div id=\"KL-divergence\"></div>\n<h2>KL-divergence</h2>\n<img style=\"width: 90%; margin-right: 0px; margin-left: 10px; margin-top: 10px; margin-bottom: 0px;\" id=\"output\" src=\"/story/9cff0996d1130e29b4cdb3f620235d68/kl_div.png\">\n<p><img style=\"width: 15px; margin-right: 4px; margin-left: 0px; margin-top: 20px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?p\">와 <img style=\"width: 13px; margin-right: 4px; margin-left: 4px; margin-top: 20px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?q\">의 분포 차이 (<img style=\"width: 60px; margin-right: 4px; margin-left: 4px; margin-top: 10px; margin-bottom: 0px;\" id=\"output\" src=\"https://latex.codecogs.com/svg.image?q - p\">)</p>\n<div id=\"Mutual information\"></div>\n<h2>Mutual information</h2>\n<img style=\"width: 46%; margin-right: 0px; margin-left: 10px; margin-top: 10px; margin-bottom: 10px;\" id=\"output\" src=\"/story/976f476c7ae3c151953f171267adb62c/mutal.png\">\n<p>x, y가 관련있는 정도(독립이면 0)</p>","frontmatter":{"title":"딥러닝 필수 기초 수학 4탄","summary":"딥러닝을 위해 반드시 알아야할 필수 기초 수학을 총정리 하였습니다.","date":"2023.02.14.","categories":["AI BASIC"],"thumbnail":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEZklEQVR42j2TCU8bVxDH9wNUvRRE1IQkrTh87PpcY0OIACGaqmoKSJFCA4ratFVDOJoAbShpEVcSEQg4YByccBgaKBgM5rC963O959tdr20gBkSq9qv0EaRKT6N5evrp/5+ZN0j151/gRo0Vx8pseJnNbMP1Zr3GgBah6nyLCRsbs8di8VA4Go8nGJbnOEEQRAAkUZRhRCoqq2zFeiuOXraZS63GElxvMWiMmArV5BebsOf28TiViERiFEWfwjwPIC8ACSZISemV8itWo05lxQ3FZoNRrzWgapNOhUHYiI2POyAWjsTiFE1DmAenMDiFTSa8orxMpy2wmPTwGHVaVF2IaQpObBsxh2Pyf5h5B5/IChKMMEdQFCsrK1UXfWrUo2YDZtBpMG2RujBfq8rHT5THw+FIMBiCPJVgGIZjT8zzLMsmEjSiRXUohkKdYrPOYkRNek1RwaWi/M8uXcgzYWr7mH17eydEkhRFwXJFIAABqvMCz8WiEaSgUGOx4MUmFLbKgKrOnc358P33Pv7og/qaamF7WiCXiIA/CYS0LO0qyTeZdHYvc/hmL7ub5hNxJCc3r6KiHJrMO/cJqtXU1V7Lzc2xGlS+lwNLjgHfVN/KrDOTlAHLSDwn8pzEswoQUiIPr8iZM2fP513EcUtHZ/uGz3twuLeyvDjy8M7wr9+vTo8+aPlpYqj/aD8jMicwJNl4TEhQgGFiIRIxmS0XLhY8HHgKW5g9SO1m0qzknbf/3Hnr676OHwf/6PK4XUf7u1AqKfApwAMmARg6Hg75N31IZWXVjMsVIYJPno5u7mylFMGx0vR7X03r9er6St3zwVY6sg3JjAwykrCXFCHPURSXoOhoGKmtrYuQ/sNdJSPxrlevJhc7+53XG1v1N25it78z9A7WhcitKOGPEH7YIeVEmYLOZY6TORZpbm4Ok8FEggGi4vP5Oga+bH9c9e09w602rKnb+EvvtUAgGCLDm+veTe9KIhKiwmQkGIiHSBqOqqfnt/U1D8tJHJBpGnTea+gaqW5o0TXexWpuFH5z2wp/JMXKKx7v0p/uDc/Sltez5V3bXl+DCdLa0rSxuhwORYGcTqWzronH3aNXq2vUZlxVbCv4qh4jAuubo22+sVbvutc9O/vaPTczNbkw8/KvBTdSWVG+uvya8O/EKfbg8B8yTtzts/3QdrXxZr21RFNaef5+c0N7jXlu6AHD8AQZDRDheffC2PCQffgJXAzLYF+P17M8NzMN32iWcb5sn50f8a77Rp4NdXfcmbA/o1hp/+BvJbXLC7Isp3leJoio68UUYrRchiJOx/j87PTc9DTgBZFYySip/ezx4dHb47f/Zg+OFSUtAjkJByKl4Eq922qJoQHS2fXIpNfdb2ueck5srHpIMsrxopLa298/lJNpUUrCvYUxmcyIkgITjoO/i4MlxKI04l5YLbfqK0pMj/p7XzgmXE7n/MIiw0IgJQBoUpEkBQA4V8BxIsuJ8ImiGJKIbG36/wPG3qQZ7mlVkwAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/story/static/3672896cbb49cb2a4050c9744a3e8496/d89b0/test.jpg","srcSet":"/story/static/3672896cbb49cb2a4050c9744a3e8496/aaa13/test.jpg 374w,\n/story/static/3672896cbb49cb2a4050c9744a3e8496/b3c6b/test.jpg 748w,\n/story/static/3672896cbb49cb2a4050c9744a3e8496/d89b0/test.jpg 1496w","sizes":"(min-width: 1496px) 1496px, 100vw"},"sources":[{"srcSet":"/story/static/3672896cbb49cb2a4050c9744a3e8496/0dfd6/test.webp 374w,\n/story/static/3672896cbb49cb2a4050c9744a3e8496/8acfa/test.webp 748w,\n/story/static/3672896cbb49cb2a4050c9744a3e8496/06565/test.webp 1496w","type":"image/webp","sizes":"(min-width: 1496px) 1496px, 100vw"}]},"width":1496,"height":1496}},"publicURL":"/story/static/3672896cbb49cb2a4050c9744a3e8496/test.png"}}}}]}},"pageContext":{"slug":"/딥러닝 필수 기초 수학 4탄/"}},"staticQueryHashes":[],"slicesMap":{}}